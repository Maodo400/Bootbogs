{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qzNWs_zEhJG"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MuCQx7XbGnf_"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from math import sqrt, pow\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Optimization\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3R-Zqn8b7-s"
   },
   "source": [
    "# Methode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_gfR4rmnddop"
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
    "    if drop:\n",
    "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "    else:\n",
    "        X_train_interim = add_operating_condition(train)\n",
    "        X_test_interim = add_operating_condition(test)\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "\n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "def rul_piecewise_fct(X_train, rul):\n",
    "\n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def prepare_data(file_name):\n",
    "    dir_path =  'C:/Users/RA-RV/Documents/Malick/data/'\n",
    "    dependent_var = ['RUL']\n",
    "    index_names = ['Unit', 'Cycle']\n",
    "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
    "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "    col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
    "\n",
    "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
    "    rul_train.columns = ['Unit', 'max']\n",
    "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
    "\n",
    "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
    "    #y_true[\"Unit\"] = y_true.index + 1\n",
    "    return df_train, df_test, y_test\n",
    "\n",
    "\n",
    "# add operational condition to then normalize the data based on these operational conditions test\n",
    "def add_operating_condition(df):\n",
    "    df_op_cond = df.copy()\n",
    "\n",
    "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
    "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
    "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
    "\n",
    "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
    "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
    "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
    "                        df_op_cond['TRA'].astype(str)\n",
    "\n",
    "    return df_op_cond\n",
    "\n",
    "# normalize the data based on the operational condition\n",
    "def condition_scaler(df_train, df_test, sensor_names):\n",
    "  # apply operating condition specific scaling\n",
    "  #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    for condition in df_train['op_cond'].unique():\n",
    "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "#to plot each sensors with respect to the RUL\n",
    "def plot_signal(df, signal_name, unit=None):\n",
    "#     train = df\n",
    "    plt.figure(figsize=(13,5))\n",
    "    if unit:\n",
    "        plt.plot('RUL', signal_name,\n",
    "                data=df[df['Unit']==unit])\n",
    "    else:\n",
    "        for i in df['Unit'].unique():\n",
    "            if (i % 10 == 0):  # only ploting every 10th unit_nr\n",
    "                plt.plot('RUL', signal_name,\n",
    "                         data=df[df['Unit']==i])\n",
    "    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n",
    "    plt.xticks(np.arange(0, 375, 25))\n",
    "    plt.ylabel(signal_name)\n",
    "    plt.xlabel('Remaining Use fulLife')\n",
    "    #plt.savefig(signal_name+'.jpeg')\n",
    "    plt.show()\n",
    "\n",
    "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
    "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
    "    df = df.copy()\n",
    "    # first, calculate the exponential weighted mean of desired sensors\n",
    "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
    "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
    "    def create_mask(data, samples):\n",
    "        result = np.ones_like(data)\n",
    "        result[0:samples] = 0\n",
    "        return result\n",
    "\n",
    "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
    "    df = df[mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "#the score defined in the paper\n",
    "def compute_s_score(rul_true, rul_pred):\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "\n",
    "#evaluate the model with RÂ² and RMSE\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "\n",
    "def generate_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of a given length from the input data.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    # Generate sequences using sliding windows\n",
    "    for start_idx in range(num_samples - sequence_length + 1):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        yield data[start_idx:end_idx, :]\n",
    "\n",
    "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate sequences for multiple units in the dataset.\n",
    "    \"\"\"\n",
    "    if unit_nrs is None:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    # Generate sequences for each unit and concatenate them\n",
    "    all_sequences = []\n",
    "    for unit_nr in unit_nrs:\n",
    "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
    "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return np.array(all_sequences, dtype=np.float32)\n",
    "\n",
    "\n",
    "def gen_train_data(df, sequence_length, columns):\n",
    "    data = df[columns].values\n",
    "    num_elements = data.shape[0]\n",
    "\n",
    "    # -1 and +1 because of Python indexing\n",
    "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
    "        yield data[start:stop, :]\n",
    "\n",
    "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
    "               for unit_nr in unit_nrs)\n",
    "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
    "    return data_array\n",
    "\n",
    "def create_model(TW , remaining_):\n",
    "#     history = History()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_MAPE(y_true, y_hat):\n",
    "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
    "    return mape\n",
    "\n",
    "def gen_labels(df, sequence_length, label):\n",
    "    data_matrix = df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
    "    return data_matrix[sequence_length-1:num_elements, :]\n",
    "\n",
    "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
    "                for unit_nr in unit_nrs]\n",
    "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "    return label_array\n",
    "def gen_test_data(df, sequence_length, columns, mask_value):\n",
    "    if df.shape[0] < sequence_length:\n",
    "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
    "        idx = data_matrix.shape[0] - df.shape[0]\n",
    "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
    "    else:\n",
    "        data_matrix = df[columns].values\n",
    "\n",
    "    # specifically yield the last possible sequence\n",
    "    stop = num_elements = data_matrix.shape[0]\n",
    "    start = stop - sequence_length\n",
    "    for i in list(range(1)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def new_column (df, column):\n",
    "    #df = df.sort_values(by=column, ascending=False)\n",
    "    df[column] = range(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3reK6P4D-4XM"
   },
   "source": [
    "# PrÃ©paration des donnÃ©es et configuration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1747643898102,
     "user": {
      "displayName": "El Hadji Malick Sy",
      "userId": "07326824895633266968"
     },
     "user_tz": -120
    },
    "id": "ZQiI0neXGngG",
    "outputId": "536c9759-97e5-4d2b-8061-003dfb2fa6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 130\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "# Configuration des paramÃ¨tres\n",
    "alpha = 0.2\n",
    "sequence_length = 40\n",
    "epochs = 10\n",
    "#nodes_per_layer = [64]\n",
    "#dropout = 0.2\n",
    "activation = 'tanh'\n",
    "batch_size = 32\n",
    "remaining_sensors = remaining_sensors\n",
    "input_shape = (sequence_length, len(remaining_sensors))\n",
    "\n",
    "space_val = {\n",
    "    'hidden_size': {\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "        'step': 32\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'min': np.log(1e-5),\n",
    "        'max': np.log(1e-2)\n",
    "    },\n",
    "    'dropout': {\n",
    "        'min': 0.1,\n",
    "        'max': 0.5,\n",
    "        'step': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# PrÃ©paration des donnÃ©es\n",
    "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\n",
    "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "path_bootstrap = 'C:/Users/RA-RV/Documents/Malick/data/EO10/fd004_bootstrap_s_score.csv'\n",
    "path_bootstrap2 = 'C:/Users/RA-RV/Documents/Malick/data/EO10/fd004_bootstrap2_s_score.csv'\n",
    "path_grid = 'C:/Users/RA-RV/Documents/Malick/data/EO10/fd004_bootbogs_s_score.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yC6kum8dWzB"
   },
   "source": [
    "# Bayesian optimization avec bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XjaNrNBnLtk"
   },
   "source": [
    "## Creer n series bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8y_6F-lTnTA5"
   },
   "outputs": [],
   "source": [
    "def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n",
    "\n",
    "    n_timesteps = len(data)\n",
    "    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n",
    "    bootstrap_series_list = []\n",
    "\n",
    "    # DÃ©couper la sÃ©rie en blocs\n",
    "    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n",
    "\n",
    "    # CrÃ©er chaque sÃ©rie bootstrap\n",
    "    for _ in range(n_bootstrap):\n",
    "        # RÃ©Ã©chantillonner les blocs avec remise\n",
    "        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n",
    "\n",
    "        # ConcatÃ©ner les blocs pour former une nouvelle sÃ©rie\n",
    "        new_series = np.concatenate(sampled_blocks, axis=0)\n",
    "\n",
    "        if len(new_series) > n_timesteps:\n",
    "            new_series = new_series[:n_timesteps]\n",
    "\n",
    "        elif len(new_series) < n_timesteps:\n",
    "          remaining_length = n_timesteps - len(new_series)\n",
    "          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n",
    "\n",
    "        bootstrap_series_list.append(new_series)\n",
    "\n",
    "    return bootstrap_series_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzO_WAqMXrHk"
   },
   "source": [
    "## Creation et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KdXdtod0er4D"
   },
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la rÃ©gression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Fonction pour entraÃ®ner le modÃ¨le et Ã©valuer la RMSE\n",
    "def train_model(params):\n",
    "    # CrÃ©ation du modÃ¨le\n",
    "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, round(params['learning_rate'], 5))\n",
    "\n",
    "    # EntraÃ®nement du modÃ¨le\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # DÃ©sactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # PrÃ©diction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "  # minimiser RMSE/s-score\n",
    "\n",
    "    # Retourner la RMSE comme mÃ©trique Ã  minimiser\n",
    "    return {'loss': s_score, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEaXloQYQXC"
   },
   "source": [
    "## Apply HyperOpt TPE and store the combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LmtmfU5JPTmh",
    "outputId": "ed664e79-5445-4f27-cd0a-d47352597be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de la sÃ©rie bootstrap 1...\n",
      "(51545, 40, 17) (51545, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 223ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 225ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step         \n",
      "\n",
      " 20%|ââ        | 2/10 [08:59<33:56, 254.50s/trial, best loss: 3349.088615019383]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D4363E6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 223ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step         \n",
      "\n",
      " 30%|âââ       | 3/10 [14:27<33:34, 287.80s/trial, best loss: 3349.088615019383]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001D43415FCE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 259ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 252ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 245ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m3s\u001b[0m 555ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 257ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 147ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 147ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [45:02<00:00, 270.25s/trial, best loss: 2406.2736081204685]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "\n",
      "       s_score       mape       r2  training_time  \n",
      "0  2689.562555  48.393862  0.79306    2934.943733  \n",
      "Traitement de la sÃ©rie bootstrap 2...\n",
      "(51552, 40, 17) (51552, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 153ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 233ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m3s\u001b[0m 469ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 211ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 365ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 226ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 220ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 158ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 157ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [58:10<00:00, 349.06s/trial, best loss: 2300.6105386729214]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "Traitement de la sÃ©rie bootstrap 3...\n",
      "(51589, 40, 17) (51589, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 220ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 212ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 197ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 365ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 16ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 371ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 15ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 223ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 260ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 241ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 242ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 222ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step           \n",
      "\n",
      "100%|ââââââââââ| 10/10 [1:05:06<00:00, 390.63s/trial, best loss: 2311.068652847872]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "Traitement de la sÃ©rie bootstrap 4...\n",
      "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 225ms/step\n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 214ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 150ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 146ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 141ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 326ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 222ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 216ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 206ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 223ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [42:58<00:00, 257.88s/trial, best loss: 2082.9630371385633]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "Traitement de la sÃ©rie bootstrap 5...\n",
      "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 241ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 153ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 159ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 152ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 145ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 147ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 173ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 238ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 206ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 326ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [38:15<00:00, 229.59s/trial, best loss: 1827.0848417752368]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "Traitement de la sÃ©rie bootstrap 6...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 144ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 196ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 338ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 219ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 388ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 149ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 147ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 204ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 148ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step        \n",
      "\n",
      "100%|ââââââââââ| 10/10 [44:38<00:00, 267.85s/trial, best loss: 1443.66354976402]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "5                 6         64.0        0.00676      0.1  20.383171   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "5  1808.168072  35.642623  0.789248    2854.381791  \n",
      "Traitement de la sÃ©rie bootstrap 7...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 204ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 229ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 209ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 229ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 229ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 324ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 392ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 328ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 206ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 227ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [50:51<00:00, 305.16s/trial, best loss: 2850.1252102798358]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "5                 6         64.0        0.00676      0.1  20.383171   \n",
      "6                 7         96.0        0.00075      0.2  19.552635   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "5  1808.168072  35.642623  0.789248    2854.381791  \n",
      "6  2509.347328  31.654784  0.806072    3270.688608  \n",
      "Traitement de la sÃ©rie bootstrap 8...\n",
      "(51677, 40, 17) (51677, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 221ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 306ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m10s\u001b[0m 1s/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 332ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 22ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 369ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 354ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 273ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 214ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 157ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 218ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step           \n",
      "\n",
      "100%|ââââââââââ| 10/10 [1:02:16<00:00, 373.64s/trial, best loss: 1821.470786557414]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "5                 6         64.0        0.00676      0.1  20.383171   \n",
      "6                 7         96.0        0.00075      0.2  19.552635   \n",
      "7                 8        128.0        0.00436      0.3  19.864306   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "5  1808.168072  35.642623  0.789248    2854.381791  \n",
      "6  2509.347328  31.654784  0.806072    3270.688608  \n",
      "7  2036.375429  43.888447  0.799841    3979.795021  \n",
      "Traitement de la sÃ©rie bootstrap 9...\n",
      "(51628, 40, 17) (51628, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 354ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 360ms/step         \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 163ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 154ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 255ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 362ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 210ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 143ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 297ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step         \n",
      "\n",
      "100%|ââââââââââ| 10/10 [53:07<00:00, 318.70s/trial, best loss: 2353.260594069523]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "5                 6         64.0        0.00676      0.1  20.383171   \n",
      "6                 7         96.0        0.00075      0.2  19.552635   \n",
      "7                 8        128.0        0.00436      0.3  19.864306   \n",
      "8                 9        160.0        0.00387      0.4  21.810074   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "5  1808.168072  35.642623  0.789248    2854.381791  \n",
      "6  2509.347328  31.654784  0.806072    3270.688608  \n",
      "7  2036.375429  43.888447  0.799841    3979.795021  \n",
      "8  2343.063296  44.425274  0.758708    3548.956652  \n",
      "Traitement de la sÃ©rie bootstrap 10...\n",
      "(51564, 40, 17) (51564, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 231ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 361ms/step       \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 19ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 388ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m2s\u001b[0m 336ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 237ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 148ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 152ms/step        \n",
      "\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 166ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 227ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 220ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step         \n",
      "\n",
      "100%|ââââââââââ| 10/10 [46:58<00:00, 281.83s/trial, best loss: 3645.967473364707]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00722      0.2  20.197954   \n",
      "1                 2        256.0        0.00037      0.1  19.911092   \n",
      "2                 3        128.0        0.00043      0.3  20.949417   \n",
      "3                 4         64.0        0.00633      0.2  19.451730   \n",
      "4                 5        192.0        0.00114      0.3  23.968625   \n",
      "5                 6         64.0        0.00676      0.1  20.383171   \n",
      "6                 7         96.0        0.00075      0.2  19.552635   \n",
      "7                 8        128.0        0.00436      0.3  19.864306   \n",
      "8                 9        160.0        0.00387      0.4  21.810074   \n",
      "9                10         32.0        0.00042      0.5  22.133627   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2689.562555  48.393862  0.793060    2934.943733  \n",
      "1  2530.533256  32.843312  0.798897    3968.865484  \n",
      "2  2812.597137  41.307634  0.777376    4173.466705  \n",
      "3  1633.986961  42.531385  0.808069    2782.637905  \n",
      "4  4142.848410  36.962056  0.708583    2763.140865  \n",
      "5  1808.168072  35.642623  0.789248    2854.381791  \n",
      "6  2509.347328  31.654784  0.806072    3270.688608  \n",
      "7  2036.375429  43.888447  0.799841    3979.795021  \n",
      "8  2343.063296  44.425274  0.758708    3548.956652  \n",
      "9  2808.978329  59.841113  0.751496    2972.210055  \n"
     ]
    }
   ],
   "source": [
    "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
    "results_all = pd.DataFrame()\n",
    "for i, series in enumerate(bootstrap_series_list):\n",
    "    print(f\"Traitement de la sÃ©rie bootstrap {i + 1}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    space = {\n",
    "        'hidden_size': hp.quniform('hidden_size',\n",
    "                              space_val['hidden_size']['min'],\n",
    "                              space_val['hidden_size']['max'],\n",
    "                              space_val['hidden_size']['step']),\n",
    "\n",
    "        'learning_rate': hp.loguniform('learning_rate',\n",
    "                                    space_val['learning_rate']['min'],\n",
    "                                    space_val['learning_rate']['max']),\n",
    "\n",
    "        'dropout': hp.quniform('dropout',\n",
    "                              space_val['dropout']['min'],\n",
    "                              space_val['dropout']['max'],\n",
    "                              space_val['dropout']['step'])\n",
    "    }\n",
    "\n",
    "    series = pd.DataFrame(series, columns=train.columns)\n",
    "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "                for unit_nr in X_test_interim['Unit'].unique())\n",
    "\n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "    # Optimisation bayÃ©sienne avec Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=train_model,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, round(best['learning_rate'], 5))\n",
    "\n",
    "    # EntraÃ®nement du modÃ¨le\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # DÃ©sactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # PrÃ©diction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "    #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "\n",
    "    time_training = time.time() - start_time\n",
    "    #Sauvegarder les rÃ©sultats dans un DataFrame\n",
    "\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "      'bootstrap_series': i + 1,\n",
    "      'hidden_size': best['hidden_size'],\n",
    "      'learning_rate': round(best['learning_rate'], 5),\n",
    "      'dropout': best['dropout'],\n",
    "      'rmse': rmse,\n",
    "      's_score': s_score,\n",
    "      'mape': mape,\n",
    "      'r2': r2,\n",
    "      'training_time': time_training\n",
    "  }])], ignore_index=True)\n",
    "    print(results_all)\n",
    "\n",
    "  # Sauvegarder les rÃ©sultats dans un fichier CSV aprÃ¨s chaque itÃ©ration\n",
    "    results_all.to_csv(path_bootstrap, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb-N_tnveCiW"
   },
   "source": [
    "# Intervalle de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "llmldvM9GzOr"
   },
   "outputs": [],
   "source": [
    "def intervalle_confiance(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    Q1 = df[\"s_score\"].quantile(0.25)\n",
    "    Q3 = df[\"s_score\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculer la moyenne et l'Ã©cart type de la colonne \"s_score\"\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    #remove duplicate values and sort list\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n",
    "    return dropout_final, learning_final, neurons_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5otejvX00cDt"
   },
   "source": [
    "# 2e TPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I35N2YFk0fT3",
    "outputId": "2d3aa6bd-0392-4e52-efa0-8a067565cc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search space 175\n",
      "Traitement de la sÃ©rie bootstrap 1...\n",
      "(51546, 40, 17) (51546, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 151ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 176ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 156ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 181ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 175ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [45:15<00:00, 271.51s/trial, best loss: 1603.8339149644262]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "Traitement de la sÃ©rie bootstrap 2...\n",
      "(51541, 40, 17) (51541, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 151ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 209ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 140ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 122ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [47:17<00:00, 283.77s/trial, best loss: 1530.2464096480774]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "Traitement de la sÃ©rie bootstrap 3...\n",
      "(51599, 40, 17) (51599, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 190ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 177ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 185ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 185ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 185ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 135ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 244ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [37:09<00:00, 222.92s/trial, best loss: 1806.9613911754886]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "Traitement de la sÃ©rie bootstrap 4...\n",
      "(51599, 40, 17) (51599, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 183ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 192ms/step       \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 203ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 140ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 204ms/step       \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 194ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 158ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 127ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 123ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\n",
      "100%|ââââââââââ| 10/10 [38:00<00:00, 228.04s/trial, best loss: 2401.99536348814]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "Traitement de la sÃ©rie bootstrap 5...\n",
      "(51570, 40, 17) (51570, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 179ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 193ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 174ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 165ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 122ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 131ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 128ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 129ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 137ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 131ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\n",
      "100%|ââââââââââ| 10/10 [48:59<00:00, 293.96s/trial, best loss: 1836.798840484108]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "Traitement de la sÃ©rie bootstrap 6...\n",
      "(51568, 40, 17) (51568, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 164ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 220ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 191ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 186ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\n",
      "100%|ââââââââââ| 10/10 [32:23<00:00, 194.32s/trial, best loss: 1739.580218361647]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "5                 6        160.0        0.00043      0.5  19.847239   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "5  2034.910328  34.284730  0.800185    2196.231438  \n",
      "Traitement de la sÃ©rie bootstrap 7...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 183ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 165ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 223ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [36:36<00:00, 219.64s/trial, best loss: 2027.5699188204007]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "5                 6        160.0        0.00043      0.5  19.847239   \n",
      "6                 7         96.0        0.00043      0.5  20.106884   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "5  2034.910328  34.284730  0.800185    2196.231438  \n",
      "6  2102.703410  37.773340  0.794922    2416.248794  \n",
      "Traitement de la sÃ©rie bootstrap 8...\n",
      "(51616, 40, 17) (51616, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 169ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 200ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 191ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 183ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 173ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [28:33<00:00, 171.31s/trial, best loss: 1980.3031050613786]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "5                 6        160.0        0.00043      0.5  19.847239   \n",
      "6                 7         96.0        0.00043      0.5  20.106884   \n",
      "7                 8         32.0        0.00436      0.2  20.057037   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "5  2034.910328  34.284730  0.800185    2196.231438  \n",
      "6  2102.703410  37.773340  0.794922    2416.248794  \n",
      "7  2225.523344  43.326014  0.795938    1834.683281  \n",
      "Traitement de la sÃ©rie bootstrap 9...\n",
      "(51616, 40, 17) (51616, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 265ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 186ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [36:46<00:00, 220.68s/trial, best loss: 1489.4354620248898]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "5                 6        160.0        0.00043      0.5  19.847239   \n",
      "6                 7         96.0        0.00043      0.5  20.106884   \n",
      "7                 8         32.0        0.00436      0.2  20.057037   \n",
      "8                 9         96.0        0.00387      0.1  19.213190   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "5  2034.910328  34.284730  0.800185    2196.231438  \n",
      "6  2102.703410  37.773340  0.794922    2416.248794  \n",
      "7  2225.523344  43.326014  0.795938    1834.683281  \n",
      "8  2028.354108  34.723484  0.812747    2403.638966  \n",
      "Traitement de la sÃ©rie bootstrap 10...\n",
      "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 214ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 126ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 132ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 126ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 117ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 184ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 179ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "100%|ââââââââââ| 10/10 [54:28<00:00, 326.85s/trial, best loss: 2720.3815818626354]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        256.0        0.00043      0.1  17.841189   \n",
      "1                 2        256.0        0.00075      0.3  22.078876   \n",
      "2                 3        128.0        0.00043      0.3  19.502449   \n",
      "3                 4         96.0        0.00075      0.4  20.622942   \n",
      "4                 5        128.0        0.00037      0.3  19.368446   \n",
      "5                 6        160.0        0.00043      0.5  19.847239   \n",
      "6                 7         96.0        0.00043      0.5  20.106884   \n",
      "7                 8         32.0        0.00436      0.2  20.057037   \n",
      "8                 9         96.0        0.00387      0.1  19.213190   \n",
      "9                10        256.0        0.00075      0.1  22.954259   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  1514.001041  27.778676  0.838536    3072.108767  \n",
      "1  2527.759561  37.363446  0.752724    3175.677857  \n",
      "2  2288.948865  30.702477  0.807067    2466.551308  \n",
      "3  2639.339089  44.795470  0.784260    2458.358685  \n",
      "4  2094.423666  32.038797  0.809709    3154.109089  \n",
      "5  2034.910328  34.284730  0.800185    2196.231438  \n",
      "6  2102.703410  37.773340  0.794922    2416.248794  \n",
      "7  2225.523344  43.326014  0.795938    1834.683281  \n",
      "8  2028.354108  34.723484  0.812747    2403.638966  \n",
      "9  3940.291675  46.732752  0.732727    3666.911463  \n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation des sÃ©ries bootstrap\n",
    "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "# Chargement de l'espace restreint (valeurs rÃ©elles)\n",
    "dropout_first, learning_rate_first, hidden_size_first = intervalle_confiance(path_bootstrap)\n",
    "\n",
    "for i, series in enumerate(bootstrap_series_list):\n",
    "    print(f\"Traitement de la sÃ©rie bootstrap {i + 1}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # DÃ©finition de lâespace de recherche avec indices\n",
    "    space = {\n",
    "        'learning_rate': hp.choice('learning_rate', list(range(len(learning_rate_first)))),\n",
    "        'dropout': hp.choice('dropout', list(range(len(dropout_first)))),\n",
    "        'hidden_size': hp.choice('hidden_size', list(range(len(hidden_size_first))))\n",
    "    }\n",
    "\n",
    "    # Formatage de la sÃ©rie bootstrap\n",
    "    series = pd.DataFrame(series, columns=train.columns)\n",
    "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "    # PrÃ©paration des donnÃ©es\n",
    "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (\n",
    "        list(gen_test_data(\n",
    "            X_test_interim[X_test_interim['Unit'] == unit_nr],\n",
    "            sequence_length, remaining_sensors, -99.0))\n",
    "        for unit_nr in X_test_interim['Unit'].unique()\n",
    "    )\n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "    # Fonction d'entraÃ®nement adaptÃ©e Ã  Hyperopt\n",
    "    def train_model(params):\n",
    "        real_params = {\n",
    "            'learning_rate': learning_rate_first[params['learning_rate']],\n",
    "            'dropout': dropout_first[params['dropout']],\n",
    "            'hidden_size': hidden_size_first[params['hidden_size']]\n",
    "        }\n",
    "\n",
    "        model = model_lstm_1layer(input_shape,\n",
    "                                  real_params['hidden_size'],\n",
    "                                  real_params['dropout'],\n",
    "                                  activation,\n",
    "                                  round(real_params['learning_rate'], 5))\n",
    "\n",
    "        model.fit(\n",
    "            train_array, label_array,\n",
    "            validation_data=(test_array, test_rul),\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(test_array)\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "        s_score = compute_s_score(test_rul, y_pred)\n",
    "        mape = compute_MAPE(test_rul, y_pred)\n",
    "        r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "        return {\n",
    "            'loss': s_score,  # ou 'rmse' si vous prÃ©fÃ©rez\n",
    "            'status': STATUS_OK,\n",
    "            'rmse': rmse,\n",
    "            's_score': s_score,\n",
    "            'mape': mape,\n",
    "            'r2': r2\n",
    "        }\n",
    "\n",
    "    # Optimisation bayÃ©sienne\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=train_model,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # RÃ©cupÃ©ration des vraies valeurs\n",
    "    best_params = {\n",
    "        'learning_rate': learning_rate_first[best['learning_rate']],\n",
    "        'dropout': dropout_first[best['dropout']],\n",
    "        'hidden_size': hidden_size_first[best['hidden_size']]\n",
    "    }\n",
    "\n",
    "    # CrÃ©ation et entraÃ®nement final du modÃ¨le avec les meilleurs hyperparamÃ¨tres\n",
    "    model = model_lstm_1layer(input_shape,\n",
    "                              best_params['hidden_size'],\n",
    "                              best_params['dropout'],\n",
    "                              activation,\n",
    "                              round(best_params['learning_rate'], 5))\n",
    "\n",
    "    model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Ãvaluation finale\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "    time_training = time.time() - start_time\n",
    "\n",
    "    # Stockage des rÃ©sultats\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "        'bootstrap_series': i + 1,\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'learning_rate': round(best_params['learning_rate'], 5),\n",
    "        'dropout': best_params['dropout'],\n",
    "        'rmse': rmse,\n",
    "        's_score': s_score,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'training_time': time_training\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "    print(results_all)\n",
    "\n",
    "    # Sauvegarde continue aprÃ¨s chaque sÃ©rie\n",
    "    results_all.to_csv(path_bootstrap2, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV9djbEb0izo"
   },
   "source": [
    "# intervalle de confiance 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dhFy5xw70nqh"
   },
   "outputs": [],
   "source": [
    "def intervalle_confiance2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    Q1 = df[\"s_score\"].quantile(0.25)\n",
    "    Q3 = df[\"s_score\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n",
    "\n",
    "    # Calculer la moyenne et l'Ã©cart type de la colonne \"s_score\"\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    #remove duplicate values and sort list\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n",
    "    print(type(neurons_final))\n",
    "    return dropout_final, learning_final, neurons_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71CHXx5siROg"
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yODLXZzQiPlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search space 64\n",
      "<class 'list'>\n",
      "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 23.5447\n",
      "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 20.5468\n",
      "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 21.5475\n",
      "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 24.5832\n",
      "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 23.5498\n",
      "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 22.2425\n",
      "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 22.6687\n",
      "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 23.5305\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 21.0690\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 21.6995\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 21.5878\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 21.6870\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 22.2841\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "Validation RMSE: 20.8335\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Validation RMSE: 21.3014\n",
      "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 22.0363\n",
      "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 22.5222\n",
      "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 20.0145\n",
      "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 21.8304\n",
      "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 23.0496\n",
      "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 23.6384\n",
      "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 21.8651\n",
      "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 20.3800\n",
      "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 22.0855\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 21.7406\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 22.8202\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 21.7702\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.4352\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 20.9118\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.7479\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.6338\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.6674\n",
      "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.6544\n",
      "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.7193\n",
      "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 20.1356\n",
      "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 21.5753\n",
      "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 21.3998\n",
      "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.9596\n",
      "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.5357\n",
      "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.5125\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.8016\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.0814\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.0396\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 21.5752\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.3015\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.6646\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.8080\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.9240\n",
      "Training with LSTM units=32.0, learning_rate=0.0044, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.2810\n",
      "Training with LSTM units=32.0, learning_rate=0.0044, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 24.7955\n",
      "Training with LSTM units=32.0, learning_rate=0.0044, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 29.4166\n",
      "Training with LSTM units=32.0, learning_rate=0.0044, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.3509\n",
      "Training with LSTM units=32.0, learning_rate=0.0039, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 23.7489\n",
      "Training with LSTM units=32.0, learning_rate=0.0039, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.8585\n",
      "Training with LSTM units=32.0, learning_rate=0.0039, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Validation RMSE: 21.8249\n",
      "Training with LSTM units=32.0, learning_rate=0.0039, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.5907\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 22.1178\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 23.7540\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.6732\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.0919\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.1304\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 21.7969\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 22.6423\n",
      "Training with LSTM units=32.0, learning_rate=0.0004, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 21.0756\n"
     ]
    }
   ],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la rÃ©gression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "dropout, learning_rate, hidden_size = intervalle_confiance2(path_bootstrap2)\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "#Sauvegarder les rÃ©sultats dans un DataFrame\n",
    "results_all = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for hidden_size in param_grid['hidden_size']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Build the LSTM model\n",
    "            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, round(learning_rate, 5))\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_array, label_array,\n",
    "                validation_data=(test_array, test_rul),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=0\n",
    "            )\n",
    "            # Evaluate the model on the validation set\n",
    "            y_pred = model.predict(test_array)\n",
    "            # Calcul de la RMSE\n",
    "            rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "            s_score = compute_s_score(test_rul, y_pred)\n",
    "            mape = compute_MAPE(test_rul, y_pred)\n",
    "            r2 = r2_score(test_rul, y_pred)\n",
    "            #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "\n",
    "            time_training = time.time() - start_time\n",
    "            i+=1\n",
    "            #Sauvegarder les rÃ©sultats dans un DataFrame\n",
    "\n",
    "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "                'bootstrap_series': i,\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': round(learning_rate, 5),\n",
    "                'dropout': dropout,\n",
    "                'rmse': rmse,\n",
    "                's_score': s_score,\n",
    "                'mape': mape,\n",
    "                'r2': r2,\n",
    "                'training_time': time_training\n",
    "            }])], ignore_index=True)\n",
    "  \n",
    "            results_all.to_csv(path_grid, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1qzNWs_zEhJG",
    "w3R-Zqn8b7-s"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
