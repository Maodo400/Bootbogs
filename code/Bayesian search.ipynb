{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qzNWs_zEhJG"
   },
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MuCQx7XbGnf_"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from math import sqrt, pow\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Optimization\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK, space_eval\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3R-Zqn8b7-s"
   },
   "source": [
    "# Methode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gfR4rmnddop"
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
    "    if drop:\n",
    "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "    else:\n",
    "        X_train_interim = add_operating_condition(train)\n",
    "        X_test_interim = add_operating_condition(test)\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "\n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "def rul_piecewise_fct(X_train, rul):\n",
    "\n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def prepare_data(file_name):\n",
    "    dir_path = '../data/'\n",
    "    dependent_var = ['RUL']\n",
    "    index_names = ['Unit', 'Cycle']\n",
    "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
    "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "    col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
    "\n",
    "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
    "    rul_train.columns = ['Unit', 'max']\n",
    "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
    "\n",
    "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
    "    #y_true[\"Unit\"] = y_true.index + 1\n",
    "    return df_train, df_test, y_test\n",
    "\n",
    "\n",
    "# add operational condition to then normalize the data based on these operational conditions test\n",
    "def add_operating_condition(df):\n",
    "    df_op_cond = df.copy()\n",
    "\n",
    "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
    "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
    "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
    "\n",
    "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
    "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
    "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
    "                        df_op_cond['TRA'].astype(str)\n",
    "\n",
    "    return df_op_cond\n",
    "\n",
    "# normalize the data based on the operational condition\n",
    "def condition_scaler(df_train, df_test, sensor_names):\n",
    "  # apply operating condition specific scaling\n",
    "  #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    for condition in df_train['op_cond'].unique():\n",
    "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
    "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
    "    df = df.copy()\n",
    "    # first, calculate the exponential weighted mean of desired sensors\n",
    "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
    "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
    "    def create_mask(data, samples):\n",
    "        result = np.ones_like(data)\n",
    "        result[0:samples] = 0\n",
    "        return result\n",
    "\n",
    "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
    "    df = df[mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "#the score defined in the paper\n",
    "def compute_s_score(rul_true, rul_pred):\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "\n",
    "#evaluate the model with R² and RMSE\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "\n",
    "def generate_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of a given length from the input data.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    # Generate sequences using sliding windows\n",
    "    for start_idx in range(num_samples - sequence_length + 1):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        yield data[start_idx:end_idx, :]\n",
    "\n",
    "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate sequences for multiple units in the dataset.\n",
    "    \"\"\"\n",
    "    if unit_nrs is None:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    # Generate sequences for each unit and concatenate them\n",
    "    all_sequences = []\n",
    "    for unit_nr in unit_nrs:\n",
    "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
    "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return np.array(all_sequences, dtype=np.float32)\n",
    "\n",
    "\n",
    "def gen_train_data(df, sequence_length, columns):\n",
    "    data = df[columns].values\n",
    "    num_elements = data.shape[0]\n",
    "\n",
    "    # -1 and +1 because of Python indexing\n",
    "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
    "        yield data[start:stop, :]\n",
    "\n",
    "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
    "               for unit_nr in unit_nrs)\n",
    "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
    "    return data_array\n",
    "\n",
    "def create_model(TW , remaining_):\n",
    "#     history = History()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_MAPE(y_true, y_hat):\n",
    "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
    "    return mape\n",
    "\n",
    "def gen_labels(df, sequence_length, label):\n",
    "    data_matrix = df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
    "    return data_matrix[sequence_length-1:num_elements, :]\n",
    "\n",
    "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
    "                for unit_nr in unit_nrs]\n",
    "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "    return label_array\n",
    "def gen_test_data(df, sequence_length, columns, mask_value):\n",
    "    if df.shape[0] < sequence_length:\n",
    "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
    "        idx = data_matrix.shape[0] - df.shape[0]\n",
    "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
    "    else:\n",
    "        data_matrix = df[columns].values\n",
    "\n",
    "    # specifically yield the last possible sequence\n",
    "    stop = num_elements = data_matrix.shape[0]\n",
    "    start = stop - sequence_length\n",
    "    for i in list(range(1)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "\n",
    "\n",
    "def new_column (df, column):\n",
    "    #df = df.sort_values(by=column, ascending=False)\n",
    "    df[column] = range(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3reK6P4D-4XM"
   },
   "source": [
    "# Préparation des données et configuration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1832,
     "status": "ok",
     "timestamp": 1745477625262,
     "user": {
      "displayName": "El Hadji Malick Sy",
      "userId": "07326824895633266968"
     },
     "user_tz": -120
    },
    "id": "ZQiI0neXGngG",
    "outputId": "4e112352-9645-4bf5-cc22-27725fb921d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 120\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "# Configuration des paramètres\n",
    "alpha = 0.2\n",
    "sequence_length = 40\n",
    "epochs = 10\n",
    "#nodes_per_layer = [64]\n",
    "#dropout = 0.2\n",
    "activation = 'tanh'\n",
    "batch_size = 32\n",
    "remaining_sensors = remaining_sensors\n",
    "input_shape = (sequence_length, len(remaining_sensors))\n",
    "\n",
    "#preciser la regle utilisee avec la ref(auteur)\n",
    "#hidden_size_list = [32, 64, 128, 256]\n",
    "space_val = {\n",
    "    'hidden_size': {\n",
    "        'min': 32,\n",
    "        'max': 256,#generaliser selon la regle en ajoutant une fonction de max selon input feature et time windows\n",
    "        'step': 32\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'min': np.log(1e-5),\n",
    "        'max': np.log(1e-2),\n",
    "        'num': 8\n",
    "    },\n",
    "    'dropout': {\n",
    "        'min': 0.1,\n",
    "        'max': 0.5,\n",
    "        'step': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Préparation des données\n",
    "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\n",
    "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "print(train_array.shape, label_array.shape, test_array.shape)\n",
    "path_random = '../data/fd004_random_search.csv'\n",
    "path_bayesian = '../data/fd004_bayesian.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yC6kum8dWzB"
   },
   "source": [
    "# Bayesian Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzO_WAqMXrHk"
   },
   "source": [
    "## Creation et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KdXdtod0er4D"
   },
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
    "def train_model(params):\n",
    "    # Création du modèle\n",
    "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, params['learning_rate'])\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=3,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "    # Retourner la RMSE comme métrique à minimiser\n",
    "    return {'loss': -r2, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEaXloQYQXC"
   },
   "source": [
    "## Apply HyperOpt TPE and store the combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmtmfU5JPTmh",
    "outputId": "e506f1d7-5c59-4d13-d998-63cf7b1f3b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting optimization run 1/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 198ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:44<00:00, 76.41s/trial, best loss: -0.8357594609260559]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.30000000000000004, 'hidden_size': 96.0, 'learning_rate': 0.002435307227409313}\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Starting optimization run 2/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [14:20<00:00, 86.01s/trial, best loss: -0.8372204303741455]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 224.0, 'learning_rate': 0.0005223861072621871}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "\n",
      "Starting optimization run 3/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [10:56<00:00, 65.67s/trial, best loss: -0.8477920293807983]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.5, 'hidden_size': 96.0, 'learning_rate': 0.0012398692589214411}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "\n",
      "Starting optimization run 4/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 164ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [11:49<00:00, 70.92s/trial, best loss: -0.8383011221885681]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.30000000000000004, 'hidden_size': 128.0, 'learning_rate': 0.0035055706622054146}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "\n",
      "Starting optimization run 5/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 170ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 153ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [13:14<00:00, 79.46s/trial, best loss: -0.8651310205459595]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.1, 'hidden_size': 96.0, 'learning_rate': 0.003056948821234977}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "\n",
      "Starting optimization run 6/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 173ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [09:57<00:00, 59.79s/trial, best loss: -0.8628333806991577]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.5, 'hidden_size': 224.0, 'learning_rate': 0.0025208281189690743}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "\n",
      "Starting optimization run 7/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 196ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:25<00:00, 74.56s/trial, best loss: -0.8245695233345032]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 32.0, 'learning_rate': 0.002959144885063178}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "5   6        224.0       0.002521      0.5  15.360831  1599.184786  27.417068   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "5  0.862833     597.952255  \n",
      "\n",
      "Starting optimization run 8/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 183ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:30<00:00, 75.09s/trial, best loss: -0.8400595784187317]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.30000000000000004, 'hidden_size': 160.0, 'learning_rate': 0.0035005234424526853}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "5   6        224.0       0.002521      0.5  15.360831  1599.184786  27.417068   \n",
      "6   7         32.0       0.002959      0.4  17.371727  2086.937302  24.165319   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "5  0.862833     597.952255  \n",
      "6  0.824570     745.622563  \n",
      "\n",
      "Starting optimization run 9/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 146ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 191ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [13:42<00:00, 82.30s/trial, best loss: -0.8591974377632141]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.1, 'hidden_size': 160.0, 'learning_rate': 0.0021775524273624793}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "5   6        224.0       0.002521      0.5  15.360831  1599.184786  27.417068   \n",
      "6   7         32.0       0.002959      0.4  17.371727  2086.937302  24.165319   \n",
      "7   8        160.0       0.003501      0.3  16.587065  1791.984488  37.238075   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "5  0.862833     597.952255  \n",
      "6  0.824570     745.622563  \n",
      "7  0.840060     750.950065  \n",
      "\n",
      "Starting optimization run 10/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 193ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step          \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 159ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [15:11<00:00, 91.14s/trial, best loss: -0.8485159873962402]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.1, 'hidden_size': 192.0, 'learning_rate': 0.002217256388519677}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "5   6        224.0       0.002521      0.5  15.360831  1599.184786  27.417068   \n",
      "6   7         32.0       0.002959      0.4  17.371727  2086.937302  24.165319   \n",
      "7   8        160.0       0.003501      0.3  16.587065  1791.984488  37.238075   \n",
      "8   9        160.0       0.002178      0.1  15.563087  1721.598062  23.577795   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "5  0.862833     597.952255  \n",
      "6  0.824570     745.622563  \n",
      "7  0.840060     750.950065  \n",
      "8  0.859197     822.971590  \n",
      "\n",
      "Starting optimization run 11/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 164ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [13:30<00:00, 81.09s/trial, best loss: -0.8448379635810852]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 224.0, 'learning_rate': 0.0022791710895983747}\n",
      "   id  hidden_size  learning_rate  dropout       rmse      s_score       mape  \\\n",
      "0   1         96.0       0.002435      0.3  16.808566  2493.499867  26.717184   \n",
      "1   2        224.0       0.000522      0.4  16.733638  2197.755558  25.422385   \n",
      "2   3         96.0       0.001240      0.5  16.181142  1971.755857  24.423856   \n",
      "3   4        128.0       0.003506      0.3  16.677999  2309.154075  27.451093   \n",
      "4   5         96.0       0.003057      0.1  15.231632  1473.862527  23.940584   \n",
      "5   6        224.0       0.002521      0.5  15.360831  1599.184786  27.417068   \n",
      "6   7         32.0       0.002959      0.4  17.371727  2086.937302  24.165319   \n",
      "7   8        160.0       0.003501      0.3  16.587065  1791.984488  37.238075   \n",
      "8   9        160.0       0.002178      0.1  15.563087  1721.598062  23.577795   \n",
      "9  10        192.0       0.002217      0.1  16.142613  1885.803551  23.612005   \n",
      "\n",
      "         r2  training_time  \n",
      "0  0.835759     764.091627  \n",
      "1  0.837220     860.144348  \n",
      "2  0.847792     656.724929  \n",
      "3  0.838301     709.166917  \n",
      "4  0.865131     794.642799  \n",
      "5  0.862833     597.952255  \n",
      "6  0.824570     745.622563  \n",
      "7  0.840060     750.950065  \n",
      "8  0.859197     822.971590  \n",
      "9  0.848516     911.436399  \n",
      "\n",
      "Starting optimization run 12/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 181ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 199ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [14:41<00:00, 88.15s/trial, best loss: -0.8239846229553223]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 224.0, 'learning_rate': 0.007235347149595856}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "\n",
      "Starting optimization run 13/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:39<00:00, 75.98s/trial, best loss: -0.8240282535552979]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.2, 'hidden_size': 192.0, 'learning_rate': 0.0021391163773704317}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "\n",
      "Starting optimization run 14/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 160ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 151ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 190ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 157ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\n",
      "100%|██████████| 10/10 [12:33<00:00, 75.33s/trial, best loss: -0.852774977684021]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 192.0, 'learning_rate': 0.007499088514376146}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "\n",
      "Starting optimization run 15/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 145ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [13:27<00:00, 80.73s/trial, best loss: -0.8497070074081421]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.1, 'hidden_size': 160.0, 'learning_rate': 0.0024011806215025635}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "\n",
      "Starting optimization run 16/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 170ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [14:43<00:00, 88.35s/trial, best loss: -0.8598071932792664]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.2, 'hidden_size': 128.0, 'learning_rate': 0.0038241453000749234}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "\n",
      "Starting optimization run 17/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 148ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 145ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 151ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 150ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 145ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [09:21<00:00, 56.13s/trial, best loss: -0.8619297742843628]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.1, 'hidden_size': 96.0, 'learning_rate': 0.0011291019039332947}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "15  16        128.0       0.003824      0.2  15.529351  1823.723473   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "15  23.259547  0.859807     883.505104  \n",
      "\n",
      "Starting optimization run 18/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 147ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 154ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 152ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 181ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:16<00:00, 73.68s/trial, best loss: -0.8548492193222046]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.4, 'hidden_size': 128.0, 'learning_rate': 0.0024403387787451138}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "15  16        128.0       0.003824      0.2  15.529351  1823.723473   \n",
      "16  17         96.0       0.001129      0.1  15.411341  1626.965177   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "15  23.259547  0.859807     883.505104  \n",
      "16  24.325863  0.861930     561.296486  \n",
      "\n",
      "Starting optimization run 19/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 164ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [12:26<00:00, 74.63s/trial, best loss: -0.8795332312583923]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.5, 'hidden_size': 64.0, 'learning_rate': 0.0033962590504569975}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "15  16        128.0       0.003824      0.2  15.529351  1823.723473   \n",
      "16  17         96.0       0.001129      0.1  15.411341  1626.965177   \n",
      "17  18        128.0       0.002440      0.4  15.801565  1924.906698   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "15  23.259547  0.859807     883.505104  \n",
      "16  24.325863  0.861930     561.296486  \n",
      "17  25.670379  0.854849     736.835712  \n",
      "\n",
      "Starting optimization run 20/20\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 197ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [14:14<00:00, 85.42s/trial, best loss: -0.8531938791275024]\n",
      "Best Hyperparameters:\n",
      "{'dropout': 0.30000000000000004, 'hidden_size': 128.0, 'learning_rate': 0.0038948904131819737}\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "15  16        128.0       0.003824      0.2  15.529351  1823.723473   \n",
      "16  17         96.0       0.001129      0.1  15.411341  1626.965177   \n",
      "17  18        128.0       0.002440      0.4  15.801565  1924.906698   \n",
      "18  19         64.0       0.003396      0.5  14.395412  1273.471813   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "15  23.259547  0.859807     883.505104  \n",
      "16  24.325863  0.861930     561.296486  \n",
      "17  25.670379  0.854849     736.835712  \n",
      "18  20.382930  0.879533     746.302778  \n",
      "\n",
      "Final Results:\n",
      "    id  hidden_size  learning_rate  dropout       rmse      s_score  \\\n",
      "0    1         96.0       0.002435      0.3  16.808566  2493.499867   \n",
      "1    2        224.0       0.000522      0.4  16.733638  2197.755558   \n",
      "2    3         96.0       0.001240      0.5  16.181142  1971.755857   \n",
      "3    4        128.0       0.003506      0.3  16.677999  2309.154075   \n",
      "4    5         96.0       0.003057      0.1  15.231632  1473.862527   \n",
      "5    6        224.0       0.002521      0.5  15.360831  1599.184786   \n",
      "6    7         32.0       0.002959      0.4  17.371727  2086.937302   \n",
      "7    8        160.0       0.003501      0.3  16.587065  1791.984488   \n",
      "8    9        160.0       0.002178      0.1  15.563087  1721.598062   \n",
      "9   10        192.0       0.002217      0.1  16.142613  1885.803551   \n",
      "10  11        224.0       0.002279      0.4  16.337409  2136.077307   \n",
      "11  12        224.0       0.007235      0.4  17.400661  2762.061793   \n",
      "12  13        192.0       0.002139      0.2  17.398505  2920.228650   \n",
      "13  14        192.0       0.007499      0.4  15.914071  1799.768109   \n",
      "14  15        160.0       0.002401      0.1  16.079030  2003.670918   \n",
      "15  16        128.0       0.003824      0.2  15.529351  1823.723473   \n",
      "16  17         96.0       0.001129      0.1  15.411341  1626.965177   \n",
      "17  18        128.0       0.002440      0.4  15.801565  1924.906698   \n",
      "18  19         64.0       0.003396      0.5  14.395412  1273.471813   \n",
      "19  20        128.0       0.003895      0.3  15.891414  1577.685013   \n",
      "\n",
      "         mape        r2  training_time  \n",
      "0   26.717184  0.835759     764.091627  \n",
      "1   25.422385  0.837220     860.144348  \n",
      "2   24.423856  0.847792     656.724929  \n",
      "3   27.451093  0.838301     709.166917  \n",
      "4   23.940584  0.865131     794.642799  \n",
      "5   27.417068  0.862833     597.952255  \n",
      "6   24.165319  0.824570     745.622563  \n",
      "7   37.238075  0.840060     750.950065  \n",
      "8   23.577795  0.859197     822.971590  \n",
      "9   23.612005  0.848516     911.436399  \n",
      "10  28.565345  0.844838     810.901579  \n",
      "11  29.589383  0.823985     881.544294  \n",
      "12  24.143131  0.824028     759.759085  \n",
      "13  27.047641  0.852775     753.324544  \n",
      "14  22.779598  0.849707     807.339501  \n",
      "15  23.259547  0.859807     883.505104  \n",
      "16  24.325863  0.861930     561.296486  \n",
      "17  25.670379  0.854849     736.835712  \n",
      "18  20.382930  0.879533     746.302778  \n",
      "19  26.755070  0.853194     854.253139  \n"
     ]
    }
   ],
   "source": [
    "# Initialize results dataframe with all relevant columns\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size',\n",
    "                              space_val['hidden_size']['min'],\n",
    "                              space_val['hidden_size']['max'],\n",
    "                              space_val['hidden_size']['step']),\n",
    "    'learning_rate': hp.loguniform('learning_rate',\n",
    "                              space_val['learning_rate']['min'],\n",
    "                              space_val['learning_rate']['max']),\n",
    "    'dropout': hp.quniform('dropout',\n",
    "                           space_val['dropout']['min'],\n",
    "                           space_val['dropout']['max'],\n",
    "                           space_val['dropout']['step'])\n",
    "}\n",
    "\n",
    "# Run Bayesian optimization multiple times\n",
    "def run_optimization(num_runs=20):\n",
    "    global results_all\n",
    "\n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        print(f\"\\nStarting optimization run {run_id}/{num_runs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        trials = Trials()\n",
    "\n",
    "        best = fmin(\n",
    "            fn=train_model,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,  # Number of evaluations per run\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "        # Get best trial results\n",
    "        decoded_best = space_eval(space, best)\n",
    "\n",
    "        print(\"Best Hyperparameters:\")\n",
    "        print(decoded_best)\n",
    "\n",
    "        best_trial = trials.best_trial\n",
    "        time_training = time.time() - start_time\n",
    "\n",
    "        best_rmse = trials.best_trial['result']['rmse']\n",
    "        best_s_score = trials.best_trial['result']['s_score']\n",
    "        best_mape = trials.best_trial['result']['mape']\n",
    "        best_r2 = trials.best_trial['result']['loss']\n",
    "\n",
    "\n",
    "        new_result = {\n",
    "          'id': run_id,\n",
    "          'hidden_size': decoded_best['hidden_size'],\n",
    "          'learning_rate': best['learning_rate'],\n",
    "          'dropout': best['dropout'],\n",
    "          'rmse': best_rmse,\n",
    "          's_score': best_s_score,\n",
    "          'mape': best_mape,\n",
    "          'r2': -best_r2,\n",
    "          'training_time': time_training\n",
    "      }\n",
    "        print(results_all)\n",
    "\n",
    "        # Update results dataframe\n",
    "        results_all = pd.concat([results_all, pd.DataFrame([new_result])], ignore_index=True)\n",
    "\n",
    "        # Save to CSV after each run\n",
    "        results_all.to_csv(path_bayesian, index=False)\n",
    "        set_seed(42)\n",
    "\n",
    "    return results_all\n",
    "\n",
    "# Execute the optimization 20 times\n",
    "final_results = run_optimization(num_runs=20)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pORtv7grZNDT"
   },
   "source": [
    "## Visualisation de la moyenne et l'ecart type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asaw6-yBiKlb"
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjiBDt67iN4L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/20 - LSTM units=224, LR=0.00801, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "→ RMSE: 19.1663, Time: 253.96s\n",
      "Trial 2/20 - LSTM units=64, LR=0.00002, dropout=0.4\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020816663920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 25.1781, Time: 107.02s\n",
      "Trial 3/20 - LSTM units=64, LR=0.00002, dropout=0.1\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002081BEE4900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 21.2680, Time: 106.52s\n",
      "Trial 4/20 - LSTM units=96, LR=0.00009, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 26.8661, Time: 150.48s\n",
      "Trial 5/20 - LSTM units=96, LR=0.00260, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 23.4732, Time: 148.39s\n",
      "Trial 6/20 - LSTM units=224, LR=0.00101, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "→ RMSE: 13.2279, Time: 275.48s\n",
      "Trial 7/20 - LSTM units=96, LR=0.00409, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 13.2683, Time: 145.23s\n",
      "Trial 8/20 - LSTM units=160, LR=0.00002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 29.3626, Time: 201.41s\n",
      "Trial 9/20 - LSTM units=96, LR=0.00002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "→ RMSE: 28.0723, Time: 144.45s\n",
      "Trial 10/20 - LSTM units=160, LR=0.00022, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 28.9663, Time: 220.96s\n",
      "Trial 11/20 - LSTM units=64, LR=0.00004, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 19.1588, Time: 118.57s\n",
      "Trial 12/20 - LSTM units=192, LR=0.00427, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "→ RMSE: 13.5366, Time: 241.54s\n",
      "Trial 13/20 - LSTM units=160, LR=0.00015, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 24.0653, Time: 202.54s\n",
      "Trial 14/20 - LSTM units=224, LR=0.00059, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "→ RMSE: 20.3910, Time: 257.22s\n",
      "Trial 15/20 - LSTM units=256, LR=0.00563, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "→ RMSE: 21.3126, Time: 295.18s\n",
      "Trial 16/20 - LSTM units=160, LR=0.00343, dropout=0.2\n"
     ]
    }
   ],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Output for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Number of random trials\n",
    "n_trials = 20\n",
    "\n",
    "# Container for results\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "# Random Search\n",
    "for i in range(n_trials):\n",
    "    # Sample hyperparameters\n",
    "    #hidden_size = random.randint(space_val['hidden_size']['min'], space_val['hidden_size']['max'])\n",
    "    #hidden_size =  random.choice([32, 64, 128, 256]),\n",
    "    hidden_size = round(random.uniform(\n",
    "        space_val['hidden_size']['min'],\n",
    "        space_val['hidden_size']['max']\n",
    "    ) / space_val['hidden_size']['step']) * space_val['hidden_size']['step']\n",
    "\n",
    "    learning_rate = np.exp(random.uniform(space_val['learning_rate']['min'], space_val['learning_rate']['max']))\n",
    "    dropout = round(random.uniform(\n",
    "        space_val['dropout']['min'],\n",
    "        space_val['dropout']['max']\n",
    "    ) / space_val['dropout']['step']) * space_val['dropout']['step']\n",
    "\n",
    "    print(f\"Trial {i+1}/{n_trials} - LSTM units={hidden_size}, LR={learning_rate:.5f}, dropout={dropout}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Build and train model\n",
    "    model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(test_array)\n",
    "    rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "    score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    print(f\"→ RMSE: {rmse:.4f}, Time: {training_time:.2f}s\")\n",
    "\n",
    "    # Save to results\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "        'id': i + 1,\n",
    "        'hidden_size': hidden_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'dropout': dropout,\n",
    "        'rmse': rmse,\n",
    "        's-score': score,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    results_all.to_csv(path_random, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 27.8205\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 24.3584\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 30.1438\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 24.8540\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 27.0758\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.5673\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 19.8573\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.3990\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.5317\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 22.7354\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 18.3365\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 20.7359\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 18.7032\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 19.8988\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 23.9797\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.2596\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 23.6727\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 15.9821\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.5707\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.1403\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.6423\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 15.8134\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 15.3504\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 14.5059\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 16.0224\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.7486\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.0498\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.6125\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.0654\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 13.5477\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.5278\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 13.1948\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.2197\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 12.6462\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.2254\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 14.7240\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 13.8957\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 14.4007\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 15.1873\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 16.2322\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 27.6322\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 27.5764\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 24.9609\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 24.7074\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.2368\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.6937\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 20.8067\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.2445\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.1430\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.6419\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.5498\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.7372\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.7971\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.6644\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 24.3405\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 17.9511\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 17.6603\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 19.9210\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 18.8494\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 24.6283\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.7392\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 14.9248\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.2749\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.3928\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Validation RMSE: 14.6107\n",
      "Training with LSTM units=64, learning_rate=0.0014, dropout=0.1\n"
     ]
    }
   ],
   "source": [
    "# Generate grid values from space_val\n",
    "param_grid = {\n",
    "    'hidden_size': [32, 64, 96, 128, 160, 192, 224, 256],\n",
    "\n",
    "    'learning_rate': [np.exp(x) for x in np.linspace(\n",
    "        space_val['learning_rate']['min'],\n",
    "        space_val['learning_rate']['max'],\n",
    "        num=space_val['learning_rate']['num']\n",
    "    )],\n",
    "    'dropout': np.round(np.arange(\n",
    "        space_val['dropout']['min'],\n",
    "        space_val['dropout']['max'] + 0.001,\n",
    "        space_val['dropout']['step']\n",
    "    ), 2)\n",
    "}\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# -------------------------\n",
    "# LSTM Model Function\n",
    "# -------------------------\n",
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# Grid Search\n",
    "# -------------------------\n",
    "results_all = pd.DataFrame()\n",
    "i = 0\n",
    "set_seed(SEED)\n",
    "for hidden_size in param_grid['hidden_size']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
    "\n",
    "            with tf.device('/device:GPU:0'):\n",
    "                start_time = time.time()\n",
    "                # Build and train model\n",
    "                model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
    "                history = model.fit(\n",
    "                    train_array, label_array,\n",
    "                    validation_data=(test_array, test_rul),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[early_stop]\n",
    "                )\n",
    "\n",
    "                # Predict and evaluate\n",
    "                y_pred = model.predict(test_array)\n",
    "                rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "                s_score = compute_s_score(test_rul, y_pred)\n",
    "                mape = compute_MAPE(test_rul, y_pred)\n",
    "                r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "            time_training = time.time() - start_time\n",
    "            i += 1\n",
    "\n",
    "            # Save results\n",
    "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "                'id': i,\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'dropout': dropout,\n",
    "                'rmse': rmse,\n",
    "                's_score': s_score,\n",
    "                'mape': mape,\n",
    "                'r2': r2,\n",
    "                'training_time': time_training\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            results_all.to_csv('data/fd004_grid_search.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_bayesian)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"rmse\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"RMSE\"\n",
    ")\n",
    "\n",
    "# Highlight the best RMSE (lowest value)\n",
    "best_idx = df[\"rmse\"].idxmin()\n",
    "plt.scatter(\n",
    "    df.loc[best_idx, \"id\"],\n",
    "    df.loc[best_idx, \"rmse\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=f\"Best RMSE: {df.loc[best_idx, 'rmse']:.2f}\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"RMSE Across Hyperparameter Configurations\", fontsize=14)\n",
    "plt.xlabel(\"id\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "plt.xticks(df[\"id\"])\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_random)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"rmse\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"RMSE\"\n",
    ")\n",
    "\n",
    "# Highlight the best RMSE (lowest value)\n",
    "best_idx = df[\"rmse\"].idxmin()\n",
    "plt.scatter(\n",
    "    df.loc[best_idx, \"id\"],\n",
    "    df.loc[best_idx, \"rmse\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=f\"Best RMSE: {df.loc[best_idx, 'rmse']:.2f}\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"RMSE Across Hyperparameter Configurations\", fontsize=14)\n",
    "plt.xlabel(\"ID\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "plt.xticks(df[\"id\"])\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1qzNWs_zEhJG",
    "w3R-Zqn8b7-s",
    "3reK6P4D-4XM",
    "6XjaNrNBnLtk",
    "LzO_WAqMXrHk",
    "YPEaXloQYQXC",
    "bb-N_tnveCiW"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
