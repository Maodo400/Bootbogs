{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qzNWs_zEhJG"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MuCQx7XbGnf_"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from math import sqrt, pow\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Optimization\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3R-Zqn8b7-s"
   },
   "source": [
    "# Methode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_gfR4rmnddop"
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
    "    if drop:\n",
    "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "    else:\n",
    "        X_train_interim = add_operating_condition(train)\n",
    "        X_test_interim = add_operating_condition(test)\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "\n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "def rul_piecewise_fct(X_train, rul):\n",
    "\n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def prepare_data(file_name):\n",
    "    dir_path =  '../data/'\n",
    "    dependent_var = ['RUL']\n",
    "    index_names = ['Unit', 'Cycle']\n",
    "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
    "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "    col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
    "\n",
    "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
    "    rul_train.columns = ['Unit', 'max']\n",
    "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
    "\n",
    "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
    "    #y_true[\"Unit\"] = y_true.index + 1\n",
    "    return df_train, df_test, y_test\n",
    "\n",
    "\n",
    "# add operational condition to then normalize the data based on these operational conditions test\n",
    "def add_operating_condition(df):\n",
    "    df_op_cond = df.copy()\n",
    "\n",
    "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
    "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
    "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
    "\n",
    "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
    "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
    "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
    "                        df_op_cond['TRA'].astype(str)\n",
    "\n",
    "    return df_op_cond\n",
    "\n",
    "# normalize the data based on the operational condition\n",
    "def condition_scaler(df_train, df_test, sensor_names):\n",
    "  # apply operating condition specific scaling\n",
    "  #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    for condition in df_train['op_cond'].unique():\n",
    "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "#to plot each sensors with respect to the RUL\n",
    "def plot_signal(df, signal_name, unit=None):\n",
    "#     train = df\n",
    "    plt.figure(figsize=(13,5))\n",
    "    if unit:\n",
    "        plt.plot('RUL', signal_name,\n",
    "                data=df[df['Unit']==unit])\n",
    "    else:\n",
    "        for i in df['Unit'].unique():\n",
    "            if (i % 10 == 0):  # only ploting every 10th unit_nr\n",
    "                plt.plot('RUL', signal_name,\n",
    "                         data=df[df['Unit']==i])\n",
    "    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n",
    "    plt.xticks(np.arange(0, 375, 25))\n",
    "    plt.ylabel(signal_name)\n",
    "    plt.xlabel('Remaining Use fulLife')\n",
    "    #plt.savefig(signal_name+'.jpeg')\n",
    "    plt.show()\n",
    "\n",
    "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
    "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
    "    df = df.copy()\n",
    "    # first, calculate the exponential weighted mean of desired sensors\n",
    "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
    "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
    "    def create_mask(data, samples):\n",
    "        result = np.ones_like(data)\n",
    "        result[0:samples] = 0\n",
    "        return result\n",
    "\n",
    "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
    "    df = df[mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "#the score defined in the paper\n",
    "def compute_s_score(rul_true, rul_pred):\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "\n",
    "#evaluate the model with R² and RMSE\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "\n",
    "def generate_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of a given length from the input data.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    # Generate sequences using sliding windows\n",
    "    for start_idx in range(num_samples - sequence_length + 1):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        yield data[start_idx:end_idx, :]\n",
    "\n",
    "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate sequences for multiple units in the dataset.\n",
    "    \"\"\"\n",
    "    if unit_nrs is None:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    # Generate sequences for each unit and concatenate them\n",
    "    all_sequences = []\n",
    "    for unit_nr in unit_nrs:\n",
    "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
    "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return np.array(all_sequences, dtype=np.float32)\n",
    "\n",
    "\n",
    "def gen_train_data(df, sequence_length, columns):\n",
    "    data = df[columns].values\n",
    "    num_elements = data.shape[0]\n",
    "\n",
    "    # -1 and +1 because of Python indexing\n",
    "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
    "        yield data[start:stop, :]\n",
    "\n",
    "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
    "               for unit_nr in unit_nrs)\n",
    "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
    "    return data_array\n",
    "\n",
    "def create_model(TW , remaining_):\n",
    "#     history = History()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_MAPE(y_true, y_hat):\n",
    "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
    "    return mape\n",
    "\n",
    "def gen_labels(df, sequence_length, label):\n",
    "    data_matrix = df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
    "    return data_matrix[sequence_length-1:num_elements, :]\n",
    "\n",
    "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
    "                for unit_nr in unit_nrs]\n",
    "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "    return label_array\n",
    "def gen_test_data(df, sequence_length, columns, mask_value):\n",
    "    if df.shape[0] < sequence_length:\n",
    "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
    "        idx = data_matrix.shape[0] - df.shape[0]\n",
    "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
    "    else:\n",
    "        data_matrix = df[columns].values\n",
    "\n",
    "    # specifically yield the last possible sequence\n",
    "    stop = num_elements = data_matrix.shape[0]\n",
    "    start = stop - sequence_length\n",
    "    for i in list(range(1)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def new_column (df, column):\n",
    "    #df = df.sort_values(by=column, ascending=False)\n",
    "    df[column] = range(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3reK6P4D-4XM"
   },
   "source": [
    "# Préparation des données et configuration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1747643898102,
     "user": {
      "displayName": "El Hadji Malick Sy",
      "userId": "07326824895633266968"
     },
     "user_tz": -120
    },
    "id": "ZQiI0neXGngG",
    "outputId": "536c9759-97e5-4d2b-8061-003dfb2fa6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 130\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "# Configuration des paramètres\n",
    "alpha = 0.2\n",
    "sequence_length = 40\n",
    "epochs = 20\n",
    "#nodes_per_layer = [64]\n",
    "#dropout = 0.2\n",
    "activation = 'tanh'\n",
    "batch_size = 32\n",
    "remaining_sensors = remaining_sensors\n",
    "input_shape = (sequence_length, len(remaining_sensors))\n",
    "\n",
    "space_val = {\n",
    "    'hidden_size': {\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "        'step': 32\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'min': np.log(1e-5),\n",
    "        'max': np.log(1e-2)\n",
    "    },\n",
    "    'dropout': {\n",
    "        'min': 0.1,\n",
    "        'max': 0.5,\n",
    "        'step': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Préparation des données\n",
    "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\n",
    "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "path_bootstrap = '../data/EO20/fd004_bootstrap_s_score.csv'\n",
    "path_bootstrap2 = '../data/EO20/fd004_bootstrap2_s_score.csv'\n",
    "path_grid = '../data/EO20/fd004_bootbogs_s_score.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yC6kum8dWzB"
   },
   "source": [
    "# Bayesian optimization avec bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XjaNrNBnLtk"
   },
   "source": [
    "## Creer n series bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8y_6F-lTnTA5"
   },
   "outputs": [],
   "source": [
    "def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n",
    "\n",
    "    n_timesteps = len(data)\n",
    "    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n",
    "    bootstrap_series_list = []\n",
    "\n",
    "    # Découper la série en blocs\n",
    "    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n",
    "\n",
    "    # Créer chaque série bootstrap\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Rééchantillonner les blocs avec remise\n",
    "        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n",
    "\n",
    "        # Concaténer les blocs pour former une nouvelle série\n",
    "        new_series = np.concatenate(sampled_blocks, axis=0)\n",
    "\n",
    "        if len(new_series) > n_timesteps:\n",
    "            new_series = new_series[:n_timesteps]\n",
    "\n",
    "        elif len(new_series) < n_timesteps:\n",
    "          remaining_length = n_timesteps - len(new_series)\n",
    "          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n",
    "\n",
    "        bootstrap_series_list.append(new_series)\n",
    "\n",
    "    return bootstrap_series_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzO_WAqMXrHk"
   },
   "source": [
    "## Creation et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KdXdtod0er4D"
   },
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
    "def train_model(params):\n",
    "    # Création du modèle\n",
    "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, round(params['learning_rate'], 5))\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # Désactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "  # minimiser RMSE/s-score\n",
    "\n",
    "    # Retourner la RMSE comme métrique à minimiser\n",
    "    return {'loss': s_score, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEaXloQYQXC"
   },
   "source": [
    "## Apply HyperOpt TPE and store the combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LmtmfU5JPTmh",
    "outputId": "ed664e79-5445-4f27-cd0a-d47352597be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de la série bootstrap 1...\n",
      "(51545, 40, 17) (51545, 1) (248, 40, 17)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Optimisation bayésienne avec Hyperopt\u001b[39;00m\n\u001b[32m     42\u001b[39m trials = Trials()\n\u001b[32m     43\u001b[39m best = fmin(\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     fn=\u001b[43mtrain_model\u001b[49m,\n\u001b[32m     45\u001b[39m     space=space,\n\u001b[32m     46\u001b[39m     algo=tpe.suggest,\n\u001b[32m     47\u001b[39m     max_evals=\u001b[32m10\u001b[39m,\n\u001b[32m     48\u001b[39m     trials=trials\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m model = model_lstm_1layer(input_shape, best[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m], best[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m], activation, \u001b[38;5;28mround\u001b[39m(best[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m], \u001b[32m5\u001b[39m))\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
    "results_all = pd.DataFrame()\n",
    "for i, series in enumerate(bootstrap_series_list):\n",
    "    print(f\"Traitement de la série bootstrap {i + 1}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    space = {\n",
    "        'hidden_size': hp.quniform('hidden_size',\n",
    "                              space_val['hidden_size']['min'],\n",
    "                              space_val['hidden_size']['max'],\n",
    "                              space_val['hidden_size']['step']),\n",
    "\n",
    "        'learning_rate': hp.loguniform('learning_rate',\n",
    "                                    space_val['learning_rate']['min'],\n",
    "                                    space_val['learning_rate']['max']),\n",
    "\n",
    "        'dropout': hp.quniform('dropout',\n",
    "                              space_val['dropout']['min'],\n",
    "                              space_val['dropout']['max'],\n",
    "                              space_val['dropout']['step'])\n",
    "    }\n",
    "\n",
    "    series = pd.DataFrame(series, columns=train.columns)\n",
    "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "                for unit_nr in X_test_interim['Unit'].unique())\n",
    "\n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "    # Optimisation bayésienne avec Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=train_model,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, round(best['learning_rate'], 5))\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # Désactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "    #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "\n",
    "    time_training = time.time() - start_time\n",
    "    #Sauvegarder les résultats dans un DataFrame\n",
    "\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "      'bootstrap_series': i + 1,\n",
    "      'hidden_size': best['hidden_size'],\n",
    "      'learning_rate': round(best['learning_rate'], 5),\n",
    "      'dropout': best['dropout'],\n",
    "      'rmse': rmse,\n",
    "      's_score': s_score,\n",
    "      'mape': mape,\n",
    "      'r2': r2,\n",
    "      'training_time': time_training\n",
    "  }])], ignore_index=True)\n",
    "    print(results_all)\n",
    "\n",
    "  # Sauvegarder les résultats dans un fichier CSV après chaque itération\n",
    "    results_all.to_csv(path_bootstrap, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb-N_tnveCiW"
   },
   "source": [
    "# Intervalle de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "llmldvM9GzOr"
   },
   "outputs": [],
   "source": [
    "def intervalle_confiance(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    Q1 = df[\"s_score\"].quantile(0.25)\n",
    "    Q3 = df[\"s_score\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculer la moyenne et l'écart type de la colonne \"s_score\"\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    #remove duplicate values and sort list\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n",
    "    return dropout_final, learning_final, neurons_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5otejvX00cDt"
   },
   "source": [
    "# 2e TPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I35N2YFk0fT3",
    "outputId": "2d3aa6bd-0392-4e52-efa0-8a067565cc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search space 210\n",
      "Traitement de la série bootstrap 1...\n",
      "(51597, 40, 17) (51597, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      " 20%|██        | 2/10 [15:18<1:04:40, 485.07s/trial, best loss: 3276.713612059894]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001924AD9AC00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 185ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
      "\n",
      " 30%|███       | 3/10 [22:40<54:17, 465.40s/trial, best loss: 2759.4026994309606] WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001924B277600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 192ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 196ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 186ms/step       \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [1:18:34<00:00, 471.41s/trial, best loss: 2220.073723315067]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0         0.0004      0.3  20.259546   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "Traitement de la série bootstrap 2...\n",
      "(51611, 40, 17) (51611, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 145ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 208ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 145ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 150ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:29:27<00:00, 536.78s/trial, best loss: 2327.3977686900334]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0         0.0004      0.3  20.259546   \n",
      "1                 2         96.0         0.0004      0.3  20.365602   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "Traitement de la série bootstrap 3...\n",
      "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 164ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 149ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:22:01<00:00, 492.15s/trial, best loss: 2126.180704938086]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0         0.0004      0.3  20.259546   \n",
      "1                 2         96.0         0.0004      0.3  20.365602   \n",
      "2                 3        128.0         0.0004      0.5  19.582596   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "Traitement de la série bootstrap 4...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 149ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step           \n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 144ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:23:35<00:00, 501.58s/trial, best loss: 1804.3051800474354]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "Traitement de la série bootstrap 5...\n",
      "(51627, 40, 17) (51627, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 204ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 225ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:33:48<00:00, 562.89s/trial, best loss: 2562.6347683181048]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "Traitement de la série bootstrap 6...\n",
      "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:10:33<00:00, 423.31s/trial, best loss: 2210.645508036648]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "5                 6         64.0        0.00786      0.2  19.860538   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "5  1985.213924  45.192134  0.799917    4446.424307  \n",
      "Traitement de la série bootstrap 7...\n",
      "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:06:31<00:00, 399.10s/trial, best loss: 1818.0116482662995]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "5                 6         64.0        0.00786      0.2  19.860538   \n",
      "6                 7        128.0        0.00786      0.2  18.624076   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "5  1985.213924  45.192134  0.799917    4446.424307  \n",
      "6  1581.367663  26.175484  0.824054    4308.599616  \n",
      "Traitement de la série bootstrap 8...\n",
      "(51567, 40, 17) (51567, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:13:31<00:00, 441.16s/trial, best loss: 1749.9641336336251]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "5                 6         64.0        0.00786      0.2  19.860538   \n",
      "6                 7        128.0        0.00786      0.2  18.624076   \n",
      "7                 8        224.0        0.00211      0.5  18.420471   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "5  1985.213924  45.192134  0.799917    4446.424307  \n",
      "6  1581.367663  26.175484  0.824054    4308.599616  \n",
      "7  1903.025548  33.697472  0.827880    4947.118579  \n",
      "Traitement de la série bootstrap 9...\n",
      "(51617, 40, 17) (51617, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:05:09<00:00, 390.97s/trial, best loss: 2172.4905043669537]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "5                 6         64.0        0.00786      0.2  19.860538   \n",
      "6                 7        128.0        0.00786      0.2  18.624076   \n",
      "7                 8        224.0        0.00211      0.5  18.420471   \n",
      "8                 9         64.0        0.00699      0.5  22.437361   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "5  1985.213924  45.192134  0.799917    4446.424307  \n",
      "6  1581.367663  26.175484  0.824054    4308.599616  \n",
      "7  1903.025548  33.697472  0.827880    4947.118579  \n",
      "8  2293.668888  41.912869  0.744629    4121.911228  \n",
      "Traitement de la série bootstrap 10...\n",
      "(51543, 40, 17) (51543, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:03:39<00:00, 381.96s/trial, best loss: 1668.5221437710502]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1        128.0        0.00040      0.3  20.259546   \n",
      "1                 2         96.0        0.00040      0.3  20.365602   \n",
      "2                 3        128.0        0.00040      0.5  19.582596   \n",
      "3                 4         64.0        0.00252      0.5  22.568257   \n",
      "4                 5        160.0        0.00040      0.5  22.006035   \n",
      "5                 6         64.0        0.00786      0.2  19.860538   \n",
      "6                 7        128.0        0.00786      0.2  18.624076   \n",
      "7                 8        224.0        0.00211      0.5  18.420471   \n",
      "8                 9         64.0        0.00699      0.5  22.437361   \n",
      "9                10         64.0        0.00040      0.2  17.872973   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2910.930261  31.878564  0.791796    5154.959415  \n",
      "1  2586.265775  38.140805  0.789611    5728.992171  \n",
      "2  2291.633861  32.472439  0.805478    5312.376236  \n",
      "3  3703.121223  45.798357  0.741640    5295.055314  \n",
      "4  4061.210686  41.275176  0.754352    6033.129849  \n",
      "5  1985.213924  45.192134  0.799917    4446.424307  \n",
      "6  1581.367663  26.175484  0.824054    4308.599616  \n",
      "7  1903.025548  33.697472  0.827880    4947.118579  \n",
      "8  2293.668888  41.912869  0.744629    4121.911228  \n",
      "9  1700.942135  28.025406  0.837960    4035.891353  \n"
     ]
    }
   ],
   "source": [
    "# Création des séries bootstrap\n",
    "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "# Chargement de l'espace restreint (valeurs réelles)\n",
    "dropout_first, learning_rate_first, hidden_size_first = intervalle_confiance(path_bootstrap)\n",
    "\n",
    "for i, series in enumerate(bootstrap_series_list):\n",
    "    print(f\"Traitement de la série bootstrap {i + 1}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Définition de l’espace de recherche avec indices\n",
    "    space = {\n",
    "        'learning_rate': hp.choice('learning_rate', list(range(len(learning_rate_first)))),\n",
    "        'dropout': hp.choice('dropout', list(range(len(dropout_first)))),\n",
    "        'hidden_size': hp.choice('hidden_size', list(range(len(hidden_size_first))))\n",
    "    }\n",
    "\n",
    "    # Formatage de la série bootstrap\n",
    "    series = pd.DataFrame(series, columns=train.columns)\n",
    "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "    # Préparation des données\n",
    "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (\n",
    "        list(gen_test_data(\n",
    "            X_test_interim[X_test_interim['Unit'] == unit_nr],\n",
    "            sequence_length, remaining_sensors, -99.0))\n",
    "        for unit_nr in X_test_interim['Unit'].unique()\n",
    "    )\n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "    # Fonction d'entraînement adaptée à Hyperopt\n",
    "    def train_model(params):\n",
    "        real_params = {\n",
    "            'learning_rate': learning_rate_first[params['learning_rate']],\n",
    "            'dropout': dropout_first[params['dropout']],\n",
    "            'hidden_size': hidden_size_first[params['hidden_size']]\n",
    "        }\n",
    "\n",
    "        model = model_lstm_1layer(input_shape,\n",
    "                                  real_params['hidden_size'],\n",
    "                                  real_params['dropout'],\n",
    "                                  activation,\n",
    "                                  round(real_params['learning_rate'], 5))\n",
    "\n",
    "        model.fit(\n",
    "            train_array, label_array,\n",
    "            validation_data=(test_array, test_rul),\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(test_array)\n",
    "\n",
    "        rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "        s_score = compute_s_score(test_rul, y_pred)\n",
    "        mape = compute_MAPE(test_rul, y_pred)\n",
    "        r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "        return {\n",
    "            'loss': s_score,  # ou 'rmse' si vous préférez\n",
    "            'status': STATUS_OK,\n",
    "            'rmse': rmse,\n",
    "            's_score': s_score,\n",
    "            'mape': mape,\n",
    "            'r2': r2\n",
    "        }\n",
    "\n",
    "    # Optimisation bayésienne\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=train_model,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Récupération des vraies valeurs\n",
    "    best_params = {\n",
    "        'learning_rate': learning_rate_first[best['learning_rate']],\n",
    "        'dropout': dropout_first[best['dropout']],\n",
    "        'hidden_size': hidden_size_first[best['hidden_size']]\n",
    "    }\n",
    "\n",
    "    # Création et entraînement final du modèle avec les meilleurs hyperparamètres\n",
    "    model = model_lstm_1layer(input_shape,\n",
    "                              best_params['hidden_size'],\n",
    "                              best_params['dropout'],\n",
    "                              activation,\n",
    "                              round(best_params['learning_rate'], 5))\n",
    "\n",
    "    model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Évaluation finale\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "    time_training = time.time() - start_time\n",
    "\n",
    "    # Stockage des résultats\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "        'bootstrap_series': i + 1,\n",
    "        'hidden_size': best_params['hidden_size'],\n",
    "        'learning_rate': round(best_params['learning_rate'], 5),\n",
    "        'dropout': best_params['dropout'],\n",
    "        'rmse': rmse,\n",
    "        's_score': s_score,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'training_time': time_training\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "    print(results_all)\n",
    "\n",
    "    # Sauvegarde continue après chaque série\n",
    "    results_all.to_csv(path_bootstrap2, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV9djbEb0izo"
   },
   "source": [
    "# intervalle de confiance 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dhFy5xw70nqh"
   },
   "outputs": [],
   "source": [
    "def intervalle_confiance2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    Q1 = df[\"s_score\"].quantile(0.25)\n",
    "    Q3 = df[\"s_score\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n",
    "\n",
    "    # Calculer la moyenne et l'écart type de la colonne \"s_score\"\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    #remove duplicate values and sort list\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n",
    "    print(type(neurons_final))\n",
    "    return dropout_final, learning_final, neurons_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71CHXx5siROg"
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yODLXZzQiPlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search space 48\n",
      "<class 'list'>\n",
      "Training with LSTM units=224.0, learning_rate=0.0079, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 24.1015\n",
      "Training with LSTM units=224.0, learning_rate=0.0079, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 22.3824\n",
      "Training with LSTM units=224.0, learning_rate=0.0079, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 24.1610\n",
      "Training with LSTM units=224.0, learning_rate=0.0070, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 22.6062\n",
      "Training with LSTM units=224.0, learning_rate=0.0070, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 25.0547\n",
      "Training with LSTM units=224.0, learning_rate=0.0070, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 22.3597\n",
      "Training with LSTM units=224.0, learning_rate=0.0021, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 22.7400\n",
      "Training with LSTM units=224.0, learning_rate=0.0021, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 22.2792\n",
      "Training with LSTM units=224.0, learning_rate=0.0021, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 19.7372\n",
      "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 18.7116\n",
      "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Validation RMSE: 19.5272\n",
      "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 19.9822\n",
      "Training with LSTM units=128.0, learning_rate=0.0079, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 19.2400\n",
      "Training with LSTM units=128.0, learning_rate=0.0079, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 20.3027\n",
      "Training with LSTM units=128.0, learning_rate=0.0079, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Validation RMSE: 19.4603\n",
      "Training with LSTM units=128.0, learning_rate=0.0070, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.0799\n",
      "Training with LSTM units=128.0, learning_rate=0.0070, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.9739\n",
      "Training with LSTM units=128.0, learning_rate=0.0070, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 21.8502\n",
      "Training with LSTM units=128.0, learning_rate=0.0021, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Validation RMSE: 17.0506\n",
      "Training with LSTM units=128.0, learning_rate=0.0021, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 18.1071\n",
      "Training with LSTM units=128.0, learning_rate=0.0021, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 17.9860\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 20.6420\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 19.3190\n",
      "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 18.7763\n",
      "Training with LSTM units=96.0, learning_rate=0.0079, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 17.8756\n",
      "Training with LSTM units=96.0, learning_rate=0.0079, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.3065\n",
      "Training with LSTM units=96.0, learning_rate=0.0079, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 20.3300\n",
      "Training with LSTM units=96.0, learning_rate=0.0070, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 21.2073\n",
      "Training with LSTM units=96.0, learning_rate=0.0070, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Validation RMSE: 25.3704\n",
      "Training with LSTM units=96.0, learning_rate=0.0070, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 18.4109\n",
      "Training with LSTM units=96.0, learning_rate=0.0021, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 24.1443\n",
      "Training with LSTM units=96.0, learning_rate=0.0021, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 21.2725\n",
      "Training with LSTM units=96.0, learning_rate=0.0021, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 22.7447\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 18.2126\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 20.1885\n",
      "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 18.6150\n",
      "Training with LSTM units=64.0, learning_rate=0.0079, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 20.4040\n",
      "Training with LSTM units=64.0, learning_rate=0.0079, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 22.5696\n",
      "Training with LSTM units=64.0, learning_rate=0.0079, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 19.1502\n",
      "Training with LSTM units=64.0, learning_rate=0.0070, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 22.2617\n",
      "Training with LSTM units=64.0, learning_rate=0.0070, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 19.4834\n",
      "Training with LSTM units=64.0, learning_rate=0.0070, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 19.0046\n",
      "Training with LSTM units=64.0, learning_rate=0.0021, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 19.3532\n",
      "Training with LSTM units=64.0, learning_rate=0.0021, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Validation RMSE: 19.4420\n",
      "Training with LSTM units=64.0, learning_rate=0.0021, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 21.3761\n",
      "Training with LSTM units=64.0, learning_rate=0.0004, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 17.3919\n",
      "Training with LSTM units=64.0, learning_rate=0.0004, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Validation RMSE: 18.5342\n",
      "Training with LSTM units=64.0, learning_rate=0.0004, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Validation RMSE: 18.8660\n"
     ]
    }
   ],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "dropout, learning_rate, hidden_size = intervalle_confiance2(path_bootstrap2)\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "#Sauvegarder les résultats dans un DataFrame\n",
    "results_all = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for hidden_size in param_grid['hidden_size']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Build the LSTM model\n",
    "            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, round(learning_rate, 5))\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_array, label_array,\n",
    "                validation_data=(test_array, test_rul),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=0\n",
    "            )\n",
    "            # Evaluate the model on the validation set\n",
    "            y_pred = model.predict(test_array)\n",
    "            # Calcul de la RMSE\n",
    "            rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "            s_score = compute_s_score(test_rul, y_pred)\n",
    "            mape = compute_MAPE(test_rul, y_pred)\n",
    "            r2 = r2_score(test_rul, y_pred)\n",
    "            #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "\n",
    "            time_training = time.time() - start_time\n",
    "            i+=1\n",
    "            #Sauvegarder les résultats dans un DataFrame\n",
    "\n",
    "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "                'bootstrap_series': i,\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': round(learning_rate, 5),\n",
    "                'dropout': dropout,\n",
    "                'rmse': rmse,\n",
    "                's_score': s_score,\n",
    "                'mape': mape,\n",
    "                'r2': r2,\n",
    "                'training_time': time_training\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            results_all.to_csv(path_grid, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1qzNWs_zEhJG",
    "w3R-Zqn8b7-s"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
