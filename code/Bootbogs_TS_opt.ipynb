{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qzNWs_zEhJG"
      },
      "source": [
        "# Importations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MuCQx7XbGnf_"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Machine learning\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:58\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolorbar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Re-exported (import x as x) for typing.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1354\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1316\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1256\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1524\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1498\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1597\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# Standard libraries\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import warnings\n",
        "from math import sqrt, pow\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
        "import keras\n",
        "from keras import backend as K\n",
        "\n",
        "# Optimization\n",
        "from scipy import optimize\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 0\n",
        "def set_seed(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    tf.random.set_seed(SEED)\n",
        "\n",
        "# Appeler la fonction pour fixer le seed\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3R-Zqn8b7-s"
      },
      "source": [
        "# Methode.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gfR4rmnddop"
      },
      "outputs": [],
      "source": [
        "# read the train and test data\n",
        "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
        "    if drop:\n",
        "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
        "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
        "    else:\n",
        "        X_train_interim = add_operating_condition(train)\n",
        "        X_test_interim = add_operating_condition(test)\n",
        "\n",
        "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
        "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
        "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
        "\n",
        "    return X_train_interim, X_test_interim\n",
        "\n",
        "def rul_piecewise_fct(X_train, rul):\n",
        "\n",
        "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
        "\n",
        "    return X_train\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    dir_path = 'data/'\n",
        "    dependent_var = ['RUL']\n",
        "    index_names = ['Unit', 'Cycle']\n",
        "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
        "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
        "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
        "    col_names = index_names + setting_names + sensor_names\n",
        "\n",
        "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
        "\n",
        "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
        "    rul_train.columns = ['Unit', 'max']\n",
        "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
        "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
        "    df_train.drop('max', axis=1, inplace=True)\n",
        "\n",
        "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
        "\n",
        "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
        "    #y_true[\"Unit\"] = y_true.index + 1\n",
        "    return df_train, df_test, y_test\n",
        "\n",
        "\n",
        "# add operational condition to then normalize the data based on these operational conditions test\n",
        "def add_operating_condition(df):\n",
        "    df_op_cond = df.copy()\n",
        "\n",
        "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
        "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
        "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
        "\n",
        "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
        "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
        "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
        "                        df_op_cond['TRA'].astype(str)\n",
        "\n",
        "    return df_op_cond\n",
        "\n",
        "# normalize the data based on the operational condition\n",
        "def condition_scaler(df_train, df_test, sensor_names):\n",
        "  # apply operating condition specific scaling\n",
        "  #scaler = StandardScaler()\n",
        "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "    for condition in df_train['op_cond'].unique():\n",
        "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
        "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
        "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
        "    return df_train, df_test\n",
        "\n",
        "\n",
        "#to plot each sensors with respect to the RUL\n",
        "def plot_signal(df, signal_name, unit=None):\n",
        "#     train = df\n",
        "    plt.figure(figsize=(13,5))\n",
        "    if unit:\n",
        "        plt.plot('RUL', signal_name,\n",
        "                data=df[df['Unit']==unit])\n",
        "    else:\n",
        "        for i in df['Unit'].unique():\n",
        "            if (i % 10 == 0):  # only ploting every 10th unit_nr\n",
        "                plt.plot('RUL', signal_name,\n",
        "                         data=df[df['Unit']==i])\n",
        "    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n",
        "    plt.xticks(np.arange(0, 375, 25))\n",
        "    plt.ylabel(signal_name)\n",
        "    plt.xlabel('Remaining Use fulLife')\n",
        "    #plt.savefig(signal_name+'.jpeg')\n",
        "    plt.show()\n",
        "\n",
        "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
        "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
        "    df = df.copy()\n",
        "    # first, calculate the exponential weighted mean of desired sensors\n",
        "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
        "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
        "\n",
        "\n",
        "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
        "    def create_mask(data, samples):\n",
        "        result = np.ones_like(data)\n",
        "        result[0:samples] = 0\n",
        "        return result\n",
        "\n",
        "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
        "    df = df[mask]\n",
        "\n",
        "    return df\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
        "\n",
        "#the score defined in the paper\n",
        "def compute_s_score(rul_true, rul_pred):\n",
        "    diff = rul_pred - rul_true\n",
        "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
        "\n",
        "#evaluate the model with R² and RMSE\n",
        "def evaluate(y_true, y_hat, label='test'):\n",
        "    mse = mean_squared_error(y_true, y_hat)\n",
        "    rmse = np.sqrt(mse)\n",
        "    variance = r2_score(y_true, y_hat)\n",
        "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
        "\n",
        "def generate_sequences(data, sequence_length):\n",
        "    \"\"\"\n",
        "    Generate sequences of a given length from the input data.\n",
        "    \"\"\"\n",
        "    num_samples = data.shape[0]\n",
        "\n",
        "    # Generate sequences using sliding windows\n",
        "    for start_idx in range(num_samples - sequence_length + 1):\n",
        "        end_idx = start_idx + sequence_length\n",
        "        yield data[start_idx:end_idx, :]\n",
        "\n",
        "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
        "    \"\"\"\n",
        "    Wrapper function to generate sequences for multiple units in the dataset.\n",
        "    \"\"\"\n",
        "    if unit_nrs is None:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    # Generate sequences for each unit and concatenate them\n",
        "    all_sequences = []\n",
        "    for unit_nr in unit_nrs:\n",
        "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
        "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
        "        all_sequences.extend(sequences)\n",
        "\n",
        "    return np.array(all_sequences, dtype=np.float32)\n",
        "\n",
        "\n",
        "def gen_train_data(df, sequence_length, columns):\n",
        "    data = df[columns].values\n",
        "    num_elements = data.shape[0]\n",
        "\n",
        "    # -1 and +1 because of Python indexing\n",
        "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
        "        yield data[start:stop, :]\n",
        "\n",
        "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
        "    if unit_nrs.size <= 0:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
        "               for unit_nr in unit_nrs)\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array\n",
        "\n",
        "def create_model(TW , remaining_):\n",
        "#     history = History()\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "    return model\n",
        "\n",
        "def compute_MAPE(y_true, y_hat):\n",
        "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
        "    return mape\n",
        "\n",
        "def gen_labels(df, sequence_length, label):\n",
        "    data_matrix = df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "\n",
        "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
        "    return data_matrix[sequence_length-1:num_elements, :]\n",
        "\n",
        "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
        "    if unit_nrs.size <= 0:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
        "                for unit_nr in unit_nrs]\n",
        "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "    return label_array\n",
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "\n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "def plot_loss(fit_history):\n",
        "    plt.figure(figsize=(13,5))\n",
        "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
        "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def new_column (df, column):\n",
        "    #df = df.sort_values(by=column, ascending=False)\n",
        "    df[column] = range(1, len(df) + 1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3reK6P4D-4XM"
      },
      "source": [
        "# Préparation des données et configuration initiale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQiI0neXGngG",
        "outputId": "2b878fa3-e75f-45ee-bd1d-8cc6206b3b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(61249, 27) (41214, 26) (248, 1)\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
          ]
        }
      ],
      "source": [
        "train, test, y_test = prepare_data('FD004.txt')\n",
        "print(train.shape, test.shape, y_test.shape)\n",
        "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
        "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
        "\n",
        "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
        "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
        "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
        "\n",
        "rul_piecewise = 130\n",
        "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
        "\n",
        "# Configuration des paramètres\n",
        "alpha = 0.2\n",
        "sequence_length = 40\n",
        "epochs = 25\n",
        "#nodes_per_layer = [64]\n",
        "#dropout = 0.2\n",
        "activation = 'tanh'\n",
        "batch_size = 32\n",
        "remaining_sensors = remaining_sensors\n",
        "input_shape = (sequence_length, len(remaining_sensors))\n",
        "\n",
        "#preciser la regle utilisee avec la ref(auteur)\n",
        "space_val = {\n",
        "    'hidden_size': {\n",
        "        'min': 32,\n",
        "        'max': 256,\n",
        "        'step': 32\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'min': np.log(1e-5),\n",
        "        'max': np.log(1e-2)#a voir selon les regles presentees dans le rapport\n",
        "    },\n",
        "    'dropout': {\n",
        "        'min': 0.1,\n",
        "        'max': 0.5,\n",
        "        'step': 0.1\n",
        "    }\n",
        "}\n",
        "\n",
        "# Préparation des données\n",
        "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
        "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
        "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
        "\n",
        "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
        "               for unit_nr in X_test_interim['Unit'].unique())\n",
        "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
        "\n",
        "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
        "print(train_array.shape, label_array.shape, test_array.shape)\n",
        "\n",
        "path_bootstrap = 'data/fd004_bootstrap_opt.csv'\n",
        "path_grid = 'data/fd004_grid_search_bootstrap_opt.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yC6kum8dWzB"
      },
      "source": [
        "# Bayesian optimization avec bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XjaNrNBnLtk"
      },
      "source": [
        "## Creer n series bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y_6F-lTnTA5"
      },
      "outputs": [],
      "source": [
        "def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n",
        "\n",
        "    n_timesteps = len(data)\n",
        "    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n",
        "    bootstrap_series_list = []\n",
        "\n",
        "    # Découper la série en blocs\n",
        "    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n",
        "\n",
        "    # Créer chaque série bootstrap\n",
        "    for _ in range(n_bootstrap):\n",
        "        # Rééchantillonner les blocs avec remise\n",
        "        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n",
        "\n",
        "        # Concaténer les blocs pour former une nouvelle série\n",
        "        new_series = np.concatenate(sampled_blocks, axis=0)\n",
        "\n",
        "        if len(new_series) > n_timesteps:\n",
        "            new_series = new_series[:n_timesteps]\n",
        "\n",
        "        elif len(new_series) < n_timesteps:\n",
        "          remaining_length = n_timesteps - len(new_series)\n",
        "          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n",
        "\n",
        "        bootstrap_series_list.append(new_series)\n",
        "\n",
        "    return bootstrap_series_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzO_WAqMXrHk"
      },
      "source": [
        "## Creation et entrainement du modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdXdtod0er4D"
      },
      "outputs": [],
      "source": [
        "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dense(1))  # Sortie pour la régression\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
        "def train_model(params):\n",
        "    # Création du modèle\n",
        "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, params['learning_rate'])\n",
        "\n",
        "    # Entraînement du modèle\n",
        "    history = model.fit(\n",
        "        train_array, label_array,\n",
        "        validation_data=(test_array, test_rul),\n",
        "        epochs=3,\n",
        "        batch_size=32,\n",
        "        verbose=0  # Désactiver les logs pour une sortie propre\n",
        "    )\n",
        "\n",
        "    # Prédiction sur l'ensemble de validation\n",
        "    y_pred = model.predict(test_array)\n",
        "\n",
        "    # Calcul de la RMSE, S-Score, Mape\n",
        "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
        "    s_score = compute_s_score(test_rul, y_pred)\n",
        "    mape = compute_MAPE(test_rul, y_pred)\n",
        "    r2 = r2_score(test_rul, y_pred)\n",
        "\n",
        "    # Retourner la RMSE comme métrique à minimiser\n",
        "    return {'loss': -r2, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEaXloQYQXC"
      },
      "source": [
        "## Apply HyperOpt TPE and store the combination of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmtmfU5JPTmh",
        "outputId": "159e0fce-dfb5-4f57-f10b-7b0a90acbdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traitement de la série bootstrap 1...\n",
            "(51545, 40, 17) (51545, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 176ms/step\n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 199ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [14:50<00:00, 89.04s/trial, best loss: -0.8004405498504639]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "\n",
            "  r2training_time     s_score       mape        r2  training_time  \n",
            "0             NaN  1962.89257  43.781214  0.800441     891.514543  \n",
            "Traitement de la série bootstrap 2...\n",
            "(51552, 40, 17) (51552, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [11:14<00:00, 67.46s/trial, best loss: -0.7979751229286194]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "Traitement de la série bootstrap 3...\n",
            "(51589, 40, 17) (51589, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [12:15<00:00, 73.55s/trial, best loss: -0.7824123501777649]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "Traitement de la série bootstrap 4...\n",
            "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 198ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [11:52<00:00, 71.30s/trial, best loss: -0.7581413388252258]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "Traitement de la série bootstrap 5...\n",
            "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 183ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 185ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
            "\n",
            "100%|██████████| 10/10 [16:01<00:00, 96.17s/trial, best loss: -0.7914313673973083] \n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "Traitement de la série bootstrap 6...\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 183ms/step        \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\n",
            "100%|██████████| 10/10 [11:23<00:00, 68.35s/trial, best loss: -0.8083147406578064]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "5                6         96.0       0.001927      0.4  18.158701   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5             NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "Traitement de la série bootstrap 7...\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [08:57<00:00, 53.75s/trial, best loss: -0.8001007437705994]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "5                6         96.0       0.001927      0.4  18.158701   \n",
            "6                7         96.0       0.004411      0.5  18.543686   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5             NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6             NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "Traitement de la série bootstrap 8...\n",
            "(51677, 40, 17) (51677, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step\n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 170ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 144ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [15:23<00:00, 92.36s/trial, best loss: -0.7921934127807617]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "5                6         96.0       0.001927      0.4  18.158701   \n",
            "6                7         96.0       0.004411      0.5  18.543686   \n",
            "7                8        224.0       0.000653      0.3  18.906892   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5             NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6             NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7             NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "Traitement de la série bootstrap 9...\n",
            "(51628, 40, 17) (51628, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 152ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [14:45<00:00, 88.51s/trial, best loss: -0.8059749007225037] \n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "5                6         96.0       0.001927      0.4  18.158701   \n",
            "6                7         96.0       0.004411      0.5  18.543686   \n",
            "7                8        224.0       0.000653      0.3  18.906892   \n",
            "8                9        160.0       0.003190      0.3  18.269195   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5             NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6             NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7             NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8             NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "Traitement de la série bootstrap 10...\n",
            "(51564, 40, 17) (51564, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step         \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
            "\n",
            "100%|██████████| 10/10 [14:29<00:00, 86.96s/trial, best loss: -0.7750133275985718]\n",
            "  bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                1        160.0       0.000396      0.3  18.527919   \n",
            "1                2        128.0       0.000835      0.4  18.642016   \n",
            "2                3         96.0       0.000420      0.2  19.346731   \n",
            "3                4        224.0       0.000918      0.1  20.397235   \n",
            "4                5         96.0       0.000944      0.3  18.941525   \n",
            "5                6         96.0       0.001927      0.4  18.158701   \n",
            "6                7         96.0       0.004411      0.5  18.543686   \n",
            "7                8        224.0       0.000653      0.3  18.906892   \n",
            "8                9        160.0       0.003190      0.3  18.269195   \n",
            "9               10         96.0       0.004641      0.5  19.672922   \n",
            "\n",
            "  r2training_time      s_score       mape        r2  training_time  \n",
            "0             NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1             NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2             NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3             NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4             NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5             NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6             NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7             NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8             NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9             NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "Traitement de la série bootstrap 11...\n",
            "(51597, 40, 17) (51597, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 198ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 159ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 186ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 198ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 186ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [12:57<00:00, 77.79s/trial, best loss: -0.8117953538894653]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "Traitement de la série bootstrap 12...\n",
            "(51611, 40, 17) (51611, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 203ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [14:56<00:00, 89.69s/trial, best loss: -0.7847614884376526]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "Traitement de la série bootstrap 13...\n",
            "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 170ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 156ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [13:05<00:00, 78.57s/trial, best loss: -0.7781884074211121]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "Traitement de la série bootstrap 14...\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 147ms/step\n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 173ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [12:52<00:00, 77.26s/trial, best loss: -0.8148192167282104]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "Traitement de la série bootstrap 15...\n",
            "(51627, 40, 17) (51627, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [10:46<00:00, 64.64s/trial, best loss: -0.8029623031616211]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "Traitement de la série bootstrap 16...\n",
            "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 183ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 160ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 176ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 159ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [12:11<00:00, 73.17s/trial, best loss: -0.7953683733940125]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "15               16        224.0       0.000514      0.4  18.761901   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "15             NaN  1952.988614  48.559091  0.795368     733.145327  \n",
            "Traitement de la série bootstrap 17...\n",
            "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 186ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step         \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
            "\n",
            "100%|██████████| 10/10 [20:31<00:00, 123.17s/trial, best loss: -0.7985103130340576]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "15               16        224.0       0.000514      0.4  18.761901   \n",
            "16               17         96.0       0.001257      0.2  18.617308   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "15             NaN  1952.988614  48.559091  0.795368     733.145327  \n",
            "16             NaN  1607.899657  41.553371  0.798510    1233.207400  \n",
            "Traitement de la série bootstrap 18...\n",
            "(51567, 40, 17) (51567, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 181ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [11:42<00:00, 70.25s/trial, best loss: -0.7948992252349854]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "15               16        224.0       0.000514      0.4  18.761901   \n",
            "16               17         96.0       0.001257      0.2  18.617308   \n",
            "17               18        128.0       0.003633      0.3  18.783396   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "15             NaN  1952.988614  48.559091  0.795368     733.145327  \n",
            "16             NaN  1607.899657  41.553371  0.798510    1233.207400  \n",
            "17             NaN  1810.533359  42.500987  0.794899     703.627050  \n",
            "Traitement de la série bootstrap 19...\n",
            "(51617, 40, 17) (51617, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 158ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 186ms/step         \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [14:06<00:00, 84.65s/trial, best loss: -0.7750187516212463]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "15               16        224.0       0.000514      0.4  18.761901   \n",
            "16               17         96.0       0.001257      0.2  18.617308   \n",
            "17               18        128.0       0.003633      0.3  18.783396   \n",
            "18               19         64.0       0.000481      0.5  19.672685   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "15             NaN  1952.988614  48.559091  0.795368     733.145327  \n",
            "16             NaN  1607.899657  41.553371  0.798510    1233.207400  \n",
            "17             NaN  1810.533359  42.500987  0.794899     703.627050  \n",
            "18             NaN  1689.625888  46.753516  0.775019     847.826083  \n",
            "Traitement de la série bootstrap 20...\n",
            "(51543, 40, 17) (51543, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 151ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [09:48<00:00, 58.83s/trial, best loss: -0.8233584761619568]\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        160.0       0.000396      0.3  18.527919   \n",
            "1                 2        128.0       0.000835      0.4  18.642016   \n",
            "2                 3         96.0       0.000420      0.2  19.346731   \n",
            "3                 4        224.0       0.000918      0.1  20.397235   \n",
            "4                 5         96.0       0.000944      0.3  18.941525   \n",
            "5                 6         96.0       0.001927      0.4  18.158701   \n",
            "6                 7         96.0       0.004411      0.5  18.543686   \n",
            "7                 8        224.0       0.000653      0.3  18.906892   \n",
            "8                 9        160.0       0.003190      0.3  18.269195   \n",
            "9                10         96.0       0.004641      0.5  19.672922   \n",
            "10               11        160.0       0.003450      0.4  17.993084   \n",
            "11               12        160.0       0.007529      0.3  19.242010   \n",
            "12               13        160.0       0.000247      0.3  19.533613   \n",
            "13               14        128.0       0.000250      0.1  17.847952   \n",
            "14               15         64.0       0.002869      0.2  18.410482   \n",
            "15               16        224.0       0.000514      0.4  18.761901   \n",
            "16               17         96.0       0.001257      0.2  18.617308   \n",
            "17               18        128.0       0.003633      0.3  18.783396   \n",
            "18               19         64.0       0.000481      0.5  19.672685   \n",
            "19               20        224.0       0.000552      0.2  17.431585   \n",
            "\n",
            "   r2training_time      s_score       mape        r2  training_time  \n",
            "0              NaN  1962.892570  43.781214  0.800441     891.514543  \n",
            "1              NaN  1822.795435  44.288784  0.797975     675.666551  \n",
            "2              NaN  2032.096772  50.713957  0.782412     736.572289  \n",
            "3              NaN  6920.693869  40.904931  0.758141     714.113007  \n",
            "4              NaN  1476.992674  38.964574  0.791431     962.748813  \n",
            "5              NaN  1673.037627  42.411705  0.808315     684.554340  \n",
            "6              NaN  2357.414327  46.657706  0.800101     538.856694  \n",
            "7              NaN  1836.452726  49.302454  0.792193     924.694279  \n",
            "8              NaN  1412.305895  38.293512  0.805975     886.424855  \n",
            "9              NaN  2153.184751  50.382758  0.775013     871.184579  \n",
            "10             NaN  1894.065886  35.141456  0.811795     779.004656  \n",
            "11             NaN  1879.193360  40.606120  0.784761     897.958482  \n",
            "12             NaN  2791.608065  48.712050  0.778188     787.298173  \n",
            "13             NaN  1732.066666  40.676386  0.814819     774.155303  \n",
            "14             NaN  1925.169483  36.614553  0.802962     647.879222  \n",
            "15             NaN  1952.988614  48.559091  0.795368     733.145327  \n",
            "16             NaN  1607.899657  41.553371  0.798510    1233.207400  \n",
            "17             NaN  1810.533359  42.500987  0.794899     703.627050  \n",
            "18             NaN  1689.625888  46.753516  0.775019     847.826083  \n",
            "19             NaN  1600.016841  35.140351  0.823358     589.365115  \n"
          ]
        }
      ],
      "source": [
        "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 20)\n",
        "results_all = pd.DataFrame(columns=['bootstrap_series', 'hidden_size', 'learning_rate', 'dropout', 'rmse', 'r2' 'training_time'])\n",
        "for i, series in enumerate(bootstrap_series_list):\n",
        "    print(f\"Traitement de la série bootstrap {i + 1}...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "    space = {\n",
        "        'hidden_size': hp.quniform('hidden_size',\n",
        "                              space_val['hidden_size']['min'],\n",
        "                              space_val['hidden_size']['max'],\n",
        "                              space_val['hidden_size']['step']),\n",
        "\n",
        "        'learning_rate': hp.loguniform('learning_rate',\n",
        "                                    space_val['learning_rate']['min'],\n",
        "                                    space_val['learning_rate']['max']),\n",
        "\n",
        "        'dropout': hp.quniform('dropout',\n",
        "                              space_val['dropout']['min'],\n",
        "                              space_val['dropout']['max'],\n",
        "                              space_val['dropout']['step'])\n",
        "    }\n",
        "\n",
        "    series = pd.DataFrame(series, columns=train.columns)\n",
        "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
        "\n",
        "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
        "\n",
        "    # create sequences train, test\n",
        "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
        "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
        "\n",
        "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n",
        "                for unit_nr in X_test_interim['Unit'].unique())\n",
        "\n",
        "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
        "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
        "    print(train_array.shape, label_array.shape, test_array.shape)\n",
        "\n",
        "    # Optimisation bayésienne avec Hyperopt\n",
        "    trials = Trials()\n",
        "    best = fmin(\n",
        "        fn=train_model,\n",
        "        space=space,\n",
        "        algo=tpe.suggest,\n",
        "        max_evals=10, # a voir pour le questionnement genane\n",
        "        trials=trials\n",
        "    )\n",
        "\n",
        "    best_rmse = trials.best_trial['result']['rmse']\n",
        "    best_s_score = trials.best_trial['result']['s_score']\n",
        "    best_mape = trials.best_trial['result']['mape']\n",
        "    best_r2 = trials.best_trial['result']['loss']\n",
        "\n",
        "\n",
        "    time_training = time.time() - start_time\n",
        "    #Sauvegarder les résultats dans un DataFrame\n",
        "\n",
        "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
        "      'bootstrap_series': i + 1,\n",
        "      'hidden_size': best['hidden_size'],\n",
        "      'learning_rate': best['learning_rate'],\n",
        "      'dropout': best['dropout'],\n",
        "      'rmse': best_rmse,\n",
        "      's_score': best_s_score,\n",
        "      'mape': best_mape,\n",
        "      'r2': -best_r2,\n",
        "      'training_time': time_training\n",
        "  }])], ignore_index=True)\n",
        "    print(results_all)\n",
        "\n",
        "  # Sauvegarder les résultats dans un fichier CSV après chaque itération\n",
        "    results_all.to_csv(path_bootstrap, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb-N_tnveCiW"
      },
      "source": [
        "# Intervalle de confiance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llmldvM9GzOr"
      },
      "outputs": [],
      "source": [
        "def intervalle_confiance(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Calculer la moyenne et l'écart type de la colonne 'rmse'\n",
        "    mean_rmse = df['rmse'].mean()\n",
        "    std_rmse = df['rmse'].std()\n",
        "\n",
        "    filtered_df = df[(df['rmse'] >= mean_rmse - std_rmse) & (df['rmse'] <= mean_rmse + std_rmse)]\n",
        "\n",
        "    dropout_rates = filtered_df['dropout'].tolist()\n",
        "    learning_rates = filtered_df['learning_rate'].tolist()\n",
        "    neurons_list = filtered_df['hidden_size'].tolist()\n",
        "\n",
        "    #remove duplicate values and sort list\n",
        "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
        "    learning_final = sorted(set(learning_rates), reverse=True)\n",
        "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
        "\n",
        "    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n",
        "    return dropout_final, learning_final, neurons_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71CHXx5siROg"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yODLXZzQiPlt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search space 260\n",
            "Training with LSTM units=224.0, learning_rate=0.0075, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Validation RMSE: 14.8671\n",
            "Training with LSTM units=224.0, learning_rate=0.0075, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Validation RMSE: 17.5269\n",
            "Training with LSTM units=224.0, learning_rate=0.0075, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 16.4335\n",
            "Training with LSTM units=224.0, learning_rate=0.0075, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 19.2701\n",
            "Training with LSTM units=224.0, learning_rate=0.0044, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 12.7759\n",
            "Training with LSTM units=224.0, learning_rate=0.0044, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Validation RMSE: 13.2605\n",
            "Training with LSTM units=224.0, learning_rate=0.0044, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Validation RMSE: 15.4133\n",
            "Training with LSTM units=224.0, learning_rate=0.0044, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Validation RMSE: 12.6809\n",
            "Training with LSTM units=224.0, learning_rate=0.0036, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Validation RMSE: 25.1679\n",
            "Training with LSTM units=224.0, learning_rate=0.0036, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Validation RMSE: 31.3692\n",
            "Training with LSTM units=224.0, learning_rate=0.0036, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 14.4457\n",
            "Training with LSTM units=224.0, learning_rate=0.0036, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 24.0567\n",
            "Training with LSTM units=224.0, learning_rate=0.0032, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 18.3642\n",
            "Training with LSTM units=224.0, learning_rate=0.0032, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 25.1749\n",
            "Training with LSTM units=224.0, learning_rate=0.0032, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 14.4232\n",
            "Training with LSTM units=224.0, learning_rate=0.0032, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 19.4522\n",
            "Training with LSTM units=224.0, learning_rate=0.0029, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 13.9551\n",
            "Training with LSTM units=224.0, learning_rate=0.0029, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 23.3659\n",
            "Training with LSTM units=224.0, learning_rate=0.0029, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 13.5943\n",
            "Training with LSTM units=224.0, learning_rate=0.0029, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.0168\n",
            "Training with LSTM units=224.0, learning_rate=0.0019, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 24.0077\n",
            "Training with LSTM units=224.0, learning_rate=0.0019, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 22.3047\n",
            "Training with LSTM units=224.0, learning_rate=0.0019, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 16.3528\n",
            "Training with LSTM units=224.0, learning_rate=0.0019, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 14.3751\n",
            "Training with LSTM units=224.0, learning_rate=0.0013, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 13.5516\n",
            "Training with LSTM units=224.0, learning_rate=0.0013, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 22.9459\n",
            "Training with LSTM units=224.0, learning_rate=0.0013, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 12.7259\n",
            "Training with LSTM units=224.0, learning_rate=0.0013, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 13.8939\n",
            "Training with LSTM units=224.0, learning_rate=0.0009, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 23.7257\n",
            "Training with LSTM units=224.0, learning_rate=0.0009, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 24.4124\n",
            "Training with LSTM units=224.0, learning_rate=0.0009, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.4733\n",
            "Training with LSTM units=224.0, learning_rate=0.0009, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.5309\n",
            "Training with LSTM units=224.0, learning_rate=0.0008, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 13.9824\n",
            "Training with LSTM units=224.0, learning_rate=0.0008, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.5349\n",
            "Training with LSTM units=224.0, learning_rate=0.0008, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 16.0390\n",
            "Training with LSTM units=224.0, learning_rate=0.0008, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 19.1201\n",
            "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 20.7180\n",
            "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 17.8291\n",
            "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.7300\n",
            "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 17.2988\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 20.3772\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 22.7328\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 26.3113\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 24.9044\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 38.1739\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 28.2375\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 34.6434\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 43.4371\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 12.9923\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 20.0678\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 43.8258\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 23.2951\n",
            "Training with LSTM units=160.0, learning_rate=0.0075, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 13.9972\n",
            "Training with LSTM units=160.0, learning_rate=0.0075, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 15.3953\n",
            "Training with LSTM units=160.0, learning_rate=0.0075, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 16.7946\n",
            "Training with LSTM units=160.0, learning_rate=0.0075, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 15.9486\n",
            "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 23.6931\n",
            "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 15.2491\n",
            "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 22.8809\n",
            "Training with LSTM units=160.0, learning_rate=0.0044, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 15.7659\n",
            "Training with LSTM units=160.0, learning_rate=0.0036, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 12.8782\n",
            "Training with LSTM units=160.0, learning_rate=0.0036, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 13.8656\n",
            "Training with LSTM units=160.0, learning_rate=0.0036, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 18.9454\n",
            "Training with LSTM units=160.0, learning_rate=0.0036, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 14.1037\n",
            "Training with LSTM units=160.0, learning_rate=0.0032, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 12.9387\n",
            "Training with LSTM units=160.0, learning_rate=0.0032, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 25.7992\n",
            "Training with LSTM units=160.0, learning_rate=0.0032, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 23.9670\n",
            "Training with LSTM units=160.0, learning_rate=0.0032, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 12.6428\n",
            "Training with LSTM units=160.0, learning_rate=0.0029, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 13.0831\n",
            "Training with LSTM units=160.0, learning_rate=0.0029, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 13.3059\n",
            "Training with LSTM units=160.0, learning_rate=0.0029, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 12.9764\n",
            "Training with LSTM units=160.0, learning_rate=0.0029, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 16.7149\n",
            "Training with LSTM units=160.0, learning_rate=0.0019, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 21.9477\n",
            "Training with LSTM units=160.0, learning_rate=0.0019, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 12.3286\n",
            "Training with LSTM units=160.0, learning_rate=0.0019, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 25.7307\n",
            "Training with LSTM units=160.0, learning_rate=0.0019, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 12.9629\n",
            "Training with LSTM units=160.0, learning_rate=0.0013, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 19.9514\n",
            "Training with LSTM units=160.0, learning_rate=0.0013, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 23.8737\n",
            "Training with LSTM units=160.0, learning_rate=0.0013, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 23.1323\n",
            "Training with LSTM units=160.0, learning_rate=0.0013, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 18.2949\n",
            "Training with LSTM units=160.0, learning_rate=0.0009, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 17.6002\n",
            "Training with LSTM units=160.0, learning_rate=0.0009, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 17.8754\n",
            "Training with LSTM units=160.0, learning_rate=0.0009, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 17.3213\n",
            "Training with LSTM units=160.0, learning_rate=0.0009, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 17.7000\n",
            "Training with LSTM units=160.0, learning_rate=0.0008, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 18.1622\n",
            "Training with LSTM units=160.0, learning_rate=0.0008, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 18.2151\n",
            "Training with LSTM units=160.0, learning_rate=0.0008, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 16.3444\n",
            "Training with LSTM units=160.0, learning_rate=0.0008, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 15.6302\n",
            "Training with LSTM units=160.0, learning_rate=0.0007, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 22.7863\n",
            "Training with LSTM units=160.0, learning_rate=0.0007, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 18.9440\n",
            "Training with LSTM units=160.0, learning_rate=0.0007, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.1396\n",
            "Training with LSTM units=160.0, learning_rate=0.0007, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 20.7929\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 16.1471\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.3448\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 19.0269\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 12.9569\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 15.0017\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.9636\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.2163\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.0762\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.4007\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 13.7792\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 23.2213\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 15.9609\n",
            "Training with LSTM units=128.0, learning_rate=0.0075, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 13.3188\n",
            "Training with LSTM units=128.0, learning_rate=0.0075, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 16.6423\n",
            "Training with LSTM units=128.0, learning_rate=0.0075, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 29.2292\n",
            "Training with LSTM units=128.0, learning_rate=0.0075, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 12.6092\n",
            "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 23.5783\n",
            "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 24.2945\n",
            "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 19.8328\n",
            "Training with LSTM units=128.0, learning_rate=0.0044, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 20.7019\n",
            "Training with LSTM units=128.0, learning_rate=0.0036, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 13.5393\n",
            "Training with LSTM units=128.0, learning_rate=0.0036, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 12.8223\n",
            "Training with LSTM units=128.0, learning_rate=0.0036, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 21.1843\n",
            "Training with LSTM units=128.0, learning_rate=0.0036, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 15.9879\n",
            "Training with LSTM units=128.0, learning_rate=0.0032, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 22.9711\n",
            "Training with LSTM units=128.0, learning_rate=0.0032, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 15.1859\n",
            "Training with LSTM units=128.0, learning_rate=0.0032, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 24.0079\n",
            "Training with LSTM units=128.0, learning_rate=0.0032, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.3985\n",
            "Training with LSTM units=128.0, learning_rate=0.0029, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 14.1544\n",
            "Training with LSTM units=128.0, learning_rate=0.0029, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 17.2033\n",
            "Training with LSTM units=128.0, learning_rate=0.0029, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 15.0481\n",
            "Training with LSTM units=128.0, learning_rate=0.0029, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 12.8081\n",
            "Training with LSTM units=128.0, learning_rate=0.0019, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.5378\n",
            "Training with LSTM units=128.0, learning_rate=0.0019, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 13.6338\n",
            "Training with LSTM units=128.0, learning_rate=0.0019, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 24.7030\n",
            "Training with LSTM units=128.0, learning_rate=0.0019, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 12.6787\n",
            "Training with LSTM units=128.0, learning_rate=0.0013, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 13.7904\n",
            "Training with LSTM units=128.0, learning_rate=0.0013, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 22.9426\n",
            "Training with LSTM units=128.0, learning_rate=0.0013, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 21.3983\n",
            "Training with LSTM units=128.0, learning_rate=0.0013, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 15.2746\n",
            "Training with LSTM units=128.0, learning_rate=0.0009, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 21.3986\n",
            "Training with LSTM units=128.0, learning_rate=0.0009, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 20.1145\n",
            "Training with LSTM units=128.0, learning_rate=0.0009, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 23.7585\n",
            "Training with LSTM units=128.0, learning_rate=0.0009, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 16.8799\n",
            "Training with LSTM units=128.0, learning_rate=0.0008, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 19.6133\n",
            "Training with LSTM units=128.0, learning_rate=0.0008, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 20.0789\n",
            "Training with LSTM units=128.0, learning_rate=0.0008, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 22.4554\n",
            "Training with LSTM units=128.0, learning_rate=0.0008, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 15.4634\n",
            "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 15.0823\n",
            "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 13.3524\n",
            "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 12.7507\n",
            "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.3648\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 13.5634\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.4302\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 17.2906\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 13.9515\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 16.8646\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.2039\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 14.1733\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 14.7022\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 15.9848\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 16.4226\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 15.2253\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 14.2154\n",
            "Training with LSTM units=96.0, learning_rate=0.0075, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 12.7617\n",
            "Training with LSTM units=96.0, learning_rate=0.0075, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 17.8340\n",
            "Training with LSTM units=96.0, learning_rate=0.0075, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 23.3841\n",
            "Training with LSTM units=96.0, learning_rate=0.0075, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 22.8888\n",
            "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 13.3855\n",
            "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 13.9746\n",
            "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 12.7750\n",
            "Training with LSTM units=96.0, learning_rate=0.0044, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 14.1673\n",
            "Training with LSTM units=96.0, learning_rate=0.0036, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 14.6265\n",
            "Training with LSTM units=96.0, learning_rate=0.0036, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 12.5872\n",
            "Training with LSTM units=96.0, learning_rate=0.0036, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 12.9969\n",
            "Training with LSTM units=96.0, learning_rate=0.0036, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 12.9565\n",
            "Training with LSTM units=96.0, learning_rate=0.0032, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 12.7525\n",
            "Training with LSTM units=96.0, learning_rate=0.0032, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 12.9302\n",
            "Training with LSTM units=96.0, learning_rate=0.0032, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 15.2711\n",
            "Training with LSTM units=96.0, learning_rate=0.0032, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 15.2236\n",
            "Training with LSTM units=96.0, learning_rate=0.0029, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Validation RMSE: 16.2973\n",
            "Training with LSTM units=96.0, learning_rate=0.0029, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 14.0013\n",
            "Training with LSTM units=96.0, learning_rate=0.0029, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 13.7602\n",
            "Training with LSTM units=96.0, learning_rate=0.0029, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 15.2869\n",
            "Training with LSTM units=96.0, learning_rate=0.0019, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 20.2341\n",
            "Training with LSTM units=96.0, learning_rate=0.0019, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 12.6039\n",
            "Training with LSTM units=96.0, learning_rate=0.0019, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 13.1048\n",
            "Training with LSTM units=96.0, learning_rate=0.0019, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Validation RMSE: 15.5297\n",
            "Training with LSTM units=96.0, learning_rate=0.0013, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Validation RMSE: 16.4293\n",
            "Training with LSTM units=96.0, learning_rate=0.0013, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Validation RMSE: 15.3487\n",
            "Training with LSTM units=96.0, learning_rate=0.0013, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 13.4652\n",
            "Training with LSTM units=96.0, learning_rate=0.0013, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 13.4860\n",
            "Training with LSTM units=96.0, learning_rate=0.0009, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 13.4162\n",
            "Training with LSTM units=96.0, learning_rate=0.0009, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 20.4421\n",
            "Training with LSTM units=96.0, learning_rate=0.0009, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 13.0537\n",
            "Training with LSTM units=96.0, learning_rate=0.0009, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 12.8261\n",
            "Training with LSTM units=96.0, learning_rate=0.0008, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 13.5425\n",
            "Training with LSTM units=96.0, learning_rate=0.0008, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 13.8453\n",
            "Training with LSTM units=96.0, learning_rate=0.0008, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 15.6788\n",
            "Training with LSTM units=96.0, learning_rate=0.0008, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Validation RMSE: 13.9473\n",
            "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 15.5246\n",
            "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 13.6460\n",
            "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 13.6350\n",
            "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Validation RMSE: 14.9499\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 13.8104\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "Validation RMSE: 13.9884\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 15.2598\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.2\n"
          ]
        }
      ],
      "source": [
        "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dense(1))  # Sortie pour la régression\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "dropout, learning_rate, hidden_size = intervalle_confiance(path_bootstrap)\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'hidden_size': hidden_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'dropout': dropout\n",
        "}\n",
        "\n",
        "#Sauvegarder les résultats dans un DataFrame\n",
        "results_all = pd.DataFrame()\n",
        "i=0\n",
        "\n",
        "for hidden_size in param_grid['hidden_size']:\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for dropout in param_grid['dropout']:\n",
        "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Build the LSTM model\n",
        "            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(\n",
        "                train_array, label_array,\n",
        "                validation_data=(test_array, test_rul),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                verbose=0\n",
        "            )\n",
        "            # Evaluate the model on the validation set\n",
        "            y_pred = model.predict(test_array)\n",
        "            # Calcul de la RMSE\n",
        "            rmse = root_mean_squared_error(test_rul, y_pred)\n",
        "            s_score = compute_s_score(test_rul, y_pred)\n",
        "            mape = compute_MAPE(test_rul, y_pred)\n",
        "            r2 = r2_score(test_rul, y_pred)\n",
        "\n",
        "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "            time_training = time.time() - start_time\n",
        "            i+=1\n",
        "            #Sauvegarder les résultats dans un DataFrame\n",
        "\n",
        "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
        "                'bootstrap_series': i,\n",
        "                'hidden_size': hidden_size,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dropout': dropout,\n",
        "                'rmse': rmse,\n",
        "                's_score': s_score,\n",
        "                'mape': mape,\n",
        "                'r2': r2,\n",
        "                'training_time': time_training\n",
        "            }])], ignore_index=True)\n",
        "\n",
        "            results_all.to_csv(path_grid, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1qzNWs_zEhJG",
        "w3R-Zqn8b7-s",
        "3reK6P4D-4XM",
        "6XjaNrNBnLtk",
        "LzO_WAqMXrHk",
        "YPEaXloQYQXC",
        "bb-N_tnveCiW"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
