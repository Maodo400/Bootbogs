{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qzNWs_zEhJG"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Importations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MuCQx7XbGnf_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# Standard libraries\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import warnings\n",
        "from math import sqrt, pow\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
        "import keras\n",
        "from keras import backend as K\n",
        "\n",
        "# Optimization\n",
        "from scipy import optimize\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SEED = 0\n",
        "def set_seed(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    tf.random.set_seed(SEED)\n",
        "\n",
        "# Appeler la fonction pour fixer le seed\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3R-Zqn8b7-s"
      },
      "source": [
        "# Methode.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_gfR4rmnddop"
      },
      "outputs": [],
      "source": [
        "# read the train and test data\n",
        "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
        "    if drop:\n",
        "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
        "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
        "    else:\n",
        "        X_train_interim = add_operating_condition(train)\n",
        "        X_test_interim = add_operating_condition(test)\n",
        "\n",
        "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
        "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
        "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
        "\n",
        "    return X_train_interim, X_test_interim\n",
        "\n",
        "def rul_piecewise_fct(X_train, rul):\n",
        "\n",
        "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
        "\n",
        "    return X_train\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    dir_path = 'C:/Users/RA-RV/Documents/Malick/data/'\n",
        "    dependent_var = ['RUL']\n",
        "    index_names = ['Unit', 'Cycle']\n",
        "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
        "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
        "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
        "    col_names = index_names + setting_names + sensor_names\n",
        "\n",
        "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
        "\n",
        "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
        "    rul_train.columns = ['Unit', 'max']\n",
        "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
        "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
        "    df_train.drop('max', axis=1, inplace=True)\n",
        "\n",
        "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
        "\n",
        "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
        "    #y_true[\"Unit\"] = y_true.index + 1\n",
        "    return df_train, df_test, y_test\n",
        "\n",
        "\n",
        "# add operational condition to then normalize the data based on these operational conditions test\n",
        "def add_operating_condition(df):\n",
        "    df_op_cond = df.copy()\n",
        "\n",
        "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
        "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
        "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
        "\n",
        "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
        "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
        "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
        "                        df_op_cond['TRA'].astype(str)\n",
        "\n",
        "    return df_op_cond\n",
        "\n",
        "# normalize the data based on the operational condition\n",
        "def condition_scaler(df_train, df_test, sensor_names):\n",
        "  # apply operating condition specific scaling\n",
        "  #scaler = StandardScaler()\n",
        "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "    for condition in df_train['op_cond'].unique():\n",
        "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
        "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
        "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
        "    return df_train, df_test\n",
        "\n",
        "\n",
        "#to plot each sensors with respect to the RUL\n",
        "def plot_signal(df, signal_name, unit=None):\n",
        "#     train = df\n",
        "    plt.figure(figsize=(13,5))\n",
        "    if unit:\n",
        "        plt.plot('RUL', signal_name,\n",
        "                data=df[df['Unit']==unit])\n",
        "    else:\n",
        "        for i in df['Unit'].unique():\n",
        "            if (i % 10 == 0):  # only ploting every 10th unit_nr\n",
        "                plt.plot('RUL', signal_name,\n",
        "                         data=df[df['Unit']==i])\n",
        "    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n",
        "    plt.xticks(np.arange(0, 375, 25))\n",
        "    plt.ylabel(signal_name)\n",
        "    plt.xlabel('Remaining Use fulLife')\n",
        "    #plt.savefig(signal_name+'.jpeg')\n",
        "    plt.show()\n",
        "\n",
        "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
        "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
        "    df = df.copy()\n",
        "    # first, calculate the exponential weighted mean of desired sensors\n",
        "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
        "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
        "\n",
        "\n",
        "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
        "    def create_mask(data, samples):\n",
        "        result = np.ones_like(data)\n",
        "        result[0:samples] = 0\n",
        "        return result\n",
        "\n",
        "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
        "    df = df[mask]\n",
        "\n",
        "    return df\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
        "\n",
        "#the score defined in the paper\n",
        "def compute_s_score(rul_true, rul_pred):\n",
        "    diff = rul_pred - rul_true\n",
        "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
        "\n",
        "#evaluate the model with R² and RMSE\n",
        "def evaluate(y_true, y_hat, label='test'):\n",
        "    mse = mean_squared_error(y_true, y_hat)\n",
        "    rmse = np.sqrt(mse)\n",
        "    variance = r2_score(y_true, y_hat)\n",
        "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
        "\n",
        "def generate_sequences(data, sequence_length):\n",
        "    \"\"\"\n",
        "    Generate sequences of a given length from the input data.\n",
        "    \"\"\"\n",
        "    num_samples = data.shape[0]\n",
        "\n",
        "    # Generate sequences using sliding windows\n",
        "    for start_idx in range(num_samples - sequence_length + 1):\n",
        "        end_idx = start_idx + sequence_length\n",
        "        yield data[start_idx:end_idx, :]\n",
        "\n",
        "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
        "    \"\"\"\n",
        "    Wrapper function to generate sequences for multiple units in the dataset.\n",
        "    \"\"\"\n",
        "    if unit_nrs is None:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    # Generate sequences for each unit and concatenate them\n",
        "    all_sequences = []\n",
        "    for unit_nr in unit_nrs:\n",
        "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
        "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
        "        all_sequences.extend(sequences)\n",
        "\n",
        "    return np.array(all_sequences, dtype=np.float32)\n",
        "\n",
        "\n",
        "def gen_train_data(df, sequence_length, columns):\n",
        "    data = df[columns].values\n",
        "    num_elements = data.shape[0]\n",
        "\n",
        "    # -1 and +1 because of Python indexing\n",
        "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
        "        yield data[start:stop, :]\n",
        "\n",
        "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
        "    if unit_nrs.size <= 0:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
        "               for unit_nr in unit_nrs)\n",
        "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
        "    return data_array\n",
        "\n",
        "def create_model(TW , remaining_):\n",
        "#     history = History()\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "    return model\n",
        "\n",
        "def compute_MAPE(y_true, y_hat):\n",
        "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
        "    return mape\n",
        "\n",
        "def gen_labels(df, sequence_length, label):\n",
        "    data_matrix = df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "\n",
        "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
        "    return data_matrix[sequence_length-1:num_elements, :]\n",
        "\n",
        "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
        "    if unit_nrs.size <= 0:\n",
        "        unit_nrs = df['Unit'].unique()\n",
        "\n",
        "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
        "                for unit_nr in unit_nrs]\n",
        "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "    return label_array\n",
        "def gen_test_data(df, sequence_length, columns, mask_value):\n",
        "    if df.shape[0] < sequence_length:\n",
        "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
        "        idx = data_matrix.shape[0] - df.shape[0]\n",
        "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
        "    else:\n",
        "        data_matrix = df[columns].values\n",
        "\n",
        "    # specifically yield the last possible sequence\n",
        "    stop = num_elements = data_matrix.shape[0]\n",
        "    start = stop - sequence_length\n",
        "    for i in list(range(1)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "def plot_loss(fit_history):\n",
        "    plt.figure(figsize=(13,5))\n",
        "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
        "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def new_column (df, column):\n",
        "    #df = df.sort_values(by=column, ascending=False)\n",
        "    df[column] = range(1, len(df) + 1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3reK6P4D-4XM"
      },
      "source": [
        "# Préparation des données et configuration initiale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQiI0neXGngG",
        "outputId": "2b878fa3-e75f-45ee-bd1d-8cc6206b3b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(61249, 27) (41214, 26) (248, 1)\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
          ]
        }
      ],
      "source": [
        "train, test, y_test = prepare_data('FD004.txt')\n",
        "print(train.shape, test.shape, y_test.shape)\n",
        "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
        "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
        "\n",
        "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
        "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
        "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
        "\n",
        "rul_piecewise = 130\n",
        "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
        "\n",
        "# Configuration des paramètres\n",
        "alpha = 0.2\n",
        "sequence_length = 40\n",
        "epochs = 20\n",
        "#nodes_per_layer = [64]\n",
        "#dropout = 0.2\n",
        "activation = 'tanh'\n",
        "batch_size = 32\n",
        "remaining_sensors = remaining_sensors\n",
        "input_shape = (sequence_length, len(remaining_sensors))\n",
        "\n",
        "space_val = {\n",
        "    'hidden_size': {\n",
        "        'min': 32,\n",
        "        'max': 256,\n",
        "        'step': 32\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'min': np.log(1e-5),\n",
        "        'max': np.log(1e-2)\n",
        "    },\n",
        "    'dropout': {\n",
        "        'min': 0.1,\n",
        "        'max': 0.5,\n",
        "        'step': 0.1\n",
        "    }\n",
        "}\n",
        "\n",
        "# Préparation des données\n",
        "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
        "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
        "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
        "\n",
        "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
        "               for unit_nr in X_test_interim['Unit'].unique())\n",
        "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
        "\n",
        "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
        "print(train_array.shape, label_array.shape, test_array.shape)\n",
        "\n",
        "path_bootstrap = 'C:/Users/RA-RV/Documents/Malick/data/fd004_bootstrap_opt_rmse_LR_N_Arr.csv'\n",
        "path_grid = 'C:/Users/RA-RV/Documents/Malick/data/fd004_grid_search_bootstrap_opt_rmse_LR_N_Arr.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yC6kum8dWzB"
      },
      "source": [
        "# Bayesian optimization avec bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XjaNrNBnLtk"
      },
      "source": [
        "## Creer n series bootstrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8y_6F-lTnTA5"
      },
      "outputs": [],
      "source": [
        "def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n",
        "\n",
        "    n_timesteps = len(data)\n",
        "    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n",
        "    bootstrap_series_list = []\n",
        "\n",
        "    # Découper la série en blocs\n",
        "    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n",
        "\n",
        "    # Créer chaque série bootstrap\n",
        "    for _ in range(n_bootstrap):\n",
        "        # Rééchantillonner les blocs avec remise\n",
        "        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n",
        "\n",
        "        # Concaténer les blocs pour former une nouvelle série\n",
        "        new_series = np.concatenate(sampled_blocks, axis=0)\n",
        "\n",
        "        if len(new_series) > n_timesteps:\n",
        "            new_series = new_series[:n_timesteps]\n",
        "\n",
        "        elif len(new_series) < n_timesteps:\n",
        "          remaining_length = n_timesteps - len(new_series)\n",
        "          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n",
        "\n",
        "        bootstrap_series_list.append(new_series)\n",
        "\n",
        "    return bootstrap_series_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzO_WAqMXrHk"
      },
      "source": [
        "## Creation et entrainement du modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KdXdtod0er4D"
      },
      "outputs": [],
      "source": [
        "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
        "    model.add(Dropout(dropout))\n",
        "    #model.add(Dense(256))\n",
        "    model.add(Dense(1))  # Sortie pour la régression\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
        "def train_model(params):\n",
        "    # Création du modèle\n",
        "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, params['learning_rate'])\n",
        "\n",
        "    # Entraînement du modèle\n",
        "    history = model.fit(\n",
        "        train_array, label_array,\n",
        "        validation_data=(test_array, test_rul),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        verbose=0  # Désactiver les logs pour une sortie propre\n",
        "    )\n",
        "\n",
        "    # Prédiction sur l'ensemble de validation\n",
        "    y_pred = model.predict(test_array)\n",
        "\n",
        "    # Calcul de la RMSE, S-Score, Mape\n",
        "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
        "    s_score = compute_s_score(test_rul, y_pred)\n",
        "    mape = compute_MAPE(test_rul, y_pred)\n",
        "    r2 = r2_score(test_rul, y_pred)\n",
        "\n",
        "  # maximiser accuracy\n",
        "\n",
        "    # Retourner la RMSE comme métrique à minimiser\n",
        "    return {'loss': rmse, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEaXloQYQXC"
      },
      "source": [
        "## Apply HyperOpt TPE and store the combination of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmtmfU5JPTmh",
        "outputId": "159e0fce-dfb5-4f57-f10b-7b0a90acbdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traitement de la série bootstrap 1...\n",
            "(51545, 40, 17) (51545, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 483ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step         \n",
            "\n",
            " 20%|██        | 2/10 [13:05<53:28, 401.10s/trial, best loss: 20.84398791679247]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028C05FFB7E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 395ms/step        \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step         \n",
            "\n",
            " 30%|███       | 3/10 [30:24<1:20:45, 692.22s/trial, best loss: 20.84398791679247]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028C086937E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 539ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 458ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 580ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 921ms/step        \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 562ms/step          \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 311ms/step          \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 318ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step            \n",
            "\n",
            "100%|██████████| 10/10 [2:07:43<00:00, 766.37s/trial, best loss: 19.43615286228058]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout     rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.1926   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "Traitement de la série bootstrap 2...\n",
            "(51552, 40, 17) (51552, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 718ms/step\n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 372ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 278ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 317ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 156ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step             \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 292ms/step             \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step              \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 253ms/step             \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 575ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 724ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 833ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [2:02:35<00:00, 735.59s/trial, best loss: 19.755757325644737]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "Traitement de la série bootstrap 3...\n",
            "(51589, 40, 17) (51589, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 275ms/step\n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 314ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 501ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 346ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 333ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 990ms/step          \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step         \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 202ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 482ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step           \n",
            "\n",
            "100%|██████████| 10/10 [1:57:17<00:00, 703.73s/trial, best loss: 20.66522917311453]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "Traitement de la série bootstrap 4...\n",
            "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 291ms/step\n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 277ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step             \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 236ms/step            \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 459ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 262ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 314ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 173ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 301ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step            \n",
            "\n",
            "100%|██████████| 10/10 [1:52:13<00:00, 673.37s/trial, best loss: 19.726347461699227]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "Traitement de la série bootstrap 5...\n",
            "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 617ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 444ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 470ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 519ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step       \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step        \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step        \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 418ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 307ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 302ms/step         \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 319ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [1:53:19<00:00, 679.95s/trial, best loss: 19.2850142256012]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "Traitement de la série bootstrap 6...\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 445ms/step\n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 294ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 937ms/step           \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 336ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 459ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 627ms/step             \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step              \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 441ms/step             \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 439ms/step            \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step             \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 305ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step             \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 525ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step            \n",
            "\n",
            "100%|██████████| 10/10 [2:22:18<00:00, 853.83s/trial, best loss: 19.664392285921508]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "5                 6        128.0       0.003949      0.3  20.543208   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "5  2610.895713  38.118621  0.785925    9136.194123  \n",
            "Traitement de la série bootstrap 7...\n",
            "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 274ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 316ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 441ms/step          \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 471ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 561ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step             \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 390ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 339ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 428ms/step            \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 464ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 196ms/step          \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 512ms/step          \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step           \n",
            "\n",
            "100%|██████████| 10/10 [2:04:57<00:00, 749.78s/trial, best loss: 20.13328163864539]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "5                 6        128.0       0.003949      0.3  20.543208   \n",
            "6                 7        160.0       0.002729      0.5  20.391612   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "5  2610.895713  38.118621  0.785925    9136.194123  \n",
            "6  2906.033928  42.336713  0.789073    8254.073181  \n",
            "Traitement de la série bootstrap 8...\n",
            "(51677, 40, 17) (51677, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 297ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 409ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 787ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 502ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 177ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 253ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 505ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 1s/step              \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step            \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 908ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [2:06:43<00:00, 760.40s/trial, best loss: 19.407059853774058]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "5                 6        128.0       0.003949      0.3  20.543208   \n",
            "6                 7        160.0       0.002729      0.5  20.391612   \n",
            "7                 8        160.0       0.000563      0.4  24.407704   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "5  2610.895713  38.118621  0.785925    9136.194123  \n",
            "6  2906.033928  42.336713  0.789073    8254.073181  \n",
            "7  6778.594762  38.719329  0.697808    8372.287093  \n",
            "Traitement de la série bootstrap 9...\n",
            "(51628, 40, 17) (51628, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 269ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 367ms/step         \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 814ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 520ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 325ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 384ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 770ms/step             \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step          \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 318ms/step           \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 280ms/step           \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 307ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step            \n",
            "\n",
            "100%|██████████| 10/10 [1:57:34<00:00, 705.43s/trial, best loss: 21.370335120080153]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "5                 6        128.0       0.003949      0.3  20.543208   \n",
            "6                 7        160.0       0.002729      0.5  20.391612   \n",
            "7                 8        160.0       0.000563      0.4  24.407704   \n",
            "8                 9        128.0       0.000284      0.3  21.109898   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "5  2610.895713  38.118621  0.785925    9136.194123  \n",
            "6  2906.033928  42.336713  0.789073    8254.073181  \n",
            "7  6778.594762  38.719329  0.697808    8372.287093  \n",
            "8  3562.401649  41.584770  0.773952    7599.927132  \n",
            "Traitement de la série bootstrap 10...\n",
            "(51564, 40, 17) (51564, 1) (248, 40, 17)\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 236ms/step\n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 480ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 366ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 272ms/step           \n",
            "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 808ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 287ms/step           \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step             \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step              \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step              \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 368ms/step             \n",
            "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 326ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step            \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 571ms/step           \n",
            "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
            "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step            \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step           \n",
            "\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 848ms/step           \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step          \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step          \n",
            "\n",
            "100%|██████████| 10/10 [1:58:50<00:00, 713.03s/trial, best loss: 21.906292489482688]\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
            "0                 1        224.0       0.000398      0.2  21.192600   \n",
            "1                 2        192.0       0.000418      0.5  20.281495   \n",
            "2                 3         96.0       0.000516      0.2  20.435456   \n",
            "3                 4         96.0       0.000442      0.4  22.935806   \n",
            "4                 5        192.0       0.000886      0.2  24.742518   \n",
            "5                 6        128.0       0.003949      0.3  20.543208   \n",
            "6                 7        160.0       0.002729      0.5  20.391612   \n",
            "7                 8        160.0       0.000563      0.4  24.407704   \n",
            "8                 9        128.0       0.000284      0.3  21.109898   \n",
            "9                10         96.0       0.000274      0.4  22.346662   \n",
            "\n",
            "       s_score       mape        r2  training_time  \n",
            "0  3227.866637  41.120556  0.772177    8585.960563  \n",
            "1  3187.505411  32.313974  0.791345    8177.158263  \n",
            "2  2467.523073  39.229689  0.788165    7616.412974  \n",
            "3  7114.442684  43.661527  0.733156    7222.857606  \n",
            "4  8668.226507  39.121250  0.689461    7691.773983  \n",
            "5  2610.895713  38.118621  0.785925    9136.194123  \n",
            "6  2906.033928  42.336713  0.789073    8254.073181  \n",
            "7  6778.594762  38.719329  0.697808    8372.287093  \n",
            "8  3562.401649  41.584770  0.773952    7599.927132  \n",
            "9  4634.856829  45.949671  0.746689    7750.200322  \n"
          ]
        }
      ],
      "source": [
        "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
        "results_all = pd.DataFrame()\n",
        "for i, series in enumerate(bootstrap_series_list):\n",
        "    print(f\"Traitement de la série bootstrap {i + 1}...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "    space = {\n",
        "        'hidden_size': hp.quniform('hidden_size',\n",
        "                              space_val['hidden_size']['min'],\n",
        "                              space_val['hidden_size']['max'],\n",
        "                              space_val['hidden_size']['step']),\n",
        "\n",
        "        'learning_rate': hp.loguniform('learning_rate',\n",
        "                                    space_val['learning_rate']['min'],\n",
        "                                    space_val['learning_rate']['max']),\n",
        "\n",
        "        'dropout': hp.quniform('dropout',\n",
        "                              space_val['dropout']['min'],\n",
        "                              space_val['dropout']['max'],\n",
        "                              space_val['dropout']['step'])\n",
        "    }\n",
        "\n",
        "    series = pd.DataFrame(series, columns=train.columns)\n",
        "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
        "\n",
        "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
        "\n",
        "    # create sequences train, test\n",
        "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
        "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
        "\n",
        "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n",
        "                for unit_nr in X_test_interim['Unit'].unique())\n",
        "\n",
        "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
        "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
        "    print(train_array.shape, label_array.shape, test_array.shape)\n",
        "\n",
        "    # Optimisation bayésienne avec Hyperopt\n",
        "    trials = Trials()\n",
        "    best = fmin(\n",
        "        fn=train_model,\n",
        "        space=space,\n",
        "        algo=tpe.suggest,\n",
        "        max_evals=10,\n",
        "        trials=trials\n",
        "    )\n",
        "\n",
        "\n",
        "    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, best['learning_rate'])\n",
        "\n",
        "    # Entraînement du modèle\n",
        "    history = model.fit(\n",
        "        train_array, label_array,\n",
        "        validation_data=(test_array, test_rul),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        verbose=0  # Désactiver les logs pour une sortie propre\n",
        "    )\n",
        "\n",
        "    # Prédiction sur l'ensemble de validation\n",
        "    y_pred = model.predict(test_array)\n",
        "\n",
        "    # Calcul de la RMSE, S-Score, Mape\n",
        "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
        "    s_score = compute_s_score(test_rul, y_pred)\n",
        "    mape = compute_MAPE(test_rul, y_pred)\n",
        "    r2 = r2_score(test_rul, y_pred)\n",
        "    #accuracy = accuracy_score(test_rul, y_pred)\n",
        "\n",
        "\n",
        "    time_training = time.time() - start_time\n",
        "    #Sauvegarder les résultats dans un DataFrame\n",
        "\n",
        "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
        "      'bootstrap_series': i + 1,\n",
        "      'hidden_size': best['hidden_size'],\n",
        "      'learning_rate': best['learning_rate'],\n",
        "      'dropout': best['dropout'],\n",
        "      'rmse': rmse,\n",
        "      's_score': s_score,\n",
        "      'mape': mape,\n",
        "      'r2': r2,\n",
        "      'training_time': time_training\n",
        "  }])], ignore_index=True)\n",
        "    print(results_all)\n",
        "\n",
        "  # Sauvegarder les résultats dans un fichier CSV après chaque itération\n",
        "    results_all.to_csv(path_bootstrap, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb-N_tnveCiW"
      },
      "source": [
        "# Intervalle de confiance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "llmldvM9GzOr"
      },
      "outputs": [],
      "source": [
        "def intervalle_confiance(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Supprimer les outliers de la colonne \"rmse\" selon la méthode IQR\n",
        "    q1 = df[\"rmse\"].quantile(0.25)\n",
        "    q3 = df[\"rmse\"].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    df = df[(df[\"rmse\"] >= lower_bound) & (df[\"rmse\"] <= upper_bound)]\n",
        "\n",
        "    # Calculer la moyenne et l'écart type après avoir retiré les outliers\n",
        "    mean_rmse = df[\"rmse\"].mean()\n",
        "    std_rmse = df[\"rmse\"].std()\n",
        "\n",
        "    # Garder les valeurs dans l'intervalle de confiance (±1 std autour de la moyenne)\n",
        "    filtered_df = df[(df[\"rmse\"] >= mean_rmse - std_rmse) & (df[\"rmse\"] <= mean_rmse + std_rmse)]\n",
        "\n",
        "    # Extraire les hyperparamètres\n",
        "    dropout_rates = filtered_df['dropout'].tolist()\n",
        "    learning_rates = filtered_df['learning_rate'].tolist()\n",
        "    neurons_list = filtered_df['hidden_size'].tolist()\n",
        "\n",
        "    # Supprimer doublons et trier\n",
        "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
        "    learning_final = sorted(set(learning_rates), reverse=True)\n",
        "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
        "\n",
        "    print(\"search space\", int(len(dropout_final) * len(learning_final) * len(neurons_final)))\n",
        "    print(type(neurons_final))\n",
        "    return dropout_final, learning_final, neurons_final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71CHXx5siROg"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yODLXZzQiPlt",
        "outputId": "44b748ea-5b0e-40d3-d232-1875d4c0cc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search space 160\n",
            "<class 'list'>\n",
            "Training with LSTM units=224.0, learning_rate=0.0039, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Validation RMSE: 25.6314\n",
            "Training with LSTM units=224.0, learning_rate=0.0039, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "Validation RMSE: 21.4440\n",
            "Training with LSTM units=224.0, learning_rate=0.0039, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
            "Validation RMSE: 23.7983\n",
            "Training with LSTM units=224.0, learning_rate=0.0039, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "Validation RMSE: 21.7249\n",
            "Training with LSTM units=224.0, learning_rate=0.0027, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
            "Validation RMSE: 22.4994\n",
            "Training with LSTM units=224.0, learning_rate=0.0027, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step\n",
            "Validation RMSE: 22.1308\n",
            "Training with LSTM units=224.0, learning_rate=0.0027, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "Validation RMSE: 22.7742\n",
            "Training with LSTM units=224.0, learning_rate=0.0027, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step\n",
            "Validation RMSE: 23.5260\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Validation RMSE: 31.5443\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n",
            "Validation RMSE: 24.4259\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "Validation RMSE: 22.6728\n",
            "Training with LSTM units=224.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "Validation RMSE: 22.2278\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Validation RMSE: 32.5622\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n",
            "Validation RMSE: 23.5081\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Validation RMSE: 22.3789\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
            "Validation RMSE: 21.0575\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
            "Validation RMSE: 21.6627\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Validation RMSE: 25.3256\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "Validation RMSE: 25.4723\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 25.5715\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
            "Validation RMSE: 24.6166\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
            "Validation RMSE: 26.1380\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Validation RMSE: 26.2423\n",
            "Training with LSTM units=224.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Validation RMSE: 26.0531\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "Validation RMSE: 23.2250\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 21.6896\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 21.3572\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 21.3064\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Validation RMSE: 22.5481\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation RMSE: 21.5303\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 25.7344\n",
            "Training with LSTM units=224.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 20.1378\n",
            "Training with LSTM units=192.0, learning_rate=0.0039, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Validation RMSE: 21.3599\n",
            "Training with LSTM units=192.0, learning_rate=0.0039, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 21.6850\n",
            "Training with LSTM units=192.0, learning_rate=0.0039, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 24.2306\n",
            "Training with LSTM units=192.0, learning_rate=0.0039, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 21.2483\n",
            "Training with LSTM units=192.0, learning_rate=0.0027, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation RMSE: 20.9838\n",
            "Training with LSTM units=192.0, learning_rate=0.0027, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 24.1561\n",
            "Training with LSTM units=192.0, learning_rate=0.0027, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 21.6185\n",
            "Training with LSTM units=192.0, learning_rate=0.0027, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 25.5113\n",
            "Training with LSTM units=192.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Validation RMSE: 22.0420\n",
            "Training with LSTM units=192.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Validation RMSE: 24.1432\n",
            "Training with LSTM units=192.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
            "Validation RMSE: 21.6950\n",
            "Training with LSTM units=192.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Validation RMSE: 31.3379\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
            "Validation RMSE: 25.7091\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 22.3151\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Validation RMSE: 23.2232\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 22.5376\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 21.3544\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 22.3738\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 21.2628\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Validation RMSE: 22.0036\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 19.6450\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Validation RMSE: 22.8063\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation RMSE: 23.7000\n",
            "Training with LSTM units=192.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 21.5634\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Validation RMSE: 20.6520\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 21.2400\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation RMSE: 20.3070\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 21.2186\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 20.4586\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Validation RMSE: 22.2618\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Validation RMSE: 20.4739\n",
            "Training with LSTM units=192.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 20.6071\n",
            "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Validation RMSE: 20.3587\n",
            "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Validation RMSE: 20.9391\n",
            "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 21.5958\n",
            "Training with LSTM units=160.0, learning_rate=0.0039, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Validation RMSE: 23.5071\n",
            "Training with LSTM units=160.0, learning_rate=0.0027, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Validation RMSE: 22.6826\n",
            "Training with LSTM units=160.0, learning_rate=0.0027, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Validation RMSE: 24.1190\n",
            "Training with LSTM units=160.0, learning_rate=0.0027, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Validation RMSE: 23.5573\n",
            "Training with LSTM units=160.0, learning_rate=0.0027, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Validation RMSE: 23.5879\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "Validation RMSE: 20.3483\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 23.5441\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Validation RMSE: 21.3522\n",
            "Training with LSTM units=160.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 23.7348\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 22.2471\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Validation RMSE: 20.5996\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 22.5688\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 22.7231\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 21.9443\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "Validation RMSE: 22.7916\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 23.8420\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 25.3638\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Validation RMSE: 22.1780\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Validation RMSE: 20.8563\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Validation RMSE: 22.0106\n",
            "Training with LSTM units=160.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
            "Validation RMSE: 22.3553\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Validation RMSE: 21.9143\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "Validation RMSE: 21.4124\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "Validation RMSE: 21.0639\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
            "Validation RMSE: 21.2513\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Validation RMSE: 22.7589\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
            "Validation RMSE: 20.6734\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
            "Validation RMSE: 22.4864\n",
            "Training with LSTM units=160.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
            "Validation RMSE: 23.1932\n",
            "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "Validation RMSE: 20.2426\n",
            "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
            "Validation RMSE: 21.3046\n",
            "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "Validation RMSE: 25.0551\n",
            "Training with LSTM units=128.0, learning_rate=0.0039, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "Validation RMSE: 26.4798\n",
            "Training with LSTM units=128.0, learning_rate=0.0027, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 22.8013\n",
            "Training with LSTM units=128.0, learning_rate=0.0027, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 21.5590\n",
            "Training with LSTM units=128.0, learning_rate=0.0027, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Validation RMSE: 22.7512\n",
            "Training with LSTM units=128.0, learning_rate=0.0027, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Validation RMSE: 22.0559\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 20.3499\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 20.8379\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Validation RMSE: 21.6653\n",
            "Training with LSTM units=128.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Validation RMSE: 21.9203\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 19.3697\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Validation RMSE: 23.1627\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Validation RMSE: 22.3983\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 21.0948\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 21.5144\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 20.9394\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 20.0091\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Validation RMSE: 22.8043\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 23.2559\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Validation RMSE: 22.4656\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 20.7421\n",
            "Training with LSTM units=128.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
            "Validation RMSE: 22.7086\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Validation RMSE: 21.8409\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Validation RMSE: 22.1393\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Validation RMSE: 20.8065\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Validation RMSE: 21.6019\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Validation RMSE: 21.6581\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Validation RMSE: 22.5651\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Validation RMSE: 22.6764\n",
            "Training with LSTM units=128.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 22.5959\n",
            "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Validation RMSE: 20.0009\n",
            "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 23.4380\n",
            "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.2002\n",
            "Training with LSTM units=96.0, learning_rate=0.0039, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 19.4376\n",
            "Training with LSTM units=96.0, learning_rate=0.0027, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.7577\n",
            "Training with LSTM units=96.0, learning_rate=0.0027, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.5321\n",
            "Training with LSTM units=96.0, learning_rate=0.0027, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.1184\n",
            "Training with LSTM units=96.0, learning_rate=0.0027, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.5531\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.0913\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.2492\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.6434\n",
            "Training with LSTM units=96.0, learning_rate=0.0005, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.8118\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.3194\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 21.2379\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 21.6374\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Validation RMSE: 21.3890\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.0041\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.3254\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.5034\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.4399\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 21.1279\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.0139\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 20.9782\n",
            "Training with LSTM units=96.0, learning_rate=0.0004, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Validation RMSE: 21.8254\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 22.1043\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 23.3073\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Validation RMSE: 22.3418\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 22.4823\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.5\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Validation RMSE: 22.9487\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.4\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Validation RMSE: 22.2925\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.3\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 24.3680\n",
            "Training with LSTM units=96.0, learning_rate=0.0003, dropout=0.2\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Validation RMSE: 20.4917\n"
          ]
        }
      ],
      "source": [
        "dropout, learning_rate, hidden_size = intervalle_confiance(path_bootstrap)\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'hidden_size': hidden_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'dropout': dropout\n",
        "}\n",
        "\n",
        "#Sauvegarder les résultats dans un DataFrame\n",
        "results_all = pd.DataFrame()\n",
        "i=0\n",
        "\n",
        "for hidden_size in param_grid['hidden_size']:\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for dropout in param_grid['dropout']:\n",
        "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Build the LSTM model\n",
        "            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
        "\n",
        "            # Train the model\n",
        "            history = model.fit(\n",
        "                train_array, label_array,\n",
        "                validation_data=(test_array, test_rul),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                verbose=0\n",
        "            )\n",
        "            # Evaluate the model on the validation set\n",
        "            y_pred = model.predict(test_array)\n",
        "            # Calcul de la RMSE\n",
        "            rmse = root_mean_squared_error(test_rul, y_pred)\n",
        "            s_score = compute_s_score(test_rul, y_pred)\n",
        "            mape = compute_MAPE(test_rul, y_pred)\n",
        "            r2 = r2_score(test_rul, y_pred)\n",
        "            #accuracy = accuracy_score(test_rul, y_pred)\n",
        "\n",
        "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "            time_training = time.time() - start_time\n",
        "            i+=1\n",
        "            #Sauvegarder les résultats dans un DataFrame\n",
        "\n",
        "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
        "                'bootstrap_series': i,\n",
        "                'hidden_size': hidden_size,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dropout': dropout,\n",
        "                'rmse': rmse,\n",
        "                's_score': s_score,\n",
        "                'mape': mape,\n",
        "                'r2': r2,\n",
        "                'training_time': time_training\n",
        "            }])], ignore_index=True)\n",
        "\n",
        "            results_all.to_csv(path_grid, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1qzNWs_zEhJG",
        "w3R-Zqn8b7-s",
        "6XjaNrNBnLtk"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
