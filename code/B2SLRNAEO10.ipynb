{"cells":[{"cell_type":"markdown","metadata":{"id":"1qzNWs_zEhJG"},"source":["\n","\n","\n","\n","# Importations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuCQx7XbGnf_"},"outputs":[],"source":["from __future__ import print_function\n","\n","# Standard libraries\n","import os\n","import time\n","import random\n","import warnings\n","from math import sqrt, pow\n","\n","# Data processing\n","import pandas as pd\n","import numpy as np\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","import sklearn\n","from sklearn import preprocessing\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Deep learning\n","import tensorflow as tf\n","from tensorflow.keras import Sequential, optimizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n","import keras\n","from keras import backend as K\n","\n","# Optimization\n","from scipy import optimize\n","from scipy.stats import spearmanr\n","from scipy.spatial.distance import pdist, squareform\n","from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n","\n","\n","%matplotlib inline\n","warnings.filterwarnings('ignore')\n","\n","SEED = 0\n","def set_seed(seed=SEED):\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    tf.random.set_seed(SEED)\n","\n","# Appeler la fonction pour fixer le seed\n","set_seed(SEED)\n"]},{"cell_type":"markdown","metadata":{"id":"w3R-Zqn8b7-s"},"source":["# Methode.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gfR4rmnddop"},"outputs":[],"source":["# read the train and test data\n","def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n","    if drop:\n","        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n","        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n","    else:\n","        X_train_interim = add_operating_condition(train)\n","        X_test_interim = add_operating_condition(test)\n","\n","    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n","    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n","    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n","\n","    return X_train_interim, X_test_interim\n","\n","def rul_piecewise_fct(X_train, rul):\n","\n","    X_train['RUL'].clip(upper=rul, inplace=True)\n","\n","    return X_train\n","\n","def prepare_data(file_name):\n","    dir_path =  'C:/Users/RA-RV/Documents/Malick/data/'\n","    dependent_var = ['RUL']\n","    index_names = ['Unit', 'Cycle']\n","    setting_names = ['Altitude', 'Mach', 'TRA']\n","    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n","                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n","    col_names = index_names + setting_names + sensor_names\n","\n","    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n","\n","    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n","    rul_train.columns = ['Unit', 'max']\n","    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n","    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n","    df_train.drop('max', axis=1, inplace=True)\n","\n","    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n","\n","    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n","    #y_true[\"Unit\"] = y_true.index + 1\n","    return df_train, df_test, y_test\n","\n","\n","# add operational condition to then normalize the data based on these operational conditions test\n","def add_operating_condition(df):\n","    df_op_cond = df.copy()\n","\n","    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n","    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n","    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n","\n","    # converting settings to string and concatanating makes the operating condition into a categorical variable\n","    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n","                        df_op_cond['Mach'].astype(str) + '_' + \\\n","                        df_op_cond['TRA'].astype(str)\n","\n","    return df_op_cond\n","\n","# normalize the data based on the operational condition\n","def condition_scaler(df_train, df_test, sensor_names):\n","  # apply operating condition specific scaling\n","  #scaler = StandardScaler()\n","    scaler = MinMaxScaler(feature_range = (0, 1))\n","    for condition in df_train['op_cond'].unique():\n","        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n","        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n","        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n","    return df_train, df_test\n","\n","\n","#to plot each sensors with respect to the RUL\n","def plot_signal(df, signal_name, unit=None):\n","#     train = df\n","    plt.figure(figsize=(13,5))\n","    if unit:\n","        plt.plot('RUL', signal_name,\n","                data=df[df['Unit']==unit])\n","    else:\n","        for i in df['Unit'].unique():\n","            if (i % 10 == 0):  # only ploting every 10th unit_nr\n","                plt.plot('RUL', signal_name,\n","                         data=df[df['Unit']==i])\n","    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n","    plt.xticks(np.arange(0, 375, 25))\n","    plt.ylabel(signal_name)\n","    plt.xlabel('Remaining Use fulLife')\n","    #plt.savefig(signal_name+'.jpeg')\n","    plt.show()\n","\n","# denoise the signal using the exponential signal wih an alpha equals to 0.3\n","def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n","    df = df.copy()\n","    # first, calculate the exponential weighted mean of desired sensors\n","    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n","    df[sensors] = new_column.reset_index(level=0, drop=True)\n","\n","\n","    # second, drop first n_samples of each unit_nr to reduce filter delay\n","    def create_mask(data, samples):\n","        result = np.ones_like(data)\n","        result[0:samples] = 0\n","        return result\n","\n","    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n","    df = df[mask]\n","\n","    return df\n","\n","def root_mean_squared_error(y_true, y_pred):\n","    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n","\n","#the score defined in the paper\n","def compute_s_score(rul_true, rul_pred):\n","    diff = rul_pred - rul_true\n","    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n","\n","#evaluate the model with RÂ² and RMSE\n","def evaluate(y_true, y_hat, label='test'):\n","    mse = mean_squared_error(y_true, y_hat)\n","    rmse = np.sqrt(mse)\n","    variance = r2_score(y_true, y_hat)\n","    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n","\n","def generate_sequences(data, sequence_length):\n","    \"\"\"\n","    Generate sequences of a given length from the input data.\n","    \"\"\"\n","    num_samples = data.shape[0]\n","\n","    # Generate sequences using sliding windows\n","    for start_idx in range(num_samples - sequence_length + 1):\n","        end_idx = start_idx + sequence_length\n","        yield data[start_idx:end_idx, :]\n","\n","def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n","    \"\"\"\n","    Wrapper function to generate sequences for multiple units in the dataset.\n","    \"\"\"\n","    if unit_nrs is None:\n","        unit_nrs = df['Unit'].unique()\n","\n","    # Generate sequences for each unit and concatenate them\n","    all_sequences = []\n","    for unit_nr in unit_nrs:\n","        unit_data = df[df['Unit'] == unit_nr][columns].values\n","        sequences = list(generate_sequences(unit_data, sequence_length))\n","        all_sequences.extend(sequences)\n","\n","    return np.array(all_sequences, dtype=np.float32)\n","\n","\n","def gen_train_data(df, sequence_length, columns):\n","    data = df[columns].values\n","    num_elements = data.shape[0]\n","\n","    # -1 and +1 because of Python indexing\n","    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n","        yield data[start:stop, :]\n","\n","def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n","    if unit_nrs.size <= 0:\n","        unit_nrs = df['Unit'].unique()\n","\n","    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n","               for unit_nr in unit_nrs)\n","    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n","    return data_array\n","\n","def create_model(TW , remaining_):\n","#     history = History()\n","    model = Sequential()\n","    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n","    model.add(Dense(units=128, activation='relu'))\n","    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n","    model.add(Dropout(0.1))\n","    model.add(Dense(1, activation='relu'))\n","    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n","\n","    return model\n","\n","def compute_MAPE(y_true, y_hat):\n","    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n","    return mape\n","\n","def gen_labels(df, sequence_length, label):\n","    data_matrix = df[label].values\n","    num_elements = data_matrix.shape[0]\n","\n","    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n","    return data_matrix[sequence_length-1:num_elements, :]\n","\n","def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n","    if unit_nrs.size <= 0:\n","        unit_nrs = df['Unit'].unique()\n","\n","    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n","                for unit_nr in unit_nrs]\n","    label_array = np.concatenate(label_gen).astype(np.float32)\n","    return label_array\n","def gen_test_data(df, sequence_length, columns, mask_value):\n","    if df.shape[0] < sequence_length:\n","        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n","        idx = data_matrix.shape[0] - df.shape[0]\n","        data_matrix[idx:,:] = df[columns].values  # fill with available data\n","    else:\n","        data_matrix = df[columns].values\n","\n","    # specifically yield the last possible sequence\n","    stop = num_elements = data_matrix.shape[0]\n","    start = stop - sequence_length\n","    for i in list(range(1)):\n","        yield data_matrix[start:stop, :]\n","def plot_loss(fit_history):\n","    plt.figure(figsize=(13,5))\n","    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n","    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","def new_column (df, column):\n","    #df = df.sort_values(by=column, ascending=False)\n","    df[column] = range(1, len(df) + 1)\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"3reK6P4D-4XM"},"source":["# PrÃ©paration des donnÃ©es et configuration initiale"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5120,"status":"ok","timestamp":1747643898102,"user":{"displayName":"El Hadji Malick Sy","userId":"07326824895633266968"},"user_tz":-120},"id":"ZQiI0neXGngG","outputId":"536c9759-97e5-4d2b-8061-003dfb2fa6c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["(61249, 27) (41214, 26) (248, 1)\n","(51538, 40, 17) (51538, 1) (248, 40, 17)\n"]}],"source":["train, test, y_test = prepare_data('FD004.txt')\n","print(train.shape, test.shape, y_test.shape)\n","sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n","                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n","\n","remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n","                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n","drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n","\n","rul_piecewise = 130\n","train['RUL'].clip(upper=rul_piecewise, inplace=True)\n","\n","# Configuration des paramÃ¨tres\n","alpha = 0.2\n","sequence_length = 40\n","epochs = 10\n","#nodes_per_layer = [64]\n","#dropout = 0.2\n","activation = 'tanh'\n","batch_size = 32\n","remaining_sensors = remaining_sensors\n","input_shape = (sequence_length, len(remaining_sensors))\n","\n","space_val = {\n","    'hidden_size': {\n","        'min': 32,\n","        'max': 256,\n","        'step': 32\n","    },\n","    'learning_rate': {\n","        'min': np.log(1e-5),\n","        'max': np.log(1e-2)\n","    },\n","    'dropout': {\n","        'min': 0.1,\n","        'max': 0.5,\n","        'step': 0.1\n","    }\n","}\n","\n","# PrÃ©paration des donnÃ©es\n","X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n","train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n","label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n","\n","test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n","               for unit_nr in X_test_interim['Unit'].unique())\n","test_array = np.concatenate(list(test_gen)).astype(np.float32)\n","\n","test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n","print(train_array.shape, label_array.shape, test_array.shape)\n","\n","path_bootstrap = 'C:/Users/RA-RV/Documents/Malick/data/EO/fd004_bootstrap_s_score.csv'\n","path_bootstrap2 = 'C:/Users/RA-RV/Documents/Malick/data/EO/fd004_bootstrap2_s_score.csv'\n","path_grid = 'C:/Users/RA-RV/Documents/Malick/data/EO/fd004_bootbogs_s_score.csv'"]},{"cell_type":"markdown","metadata":{"id":"8yC6kum8dWzB"},"source":["# Bayesian optimization avec bootstrap"]},{"cell_type":"markdown","metadata":{"id":"6XjaNrNBnLtk"},"source":["## Creer n series bootstrap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8y_6F-lTnTA5"},"outputs":[],"source":["def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n","\n","    n_timesteps = len(data)\n","    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n","    bootstrap_series_list = []\n","\n","    # DÃ©couper la sÃ©rie en blocs\n","    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n","\n","    # CrÃ©er chaque sÃ©rie bootstrap\n","    for _ in range(n_bootstrap):\n","        # RÃ©Ã©chantillonner les blocs avec remise\n","        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n","\n","        # ConcatÃ©ner les blocs pour former une nouvelle sÃ©rie\n","        new_series = np.concatenate(sampled_blocks, axis=0)\n","\n","        if len(new_series) > n_timesteps:\n","            new_series = new_series[:n_timesteps]\n","\n","        elif len(new_series) < n_timesteps:\n","          remaining_length = n_timesteps - len(new_series)\n","          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n","\n","        bootstrap_series_list.append(new_series)\n","\n","    return bootstrap_series_list"]},{"cell_type":"markdown","metadata":{"id":"LzO_WAqMXrHk"},"source":["## Creation et entrainement du modele"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KdXdtod0er4D"},"outputs":[],"source":["def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n","    model = Sequential()\n","    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(256))\n","    model.add(Dense(1))  # Sortie pour la rÃ©gression\n","    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n","    return model\n","\n","# Fonction pour entraÃ®ner le modÃ¨le et Ã©valuer la RMSE\n","def train_model(params):\n","    # CrÃ©ation du modÃ¨le\n","    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, params['learning_rate'])\n","\n","    # EntraÃ®nement du modÃ¨le\n","    history = model.fit(\n","        train_array, label_array,\n","        validation_data=(test_array, test_rul),\n","        epochs=epochs,\n","        batch_size=32,\n","        verbose=0  # DÃ©sactiver les logs pour une sortie propre\n","    )\n","\n","    # PrÃ©diction sur l'ensemble de validation\n","    y_pred = model.predict(test_array)\n","\n","    # Calcul de la RMSE, S-Score, Mape\n","    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n","    s_score = compute_s_score(test_rul, y_pred)\n","    mape = compute_MAPE(test_rul, y_pred)\n","    r2 = r2_score(test_rul, y_pred)\n","\n","  # minimiser RMSE/s-score\n","\n","    # Retourner la RMSE comme mÃ©trique Ã  minimiser\n","    return {'loss': s_score, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"]},{"cell_type":"markdown","metadata":{"id":"YPEaXloQYQXC"},"source":["## Apply HyperOpt TPE and store the combination of hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LmtmfU5JPTmh","outputId":"ed664e79-5445-4f27-cd0a-d47352597be2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traitement de la sÃ©rie bootstrap 1...\n","(51545, 40, 17) (51545, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n"," 20%|ââ        | 2/10 [08:24<32:37, 244.67s/trial, best loss: 20.673563801008644]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001992DC69DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 109ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n"," 30%|âââ       | 3/10 [12:54<29:52, 256.13s/trial, best loss: 20.673563801008644]WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000019930805DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 116ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 110ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 95ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 104ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","100%|ââââââââââ| 10/10 [38:03<00:00, 228.35s/trial, best loss: 19.008231538229364]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","\n","      s_score       mape        r2  training_time  \n","0  3132.46519  40.432798  0.789593    2451.267729  \n","Traitement de la sÃ©rie bootstrap 2...\n","(51552, 40, 17) (51552, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 103ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 102ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 103ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","100%|ââââââââââ| 10/10 [27:35<00:00, 165.59s/trial, best loss: 18.990898763350927]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","\n","      s_score       mape        r2  training_time  \n","0  3132.46519  40.432798  0.789593    2451.267729  \n","1  1612.78985  30.753930  0.833426    1759.525773  \n","Traitement de la sÃ©rie bootstrap 3...\n","(51589, 40, 17) (51589, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 110ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 93ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 185ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","100%|ââââââââââ| 10/10 [35:57<00:00, 215.80s/trial, best loss: 20.011912040960908]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","Traitement de la sÃ©rie bootstrap 4...\n","(51577, 40, 17) (51577, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 96ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 97ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 109ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 97ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n","\n","100%|ââââââââââ| 10/10 [27:22<00:00, 164.29s/trial, best loss: 19.89210704906754]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","Traitement de la sÃ©rie bootstrap 5...\n","(51587, 40, 17) (51587, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 95ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step        \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 114ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 110ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 105ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","100%|ââââââââââ| 10/10 [32:08<00:00, 192.81s/trial, best loss: 19.468529762749082]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","Traitement de la sÃ©rie bootstrap 6...\n","(51538, 40, 17) (51538, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 102ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 101ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n","\n","100%|ââââââââââ| 10/10 [32:58<00:00, 197.89s/trial, best loss: 19.050293863588102]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","5                 6        160.0       0.000501      0.3  19.053071   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","5  2063.439091  31.749693  0.815855    2187.686555  \n","Traitement de la sÃ©rie bootstrap 7...\n","(51538, 40, 17) (51538, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 94ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 96ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 91ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 95ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 167ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 111ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\n","100%|ââââââââââ| 10/10 [23:13<00:00, 139.32s/trial, best loss: 19.51420115277229]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","5                 6        160.0       0.000501      0.3  19.053071   \n","6                 7         64.0       0.001040      0.2  20.791876   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","5  2063.439091  31.749693  0.815855    2187.686555  \n","6  3973.740274  39.482037  0.780711    1506.774945  \n","Traitement de la sÃ©rie bootstrap 8...\n","(51677, 40, 17) (51677, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 94ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 93ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 121ms/step         \n","\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 109ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 106ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 96ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step          \n","\n","100%|ââââââââââ| 10/10 [30:45<00:00, 184.53s/trial, best loss: 19.991189160301815]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","5                 6        160.0       0.000501      0.3  19.053071   \n","6                 7         64.0       0.001040      0.2  20.791876   \n","7                 8        224.0       0.000313      0.3  23.001069   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","5  2063.439091  31.749693  0.815855    2187.686555  \n","6  3973.740274  39.482037  0.780711    1506.774945  \n","7  3744.857834  38.409910  0.731636    2115.308160  \n","Traitement de la sÃ©rie bootstrap 9...\n","(51628, 40, 17) (51628, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 108ms/step       \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step       \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step        \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 98ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 109ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 112ms/step         \n","\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 102ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 107ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 100ms/step         \n","\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n","\n","100%|ââââââââââ| 10/10 [35:59<00:00, 215.92s/trial, best loss: 19.799815259900075]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","5                 6        160.0       0.000501      0.3  19.053071   \n","6                 7         64.0       0.001040      0.2  20.791876   \n","7                 8        224.0       0.000313      0.3  23.001069   \n","8                 9         64.0       0.000576      0.2  19.604781   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","5  2063.439091  31.749693  0.815855    2187.686555  \n","6  3973.740274  39.482037  0.780711    1506.774945  \n","7  3744.857834  38.409910  0.731636    2115.308160  \n","8  2148.732220  39.218896  0.805037    2272.063179  \n","Traitement de la sÃ©rie bootstrap 10...\n","(51564, 40, 17) (51564, 1) (248, 40, 17)\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 102ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step        \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 165ms/step         \n","\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 10ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 191ms/step         \n","\u001b[1m4/8\u001b[0m \u001b[32mââââââââââ\u001b[0m\u001b[37mââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 158ms/step         \n","\u001b[1m7/8\u001b[0m \u001b[32mâââââââââââââââââ\u001b[0m\u001b[37mâââ\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 176ms/step         \n","\u001b[1m5/8\u001b[0m \u001b[32mââââââââââââ\u001b[0m\u001b[37mââââââââ\u001b[0m \u001b[1m0s\u001b[0m 13ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 122ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 122ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n","\n","\u001b[1m1/8\u001b[0m \u001b[32mââ\u001b[0m\u001b[37mââââââââââââââââââ\u001b[0m \u001b[1m1s\u001b[0m 249ms/step         \n","\u001b[1m6/8\u001b[0m \u001b[32mâââââââââââââââ\u001b[0m\u001b[37mâââââ\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step          \n","\n","100%|ââââââââââ| 10/10 [37:08<00:00, 222.90s/trial, best loss: 21.077722498936822]\n","\u001b[1m8/8\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n","0                 1        128.0       0.001265      0.2  20.366473   \n","1                 2         64.0       0.007054      0.1  18.121296   \n","2                 3        224.0       0.000244      0.5  21.831522   \n","3                 4         96.0       0.002008      0.2  20.453563   \n","4                 5        192.0       0.000170      0.3  20.669240   \n","5                 6        160.0       0.000501      0.3  19.053071   \n","6                 7         64.0       0.001040      0.2  20.791876   \n","7                 8        224.0       0.000313      0.3  23.001069   \n","8                 9         64.0       0.000576      0.2  19.604781   \n","9                10         32.0       0.000559      0.4  21.924280   \n","\n","       s_score       mape        r2  training_time  \n","0  3132.465190  40.432798  0.789593    2451.267729  \n","1  1612.789850  30.753930  0.833426    1759.525773  \n","2  3509.966813  44.899465  0.758233    2427.608999  \n","3  2393.084605  37.383075  0.787790    1789.226557  \n","4  2665.102324  36.564785  0.783291    2195.904428  \n","5  2063.439091  31.749693  0.815855    2187.686555  \n","6  3973.740274  39.482037  0.780711    1506.774945  \n","7  3744.857834  38.409910  0.731636    2115.308160  \n","8  2148.732220  39.218896  0.805037    2272.063179  \n","9  2825.633360  55.464750  0.756174    2363.556840  \n"]}],"source":["bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n","results_all = pd.DataFrame()\n","for i, series in enumerate(bootstrap_series_list):\n","    print(f\"Traitement de la sÃ©rie bootstrap {i + 1}...\")\n","\n","    start_time = time.time()\n","\n","\n","    space = {\n","        'hidden_size': hp.quniform('hidden_size',\n","                              space_val['hidden_size']['min'],\n","                              space_val['hidden_size']['max'],\n","                              space_val['hidden_size']['step']),\n","\n","        'learning_rate': hp.loguniform('learning_rate',\n","                                    space_val['learning_rate']['min'],\n","                                    space_val['learning_rate']['max']),\n","\n","        'dropout': hp.quniform('dropout',\n","                              space_val['dropout']['min'],\n","                              space_val['dropout']['max'],\n","                              space_val['dropout']['step'])\n","    }\n","\n","    series = pd.DataFrame(series, columns=train.columns)\n","    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n","\n","    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n","\n","    # create sequences train, test\n","    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n","    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n","\n","    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n","                for unit_nr in X_test_interim['Unit'].unique())\n","\n","    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n","    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n","    print(train_array.shape, label_array.shape, test_array.shape)\n","\n","    # Optimisation bayÃ©sienne avec Hyperopt\n","    trials = Trials()\n","    best = fmin(\n","        fn=train_model,\n","        space=space,\n","        algo=tpe.suggest,\n","        max_evals=10,\n","        trials=trials\n","    )\n","\n","    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, best['learning_rate'])\n","\n","    # EntraÃ®nement du modÃ¨le\n","    history = model.fit(\n","        train_array, label_array,\n","        validation_data=(test_array, test_rul),\n","        epochs=epochs,\n","        batch_size=32,\n","        verbose=0  # DÃ©sactiver les logs pour une sortie propre\n","    )\n","\n","    # PrÃ©diction sur l'ensemble de validation\n","    y_pred = model.predict(test_array)\n","\n","    # Calcul de la RMSE, S-Score, Mape\n","    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n","    s_score = compute_s_score(test_rul, y_pred)\n","    mape = compute_MAPE(test_rul, y_pred)\n","    r2 = r2_score(test_rul, y_pred)\n","    #accuracy = accuracy_score(test_rul, y_pred)\n","\n","\n","    time_training = time.time() - start_time\n","    #Sauvegarder les rÃ©sultats dans un DataFrame\n","\n","    results_all = pd.concat([results_all, pd.DataFrame([{\n","      'bootstrap_series': i + 1,\n","      'hidden_size': best['hidden_size'],\n","      'learning_rate': best['learning_rate'],\n","      'dropout': best['dropout'],\n","      'rmse': rmse,\n","      's_score': s_score,\n","      'mape': mape,\n","      'r2': r2,\n","      'training_time': time_training\n","  }])], ignore_index=True)\n","    print(results_all)\n","\n","  # Sauvegarder les rÃ©sultats dans un fichier CSV aprÃ¨s chaque itÃ©ration\n","    results_all.to_csv(path_bootstrap, index=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bb-N_tnveCiW"},"source":["# Intervalle de confiance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llmldvM9GzOr"},"outputs":[],"source":["def intervalle_confiance(file_path):\n","    df = pd.read_csv(file_path)\n","\n","    Q1 = df[\"s_score\"].quantile(0.25)\n","    Q3 = df[\"s_score\"].quantile(0.75)\n","    IQR = Q3 - Q1\n","\n","    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n","    df = pd.read_csv(file_path)\n","\n","    # Calculer la moyenne et l'Ã©cart type de la colonne \"s_score\"\n","    mean_s_score = df[\"s_score\"].mean()\n","    std_s_score = df[\"s_score\"].std()\n","\n","    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n","\n","    dropout_rates = filtered_df['dropout'].tolist()\n","    learning_rates = filtered_df['learning_rate'].tolist()\n","    neurons_list = filtered_df['hidden_size'].tolist()\n","\n","    #remove duplicate values and sort list\n","    dropout_final = sorted(set(dropout_rates), reverse=True)\n","    learning_final = sorted(set(learning_rates), reverse=True)\n","    neurons_final = sorted(set(neurons_list), reverse=True)\n","\n","    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n","    return dropout_final, learning_final, neurons_final"]},{"cell_type":"markdown","metadata":{"id":"5otejvX00cDt"},"source":["# 2e TPE\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I35N2YFk0fT3","outputId":"2d3aa6bd-0392-4e52-efa0-8a067565cc1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["search space 168\n","<class 'list'>\n","Traitement de la sÃ©rie bootstrap 1...\n","(51546, 40, 17) (51546, 1) (248, 40, 17)\n","  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"]},{"name":"stderr","output_type":"stream","text":["job exception: 'dropout'\n","\n"]},{"name":"stdout","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]\n"]},{"ename":"KeyError","evalue":"'dropout'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Optimisation bayÃ©sienne avec Hyperopt\u001b[39;00m\n\u001b[32m     37\u001b[39m trials = Trials()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m best = \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m model = model_lstm_1layer(input_shape, best[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m], best[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m], activation, best[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# EntraÃ®nement du modÃ¨le\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    537\u001b[39m     fn = __objective_fmin_wrapper(fn)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[33m\"\u001b[39m\u001b[33mfmin\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(trials_save_file):\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[39m, in \u001b[36mTrials.fmin\u001b[39m\u001b[34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    583\u001b[39m rval.catch_eval_exceptions = catch_eval_exceptions\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[43mrval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials.trials) == \u001b[32m0\u001b[39m:\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[39m, in \u001b[36mFMinIter.exhaust\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    363\u001b[39m     n_done = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.trials)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[39m, in \u001b[36mFMinIter.run\u001b[39m\u001b[34m(self, N, block_until_done)\u001b[39m\n\u001b[32m    297\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m.poll_interval_secs)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trials_save_file != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[39m, in \u001b[36mFMinIter.serial_evaluate\u001b[39m\u001b[34m(self, N)\u001b[39m\n\u001b[32m    176\u001b[39m ctrl = base.Ctrl(\u001b[38;5;28mself\u001b[39m.trials, current_trial=trial)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    180\u001b[39m     logger.error(\u001b[33m\"\u001b[39m\u001b[33mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(e))\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[39m, in \u001b[36mDomain.evaluate\u001b[39m\u001b[34m(self, config, ctrl, attach_attachments)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    884\u001b[39m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[32m    885\u001b[39m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[32m    887\u001b[39m     pyll_rval = pyll.rec_eval(\n\u001b[32m    888\u001b[39m         \u001b[38;5;28mself\u001b[39m.expr,\n\u001b[32m    889\u001b[39m         memo=memo,\n\u001b[32m    890\u001b[39m         print_node_on_error=\u001b[38;5;28mself\u001b[39m.rec_eval_print_node_on_error,\n\u001b[32m    891\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np.number)):\n\u001b[32m    895\u001b[39m     dict_rval = {\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m: STATUS_OK}\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(params):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# CrÃ©ation du modÃ¨le\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     model = model_lstm_1layer(input_shape, params[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdropout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, activation, params[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# EntraÃ®nement du modÃ¨le\u001b[39;00m\n\u001b[32m     16\u001b[39m     history = model.fit(\n\u001b[32m     17\u001b[39m         train_array, label_array,\n\u001b[32m     18\u001b[39m         validation_data=(test_array, test_rul),\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m         verbose=\u001b[32m0\u001b[39m  \u001b[38;5;66;03m# DÃ©sactiver les logs pour une sortie propre\u001b[39;00m\n\u001b[32m     22\u001b[39m     )\n","\u001b[31mKeyError\u001b[39m: 'dropout'"]}],"source":["bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n","results_all = pd.DataFrame()\n","dropout_first, learning_rate_first, hidden_size_first = intervalle_confiance(path_bootstrap)\n","\n","dropout_first = list(dropout_first)\n","learning_rate_first = list(learning_rate_first)\n","hidden_size_first = list(hidden_size_first)\n","\n","for i, series in enumerate(bootstrap_series_list):\n","    print(f\"Traitement de la sÃ©rie bootstrap {i + 1}...\")\n","\n","    start_time = time.time()\n","\n","\n","    space = {\n","        'learning_rate': hp.choice('learning_rate', learning_rate_first),\n","        'dropout_rate': hp.choice('dropout_rate', dropout_first),\n","        'hidden_size': hp.choice('hidden_size', hidden_size_first)\n","    }\n","\n","\n","    series = pd.DataFrame(series, columns=train.columns)\n","    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n","\n","    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n","\n","    # create sequences train, test\n","    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n","    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n","\n","    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n","                for unit_nr in X_test_interim['Unit'].unique())\n","\n","    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n","    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n","    print(train_array.shape, label_array.shape, test_array.shape)\n","\n","    # Optimisation bayÃ©sienne avec Hyperopt\n","    trials = Trials()\n","    best = fmin(\n","        fn=train_model,\n","        space=space,\n","        algo=tpe.suggest,\n","        max_evals=10,\n","        trials=trials\n","    )\n","\n","    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, best['learning_rate'])\n","\n","    # EntraÃ®nement du modÃ¨le\n","    history = model.fit(\n","        train_array, label_array,\n","        validation_data=(test_array, test_rul),\n","        epochs=epochs,\n","        batch_size=32,\n","        verbose=0  # DÃ©sactiver les logs pour une sortie propre\n","    )\n","\n","    # PrÃ©diction sur l'ensemble de validation\n","    y_pred = model.predict(test_array)\n","\n","    # Calcul de la RMSE, S-Score, Mape\n","    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n","    s_score = compute_s_score(test_rul, y_pred)\n","    mape = compute_MAPE(test_rul, y_pred)\n","    r2 = r2_score(test_rul, y_pred)\n","    #accuracy = accuracy_score(test_rul, y_pred)\n","\n","\n","    time_training = time.time() - start_time\n","    #Sauvegarder les rÃ©sultats dans un DataFrame\n","\n","    results_all = pd.concat([results_all, pd.DataFrame([{\n","      'bootstrap_series': i + 1,\n","      'hidden_size': best['hidden_size'],\n","      'learning_rate': best['learning_rate'],\n","      'dropout': best['dropout'],\n","      'rmse': rmse,\n","      's_score': s_score,\n","      'mape': mape,\n","      'r2': r2,\n","      'training_time': time_training\n","  }])], ignore_index=True)\n","    print(results_all)\n","\n","  # Sauvegarder les rÃ©sultats dans un fichier CSV aprÃ¨s chaque itÃ©ration\n","    results_all.to_csv(path_bootstrap2, index=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BV9djbEb0izo"},"source":["# intervalle de confiance 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhFy5xw70nqh"},"outputs":[],"source":["def intervalle_confiance2(file_path):\n","    df = pd.read_csv(file_path)\n","\n","    Q1 = df[\"s_score\"].quantile(0.25)\n","    Q3 = df[\"s_score\"].quantile(0.75)\n","    IQR = Q3 - Q1\n","\n","    df = df[(df[\"s_score\"] >= (Q1 - 1.5 * IQR)) & (df[\"s_score\"] <= (Q3 + 1.5 * IQR))]\n","\n","    # Calculer la moyenne et l'Ã©cart type de la colonne \"s_score\"\n","    mean_s_score = df[\"s_score\"].mean()\n","    std_s_score = df[\"s_score\"].std()\n","\n","    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n","\n","    dropout_rates = filtered_df['dropout'].tolist()\n","    learning_rates = filtered_df['learning_rate'].tolist()\n","    neurons_list = filtered_df['hidden_size'].tolist()\n","\n","    #remove duplicate values and sort list\n","    dropout_final = sorted(set(dropout_rates), reverse=True)\n","    learning_final = sorted(set(learning_rates), reverse=True)\n","    neurons_final = sorted(set(neurons_list), reverse=True)\n","\n","    print(\"search space\",int(len(dropout_final)*len(learning_final)*len(neurons_final)))\n","    print(type(neurons_final))\n","    return dropout_final, learning_final, neurons_final"]},{"cell_type":"markdown","metadata":{"id":"71CHXx5siROg"},"source":["# Grid Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yODLXZzQiPlt"},"outputs":[],"source":["def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n","    model = Sequential()\n","    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n","    model.add(Dropout(dropout))\n","    model.add(Dense(256))\n","    model.add(Dense(1))  # Sortie pour la rÃ©gression\n","    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n","    return model\n","\n","dropout, learning_rate, hidden_size = intervalle_confiance2(path_bootstrap2)\n","# Define the hyperparameter grid\n","param_grid = {\n","    'hidden_size': hidden_size,\n","    'learning_rate': learning_rate,\n","    'dropout': dropout\n","}\n","\n","#Sauvegarder les rÃ©sultats dans un DataFrame\n","results_all = pd.DataFrame()\n","i=0\n","\n","for hidden_size in param_grid['hidden_size']:\n","    for learning_rate in param_grid['learning_rate']:\n","        for dropout in param_grid['dropout']:\n","            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n","\n","            start_time = time.time()\n","\n","            # Build the LSTM model\n","            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n","\n","            # Train the model\n","            history = model.fit(\n","                train_array, label_array,\n","                validation_data=(test_array, test_rul),\n","                epochs=epochs,\n","                batch_size=batch_size,\n","                verbose=0\n","            )\n","            # Evaluate the model on the validation set\n","            y_pred = model.predict(test_array)\n","            # Calcul de la RMSE\n","            rmse = root_mean_squared_error(test_rul, y_pred)\n","            s_score = compute_s_score(test_rul, y_pred)\n","            mape = compute_MAPE(test_rul, y_pred)\n","            r2 = r2_score(test_rul, y_pred)\n","            #accuracy = accuracy_score(test_rul, y_pred)\n","\n","            print(f\"Validation RMSE: {rmse:.4f}\")\n","\n","            time_training = time.time() - start_time\n","            i+=1\n","            #Sauvegarder les rÃ©sultats dans un DataFrame\n","\n","            results_all = pd.concat([results_all, pd.DataFrame([{\n","                'bootstrap_series': i,\n","                'hidden_size': hidden_size,\n","                'learning_rate': learning_rate,\n","                'dropout': dropout,\n","                'rmse': rmse,\n","                's_score': s_score,\n","                'mape': mape,\n","                'r2': r2,\n","                'training_time': time_training\n","            }])], ignore_index=True)\n","\n","            results_all.to_csv(path_grid, index=False)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["1qzNWs_zEhJG","w3R-Zqn8b7-s"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}