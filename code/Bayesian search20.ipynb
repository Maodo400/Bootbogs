{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qzNWs_zEhJG"
   },
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MuCQx7XbGnf_"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from math import sqrt, pow\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Optimization\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK, space_eval\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3R-Zqn8b7-s"
   },
   "source": [
    "# Methode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_gfR4rmnddop"
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
    "    if drop:\n",
    "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "    else:\n",
    "        X_train_interim = add_operating_condition(train)\n",
    "        X_test_interim = add_operating_condition(test)\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "\n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "def rul_piecewise_fct(X_train, rul):\n",
    "\n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def prepare_data(file_name):\n",
    "    dir_path = '../data/'\n",
    "    dependent_var = ['RUL']\n",
    "    index_names = ['Unit', 'Cycle']\n",
    "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
    "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "    col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
    "\n",
    "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
    "    rul_train.columns = ['Unit', 'max']\n",
    "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
    "\n",
    "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
    "    #y_true[\"Unit\"] = y_true.index + 1\n",
    "    return df_train, df_test, y_test\n",
    "\n",
    "\n",
    "# add operational condition to then normalize the data based on these operational conditions test\n",
    "def add_operating_condition(df):\n",
    "    df_op_cond = df.copy()\n",
    "\n",
    "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
    "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
    "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
    "\n",
    "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
    "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
    "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
    "                        df_op_cond['TRA'].astype(str)\n",
    "\n",
    "    return df_op_cond\n",
    "\n",
    "# normalize the data based on the operational condition\n",
    "def condition_scaler(df_train, df_test, sensor_names):\n",
    "  # apply operating condition specific scaling\n",
    "  #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    for condition in df_train['op_cond'].unique():\n",
    "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
    "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
    "    df = df.copy()\n",
    "    # first, calculate the exponential weighted mean of desired sensors\n",
    "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
    "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
    "    def create_mask(data, samples):\n",
    "        result = np.ones_like(data)\n",
    "        result[0:samples] = 0\n",
    "        return result\n",
    "\n",
    "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
    "    df = df[mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "#the score defined in the paper\n",
    "def compute_s_score(rul_true, rul_pred):\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "\n",
    "#evaluate the model with R² and RMSE\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "\n",
    "def generate_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of a given length from the input data.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    # Generate sequences using sliding windows\n",
    "    for start_idx in range(num_samples - sequence_length + 1):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        yield data[start_idx:end_idx, :]\n",
    "\n",
    "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate sequences for multiple units in the dataset.\n",
    "    \"\"\"\n",
    "    if unit_nrs is None:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    # Generate sequences for each unit and concatenate them\n",
    "    all_sequences = []\n",
    "    for unit_nr in unit_nrs:\n",
    "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
    "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return np.array(all_sequences, dtype=np.float32)\n",
    "\n",
    "\n",
    "def gen_train_data(df, sequence_length, columns):\n",
    "    data = df[columns].values\n",
    "    num_elements = data.shape[0]\n",
    "\n",
    "    # -1 and +1 because of Python indexing\n",
    "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
    "        yield data[start:stop, :]\n",
    "\n",
    "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
    "               for unit_nr in unit_nrs)\n",
    "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
    "    return data_array\n",
    "\n",
    "def create_model(TW , remaining_):\n",
    "#     history = History()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_MAPE(y_true, y_hat):\n",
    "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
    "    return mape\n",
    "\n",
    "def gen_labels(df, sequence_length, label):\n",
    "    data_matrix = df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
    "    return data_matrix[sequence_length-1:num_elements, :]\n",
    "\n",
    "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
    "                for unit_nr in unit_nrs]\n",
    "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "    return label_array\n",
    "def gen_test_data(df, sequence_length, columns, mask_value):\n",
    "    if df.shape[0] < sequence_length:\n",
    "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
    "        idx = data_matrix.shape[0] - df.shape[0]\n",
    "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
    "    else:\n",
    "        data_matrix = df[columns].values\n",
    "\n",
    "    # specifically yield the last possible sequence\n",
    "    stop = num_elements = data_matrix.shape[0]\n",
    "    start = stop - sequence_length\n",
    "    for i in list(range(1)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "\n",
    "\n",
    "def new_column (df, column):\n",
    "    #df = df.sort_values(by=column, ascending=False)\n",
    "    df[column] = range(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3reK6P4D-4XM"
   },
   "source": [
    "# Préparation des données et configuration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1832,
     "status": "ok",
     "timestamp": 1745477625262,
     "user": {
      "displayName": "El Hadji Malick Sy",
      "userId": "07326824895633266968"
     },
     "user_tz": -120
    },
    "id": "ZQiI0neXGngG",
    "outputId": "4e112352-9645-4bf5-cc22-27725fb921d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 120\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "# Configuration des paramètres\n",
    "alpha = 0.2\n",
    "sequence_length = 40\n",
    "epochs = 10\n",
    "#nodes_per_layer = [64]\n",
    "#dropout = 0.2\n",
    "activation = 'tanh'\n",
    "batch_size = 32\n",
    "remaining_sensors = remaining_sensors\n",
    "input_shape = (sequence_length, len(remaining_sensors))\n",
    "\n",
    "#preciser la regle utilisee avec la ref(auteur)\n",
    "#hidden_size_list = [32, 64, 128, 256]\n",
    "space_val = {\n",
    "    'hidden_size': {\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "        'step': 32\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'min': np.log(1e-5),\n",
    "        'max': np.log(1e-2),\n",
    "        'num': 10\n",
    "    },\n",
    "    'dropout': {\n",
    "        'min': 0.1,\n",
    "        'max': 0.5,\n",
    "        'step': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Préparation des données\n",
    "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\n",
    "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "path_bayesian = '../data/grid_bayesian_random20/fd004_bayesian20.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yC6kum8dWzB"
   },
   "source": [
    "# Bayesian Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzO_WAqMXrHk"
   },
   "source": [
    "## Creation et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KdXdtod0er4D"
   },
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
    "def train_model(params):\n",
    "    # Création du modèle\n",
    "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, params['learning_rate'])\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=3,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "    # Retourner la RMSE comme métrique à minimiser\n",
    "    return {'loss': rmse, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEaXloQYQXC"
   },
   "source": [
    "## Apply HyperOpt TPE and store the combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmtmfU5JPTmh",
    "outputId": "e506f1d7-5c59-4d13-d998-63cf7b1f3b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting optimization run 1/20\n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:26<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results_all\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Execute the optimization 20 times\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m final_results = \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(final_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mrun_optimization\u001b[39m\u001b[34m(num_runs)\u001b[39m\n\u001b[32m     26\u001b[39m start_time = time.time()\n\u001b[32m     28\u001b[39m trials = Trials()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m best = \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of evaluations per run\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Get best trial results\u001b[39;00m\n\u001b[32m     39\u001b[39m decoded_best = space_eval(space, best)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    537\u001b[39m     fn = __objective_fmin_wrapper(fn)\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[33m\"\u001b[39m\u001b[33mfmin\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(trials_save_file):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[39m, in \u001b[36mTrials.fmin\u001b[39m\u001b[34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[39m, in \u001b[36mfmin\u001b[39m\u001b[34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[39m\n\u001b[32m    583\u001b[39m rval.catch_eval_exceptions = catch_eval_exceptions\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m \u001b[43mrval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[32m    589\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials.trials) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[39m, in \u001b[36mFMinIter.exhaust\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    363\u001b[39m     n_done = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.trials)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[39m, in \u001b[36mFMinIter.run\u001b[39m\u001b[34m(self, N, block_until_done)\u001b[39m\n\u001b[32m    297\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m.poll_interval_secs)\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28mself\u001b[39m.trials.refresh()\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trials_save_file != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[39m, in \u001b[36mFMinIter.serial_evaluate\u001b[39m\u001b[34m(self, N)\u001b[39m\n\u001b[32m    176\u001b[39m ctrl = base.Ctrl(\u001b[38;5;28mself\u001b[39m.trials, current_trial=trial)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    180\u001b[39m     logger.error(\u001b[33m\"\u001b[39m\u001b[33mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[39m, in \u001b[36mDomain.evaluate\u001b[39m\u001b[34m(self, config, ctrl, attach_attachments)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    884\u001b[39m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[32m    885\u001b[39m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[32m    887\u001b[39m     pyll_rval = pyll.rec_eval(\n\u001b[32m    888\u001b[39m         \u001b[38;5;28mself\u001b[39m.expr,\n\u001b[32m    889\u001b[39m         memo=memo,\n\u001b[32m    890\u001b[39m         print_node_on_error=\u001b[38;5;28mself\u001b[39m.rec_eval_print_node_on_error,\n\u001b[32m    891\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     rval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np.number)):\n\u001b[32m    895\u001b[39m     dict_rval = {\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m: STATUS_OK}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     13\u001b[39m model = model_lstm_1layer(input_shape, params[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m], params[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m], activation, params[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rul\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Prédiction sur l'ensemble de validation\u001b[39;00m\n\u001b[32m     25\u001b[39m y_pred = model.predict(test_array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\RA-RV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize results dataframe with all relevant columns\n",
    "results_all = pd.DataFrame()\n",
    "set_seed(42)\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size',\n",
    "                              space_val['hidden_size']['min'],\n",
    "                              space_val['hidden_size']['max'],\n",
    "                              space_val['hidden_size']['step']),\n",
    "    'learning_rate': hp.loguniform('learning_rate',\n",
    "                              space_val['learning_rate']['min'],\n",
    "                              space_val['learning_rate']['max']),\n",
    "    'dropout': hp.quniform('dropout',\n",
    "                           space_val['dropout']['min'],\n",
    "                           space_val['dropout']['max'],\n",
    "                           space_val['dropout']['step'])\n",
    "}\n",
    "\n",
    "# Run Bayesian optimization multiple times\n",
    "def run_optimization(num_runs=20):\n",
    "    global results_all\n",
    "\n",
    "    for run_id in range(1, num_runs + 1):\n",
    "        print(f\"\\nStarting optimization run {run_id}/{num_runs}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        trials = Trials()\n",
    "\n",
    "        best = fmin(\n",
    "            fn=train_model,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,  # Number of evaluations per run\n",
    "            trials=trials\n",
    "        )\n",
    "\n",
    "        # Get best trial results\n",
    "        decoded_best = space_eval(space, best)\n",
    "\n",
    "        print(\"Best Hyperparameters:\")\n",
    "        print(decoded_best)\n",
    "\n",
    "        best_trial = trials.best_trial\n",
    "        time_training = time.time() - start_time\n",
    "\n",
    "        best_rmse = trials.best_trial['result']['rmse']\n",
    "        best_s_score = trials.best_trial['result']['s_score']\n",
    "        best_mape = trials.best_trial['result']['mape']\n",
    "        best_r2 = trials.best_trial['result']['loss']\n",
    "\n",
    "\n",
    "        new_result = {\n",
    "          'id': run_id,\n",
    "          'hidden_size': decoded_best['hidden_size'],\n",
    "          'learning_rate': best['learning_rate'],\n",
    "          'dropout': best['dropout'],\n",
    "          'rmse': best_rmse,\n",
    "          's_score': best_s_score,\n",
    "          'mape': best_mape,\n",
    "          'r2': -best_r2,\n",
    "          'training_time': time_training\n",
    "      }\n",
    "        print(results_all)\n",
    "\n",
    "        # Update results dataframe\n",
    "        results_all = pd.concat([results_all, pd.DataFrame([new_result])], ignore_index=True)\n",
    "\n",
    "        # Save to CSV after each run\n",
    "        results_all.to_csv(path_bayesian, index=False)\n",
    "\n",
    "    return results_all\n",
    "\n",
    "# Execute the optimization 20 times\n",
    "final_results = run_optimization(num_runs=20)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pORtv7grZNDT"
   },
   "source": [
    "## Visualisation de la moyenne et l'ecart type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asaw6-yBiKlb"
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjiBDt67iN4L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/20 - LSTM units=224, LR=0.00801, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "→ RMSE: 19.1663, Time: 253.96s\n",
      "Trial 2/20 - LSTM units=64, LR=0.00002, dropout=0.4\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020816663920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 25.1781, Time: 107.02s\n",
      "Trial 3/20 - LSTM units=64, LR=0.00002, dropout=0.1\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002081BEE4900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 21.2680, Time: 106.52s\n",
      "Trial 4/20 - LSTM units=96, LR=0.00009, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 26.8661, Time: 150.48s\n",
      "Trial 5/20 - LSTM units=96, LR=0.00260, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 23.4732, Time: 148.39s\n",
      "Trial 6/20 - LSTM units=224, LR=0.00101, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "→ RMSE: 13.2279, Time: 275.48s\n",
      "Trial 7/20 - LSTM units=96, LR=0.00409, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "→ RMSE: 13.2683, Time: 145.23s\n",
      "Trial 8/20 - LSTM units=160, LR=0.00002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 29.3626, Time: 201.41s\n",
      "Trial 9/20 - LSTM units=96, LR=0.00002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "→ RMSE: 28.0723, Time: 144.45s\n",
      "Trial 10/20 - LSTM units=160, LR=0.00022, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 28.9663, Time: 220.96s\n",
      "Trial 11/20 - LSTM units=64, LR=0.00004, dropout=0.30000000000000004\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "→ RMSE: 19.1588, Time: 118.57s\n",
      "Trial 12/20 - LSTM units=192, LR=0.00427, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "→ RMSE: 13.5366, Time: 241.54s\n",
      "Trial 13/20 - LSTM units=160, LR=0.00015, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "→ RMSE: 24.0653, Time: 202.54s\n",
      "Trial 14/20 - LSTM units=224, LR=0.00059, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "→ RMSE: 20.3910, Time: 257.22s\n",
      "Trial 15/20 - LSTM units=256, LR=0.00563, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "→ RMSE: 21.3126, Time: 295.18s\n",
      "Trial 16/20 - LSTM units=160, LR=0.00343, dropout=0.2\n"
     ]
    }
   ],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Output for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Number of random trials\n",
    "n_trials = 20\n",
    "\n",
    "# Container for results\n",
    "results_all = pd.DataFrame()\n",
    "\n",
    "# Random Search\n",
    "for i in range(n_trials):\n",
    "    # Sample hyperparameters\n",
    "    #hidden_size = random.randint(space_val['hidden_size']['min'], space_val['hidden_size']['max'])\n",
    "    #hidden_size =  random.choice([32, 64, 128, 256]),\n",
    "    hidden_size = round(random.uniform(\n",
    "        space_val['hidden_size']['min'],\n",
    "        space_val['hidden_size']['max']\n",
    "    ) / space_val['hidden_size']['step']) * space_val['hidden_size']['step']\n",
    "\n",
    "    learning_rate = np.exp(random.uniform(space_val['learning_rate']['min'], space_val['learning_rate']['max']))\n",
    "    dropout = round(random.uniform(\n",
    "        space_val['dropout']['min'],\n",
    "        space_val['dropout']['max']\n",
    "    ) / space_val['dropout']['step']) * space_val['dropout']['step']\n",
    "\n",
    "    print(f\"Trial {i+1}/{n_trials} - LSTM units={hidden_size}, LR={learning_rate:.5f}, dropout={dropout}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Build and train model\n",
    "    model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(test_array)\n",
    "    rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "    score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    print(f\"→ RMSE: {rmse:.4f}, Time: {training_time:.2f}s\")\n",
    "\n",
    "    # Save to results\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "        'id': i + 1,\n",
    "        'hidden_size': hidden_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'dropout': dropout,\n",
    "        'rmse': rmse,\n",
    "        's-score': score,\n",
    "        'mape': mape,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    results_all.to_csv(path_random, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 27.8205\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 24.3584\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 30.1438\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 24.8540\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 27.0758\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.5673\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 19.8573\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.3990\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.5317\n",
      "Training with LSTM units=32, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 22.7354\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 18.3365\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 20.7359\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 18.7032\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 19.8988\n",
      "Training with LSTM units=32, learning_rate=0.0001, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 23.9797\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.2596\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 23.6727\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 15.9821\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.5707\n",
      "Training with LSTM units=32, learning_rate=0.0002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.1403\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.6423\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 15.8134\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 15.3504\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 14.5059\n",
      "Training with LSTM units=32, learning_rate=0.0005, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 16.0224\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.7486\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.0498\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.6125\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.0654\n",
      "Training with LSTM units=32, learning_rate=0.0014, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 13.5477\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.5278\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 13.1948\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.2197\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 12.6462\n",
      "Training with LSTM units=32, learning_rate=0.0037, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 13.2254\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 14.7240\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 13.8957\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 14.4007\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 15.1873\n",
      "Training with LSTM units=32, learning_rate=0.0100, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 16.2322\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 27.6322\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 27.5764\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 24.9609\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 24.7074\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.2368\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.6937\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Validation RMSE: 20.8067\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.2445\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.1430\n",
      "Training with LSTM units=64, learning_rate=0.0000, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.6419\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 23.5498\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.7372\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 22.7971\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Validation RMSE: 21.6644\n",
      "Training with LSTM units=64, learning_rate=0.0001, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 24.3405\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 17.9511\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 17.6603\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 19.9210\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 18.8494\n",
      "Training with LSTM units=64, learning_rate=0.0002, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 24.6283\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.7392\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.2\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 14.9248\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 14.2749\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 16.3928\n",
      "Training with LSTM units=64, learning_rate=0.0005, dropout=0.5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Validation RMSE: 14.6107\n",
      "Training with LSTM units=64, learning_rate=0.0014, dropout=0.1\n"
     ]
    }
   ],
   "source": [
    "# Generate grid values from space_val\n",
    "param_grid = {\n",
    "    'hidden_size': [32, 64, 96, 128, 160, 192, 224, 256],\n",
    "\n",
    "    'learning_rate': [np.exp(x) for x in np.linspace(\n",
    "        space_val['learning_rate']['min'],\n",
    "        space_val['learning_rate']['max'],\n",
    "        num=space_val['learning_rate']['num']\n",
    "    )],\n",
    "    'dropout': np.round(np.arange(\n",
    "        space_val['dropout']['min'],\n",
    "        space_val['dropout']['max'] + 0.001,\n",
    "        space_val['dropout']['step']\n",
    "    ), 2)\n",
    "}\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# -------------------------\n",
    "# LSTM Model Function\n",
    "# -------------------------\n",
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# Grid Search\n",
    "# -------------------------\n",
    "results_all = pd.DataFrame()\n",
    "i = 0\n",
    "set_seed(SEED)\n",
    "for hidden_size in param_grid['hidden_size']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
    "\n",
    "            with tf.device('/device:GPU:0'):\n",
    "                start_time = time.time()\n",
    "                # Build and train model\n",
    "                model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
    "                history = model.fit(\n",
    "                    train_array, label_array,\n",
    "                    validation_data=(test_array, test_rul),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[early_stop]\n",
    "                )\n",
    "\n",
    "                # Predict and evaluate\n",
    "                y_pred = model.predict(test_array)\n",
    "                rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "                s_score = compute_s_score(test_rul, y_pred)\n",
    "                mape = compute_MAPE(test_rul, y_pred)\n",
    "                r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "            time_training = time.time() - start_time\n",
    "            i += 1\n",
    "\n",
    "            # Save results\n",
    "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "                'id': i,\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'dropout': dropout,\n",
    "                'rmse': rmse,\n",
    "                's_score': s_score,\n",
    "                'mape': mape,\n",
    "                'r2': r2,\n",
    "                'training_time': time_training\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            results_all.to_csv(path_grid, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_bayesian)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"rmse\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"RMSE\"\n",
    ")\n",
    "\n",
    "# Highlight the best RMSE (lowest value)\n",
    "best_idx = df[\"rmse\"].idxmin()\n",
    "plt.scatter(\n",
    "    df.loc[best_idx, \"id\"],\n",
    "    df.loc[best_idx, \"rmse\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=f\"Best RMSE: {df.loc[best_idx, 'rmse']:.2f}\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"RMSE Across Hyperparameter Configurations\", fontsize=14)\n",
    "plt.xlabel(\"id\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "plt.xticks(df[\"id\"])\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_random)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(\n",
    "    df[\"id\"],\n",
    "    df[\"rmse\"],\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    markersize=8,\n",
    "    label=\"RMSE\"\n",
    ")\n",
    "\n",
    "# Highlight the best RMSE (lowest value)\n",
    "best_idx = df[\"rmse\"].idxmin()\n",
    "plt.scatter(\n",
    "    df.loc[best_idx, \"id\"],\n",
    "    df.loc[best_idx, \"rmse\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    label=f\"Best RMSE: {df.loc[best_idx, 'rmse']:.2f}\",\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"RMSE Across Hyperparameter Configurations\", fontsize=14)\n",
    "plt.xlabel(\"ID\", fontsize=12)\n",
    "plt.ylabel(\"RMSE\", fontsize=12)\n",
    "plt.xticks(df[\"id\"])\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1qzNWs_zEhJG",
    "w3R-Zqn8b7-s",
    "3reK6P4D-4XM",
    "6XjaNrNBnLtk",
    "LzO_WAqMXrHk",
    "YPEaXloQYQXC",
    "bb-N_tnveCiW"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
