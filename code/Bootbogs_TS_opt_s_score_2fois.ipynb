{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qzNWs_zEhJG"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MuCQx7XbGnf_"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from math import sqrt, pow\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# Optimization\n",
    "from scipy import optimize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from hyperopt import fmin, tpe, Trials, hp, STATUS_OK\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 0\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "# Appeler la fonction pour fixer le seed\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3R-Zqn8b7-s"
   },
   "source": [
    "# Methode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_gfR4rmnddop"
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def prep_data(train, test, drop_sensors, remaining_sensors, alpha, drop = True):\n",
    "    if drop:\n",
    "        X_train_interim = add_operating_condition(train.drop(drop_sensors, axis=1))\n",
    "        X_test_interim = add_operating_condition(test.drop(drop_sensors, axis=1))\n",
    "    else:\n",
    "        X_train_interim = add_operating_condition(train)\n",
    "        X_test_interim = add_operating_condition(test)\n",
    "\n",
    "    X_train_interim, X_test_interim = condition_scaler(X_train_interim, X_test_interim, remaining_sensors)\n",
    "    X_train_interim = exponential_smoothing(X_train_interim, remaining_sensors, 0, alpha)\n",
    "    X_test_interim = exponential_smoothing(X_test_interim, remaining_sensors, 0, alpha)\n",
    "\n",
    "    return X_train_interim, X_test_interim\n",
    "\n",
    "def rul_piecewise_fct(X_train, rul):\n",
    "\n",
    "    X_train['RUL'].clip(upper=rul, inplace=True)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def prepare_data(file_name):\n",
    "    dir_path =  'C:/Users/RA-RV/Documents/Malick/data/'\n",
    "    dependent_var = ['RUL']\n",
    "    index_names = ['Unit', 'Cycle']\n",
    "    setting_names = ['Altitude', 'Mach', 'TRA']\n",
    "    sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "    col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "    df_train = pd.read_csv(dir_path+'train_'+str(file_name),delim_whitespace=True,names=col_names)\n",
    "\n",
    "    rul_train = pd.DataFrame(df_train.groupby('Unit')['Cycle'].max()).reset_index()\n",
    "    rul_train.columns = ['Unit', 'max']\n",
    "    df_train = df_train.merge(rul_train, on=['Unit'], how='left')\n",
    "    df_train['RUL'] = df_train['max'] - df_train['Cycle']\n",
    "    df_train.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    df_test = pd.read_csv(dir_path+'test_'+str(file_name), delim_whitespace=True, names=col_names)\n",
    "\n",
    "    y_test = pd.read_csv(dir_path+'RUL_'+(file_name), delim_whitespace=True,names=[\"RUL\"])\n",
    "    #y_true[\"Unit\"] = y_true.index + 1\n",
    "    return df_train, df_test, y_test\n",
    "\n",
    "\n",
    "# add operational condition to then normalize the data based on these operational conditions test\n",
    "def add_operating_condition(df):\n",
    "    df_op_cond = df.copy()\n",
    "\n",
    "    df_op_cond['Altitude'] = df_op_cond['Altitude'].round()\n",
    "    df_op_cond['Mach'] = df_op_cond['Mach'].round(decimals=2)\n",
    "    df_op_cond['TRA'] = df_op_cond['TRA'].round()\n",
    "\n",
    "    # converting settings to string and concatanating makes the operating condition into a categorical variable\n",
    "    df_op_cond['op_cond'] = df_op_cond['Altitude'].astype(str) + '_' + \\\n",
    "                        df_op_cond['Mach'].astype(str) + '_' + \\\n",
    "                        df_op_cond['TRA'].astype(str)\n",
    "\n",
    "    return df_op_cond\n",
    "\n",
    "# normalize the data based on the operational condition\n",
    "def condition_scaler(df_train, df_test, sensor_names):\n",
    "  # apply operating condition specific scaling\n",
    "  #scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    for condition in df_train['op_cond'].unique():\n",
    "        scaler.fit(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_train.loc[df_train['op_cond']==condition, sensor_names] = scaler.transform(df_train.loc[df_train['op_cond']==condition, sensor_names])\n",
    "        df_test.loc[df_test['op_cond']==condition, sensor_names] = scaler.transform(df_test.loc[df_test['op_cond']==condition, sensor_names])\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "#to plot each sensors with respect to the RUL\n",
    "def plot_signal(df, signal_name, unit=None):\n",
    "#     train = df\n",
    "    plt.figure(figsize=(13,5))\n",
    "    if unit:\n",
    "        plt.plot('RUL', signal_name,\n",
    "                data=df[df['Unit']==unit])\n",
    "    else:\n",
    "        for i in df['Unit'].unique():\n",
    "            if (i % 10 == 0):  # only ploting every 10th unit_nr\n",
    "                plt.plot('RUL', signal_name,\n",
    "                         data=df[df['Unit']==i])\n",
    "    plt.xlim(350, 0)  # reverse the x-axis so RUL counts down to zero\n",
    "    plt.xticks(np.arange(0, 375, 25))\n",
    "    plt.ylabel(signal_name)\n",
    "    plt.xlabel('Remaining Use fulLife')\n",
    "    #plt.savefig(signal_name+'.jpeg')\n",
    "    plt.show()\n",
    "\n",
    "# denoise the signal using the exponential signal wih an alpha equals to 0.3\n",
    "def exponential_smoothing(df, sensors, n_samples, alpha=0.2):\n",
    "    df = df.copy()\n",
    "    # first, calculate the exponential weighted mean of desired sensors\n",
    "    new_column = df.groupby('Unit')[sensors].apply(lambda x: x.ewm(alpha=alpha).mean())\n",
    "    df[sensors] = new_column.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    # second, drop first n_samples of each unit_nr to reduce filter delay\n",
    "    def create_mask(data, samples):\n",
    "        result = np.ones_like(data)\n",
    "        result[0:samples] = 0\n",
    "        return result\n",
    "\n",
    "    mask = df.groupby('Unit')['Unit'].transform(create_mask, samples=n_samples).astype(bool)\n",
    "    df = df[mask]\n",
    "\n",
    "    return df\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "#the score defined in the paper\n",
    "def compute_s_score(rul_true, rul_pred):\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "\n",
    "#evaluate the model with R² and RMSE\n",
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))\n",
    "\n",
    "def generate_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Generate sequences of a given length from the input data.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    # Generate sequences using sliding windows\n",
    "    for start_idx in range(num_samples - sequence_length + 1):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        yield data[start_idx:end_idx, :]\n",
    "\n",
    "def generate_data_wrapper(df, sequence_length, columns, unit_nrs=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to generate sequences for multiple units in the dataset.\n",
    "    \"\"\"\n",
    "    if unit_nrs is None:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    # Generate sequences for each unit and concatenate them\n",
    "    all_sequences = []\n",
    "    for unit_nr in unit_nrs:\n",
    "        unit_data = df[df['Unit'] == unit_nr][columns].values\n",
    "        sequences = list(generate_sequences(unit_data, sequence_length))\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return np.array(all_sequences, dtype=np.float32)\n",
    "\n",
    "\n",
    "def gen_train_data(df, sequence_length, columns):\n",
    "    data = df[columns].values\n",
    "    num_elements = data.shape[0]\n",
    "\n",
    "    # -1 and +1 because of Python indexing\n",
    "    for start, stop in zip(range(0, num_elements-(sequence_length-1)), range(sequence_length, num_elements+1)):\n",
    "        yield data[start:stop, :]\n",
    "\n",
    "def gen_data_wrapper(df, sequence_length, columns, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    data_gen = (list(gen_train_data(df[df['Unit']==unit_nr], sequence_length, columns))\n",
    "               for unit_nr in unit_nrs)\n",
    "    data_array = np.concatenate(list(data_gen)).astype(np.float32)\n",
    "    return data_array\n",
    "\n",
    "def create_model(TW , remaining_):\n",
    "#     history = History()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='tanh',input_shape=(TW, len(remaining_))))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    #model.add(GlobalAveragePooling1D(name = 'feature_layer'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse',metrics=['mse'], optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "    return model\n",
    "\n",
    "def compute_MAPE(y_true, y_hat):\n",
    "    mape = np.mean(np.abs((y_true - y_hat)/y_true))*100\n",
    "    return mape\n",
    "\n",
    "def gen_labels(df, sequence_length, label):\n",
    "    data_matrix = df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "\n",
    "    # -1 because I want to predict the rul of that last row in the sequence, not the next row\n",
    "    return data_matrix[sequence_length-1:num_elements, :]\n",
    "\n",
    "def gen_label_wrapper(df, sequence_length, label, unit_nrs=np.array([])):\n",
    "    if unit_nrs.size <= 0:\n",
    "        unit_nrs = df['Unit'].unique()\n",
    "\n",
    "    label_gen = [gen_labels(df[df['Unit']==unit_nr], sequence_length, label)\n",
    "                for unit_nr in unit_nrs]\n",
    "    label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "    return label_array\n",
    "def gen_test_data(df, sequence_length, columns, mask_value):\n",
    "    if df.shape[0] < sequence_length:\n",
    "        data_matrix = np.full(shape=(sequence_length, len(columns)), fill_value=mask_value) # pad\n",
    "        idx = data_matrix.shape[0] - df.shape[0]\n",
    "        data_matrix[idx:,:] = df[columns].values  # fill with available data\n",
    "    else:\n",
    "        data_matrix = df[columns].values\n",
    "\n",
    "    # specifically yield the last possible sequence\n",
    "    stop = num_elements = data_matrix.shape[0]\n",
    "    start = stop - sequence_length\n",
    "    for i in list(range(1)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def new_column (df, column):\n",
    "    #df = df.sort_values(by=column, ascending=False)\n",
    "    df[column] = range(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3reK6P4D-4XM"
   },
   "source": [
    "# Préparation des données et configuration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1747643898102,
     "user": {
      "displayName": "El Hadji Malick Sy",
      "userId": "07326824895633266968"
     },
     "user_tz": -120
    },
    "id": "ZQiI0neXGngG",
    "outputId": "536c9759-97e5-4d2b-8061-003dfb2fa6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                     'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 130\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "# Configuration des paramètres\n",
    "alpha = 0.2\n",
    "sequence_length = 40\n",
    "epochs = 20\n",
    "#nodes_per_layer = [64]\n",
    "#dropout = 0.2\n",
    "activation = 'tanh'\n",
    "batch_size = 32\n",
    "remaining_sensors = remaining_sensors\n",
    "input_shape = (sequence_length, len(remaining_sensors))\n",
    "\n",
    "space_val = {\n",
    "    'hidden_size': {\n",
    "        'min': 32,\n",
    "        'max': 256,\n",
    "        'step': 32\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'min': np.log(1e-5),\n",
    "        'max': np.log(1e-2)\n",
    "    },\n",
    "    'dropout': {\n",
    "        'min': 0.1,\n",
    "        'max': 0.5,\n",
    "        'step': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Préparation des données\n",
    "X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "\n",
    "test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "path_bootstrap = 'C:/Users/RA-RV/Documents/Malick/data/fd004_bootstrap_s_score2_LR_Arr111.csv'\n",
    "path_bootstrap2 = 'C:/Users/RA-RV/Documents/Malick/data/fd004_bootstrap2_s_score_LR_Arr111.csv'\n",
    "path_grid = 'C:/Users/RA-RV/Documents/Malick/data/fd004_grid_search_bootstrap_s_score_LR_Arr111.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yC6kum8dWzB"
   },
   "source": [
    "# Bayesian optimization avec bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XjaNrNBnLtk"
   },
   "source": [
    "## Creer n series bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8y_6F-lTnTA5"
   },
   "outputs": [],
   "source": [
    "def create_multivariate_bootstrap_series(data, sequence_length, n_bootstrap):\n",
    "\n",
    "    n_timesteps = len(data)\n",
    "    n_blocks = n_timesteps // sequence_length  # Nombre de blocs complets\n",
    "    bootstrap_series_list = []\n",
    "\n",
    "    # Découper la série en blocs\n",
    "    blocks = [data[i * sequence_length:(i + 1) * sequence_length] for i in range(n_blocks)]\n",
    "\n",
    "    # Créer chaque série bootstrap\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Rééchantillonner les blocs avec remise\n",
    "        sampled_blocks = [blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)]\n",
    "\n",
    "        # Concaténer les blocs pour former une nouvelle série\n",
    "        new_series = np.concatenate(sampled_blocks, axis=0)\n",
    "\n",
    "        if len(new_series) > n_timesteps:\n",
    "            new_series = new_series[:n_timesteps]\n",
    "\n",
    "        elif len(new_series) < n_timesteps:\n",
    "          remaining_length = n_timesteps - len(new_series)\n",
    "          new_series = np.concatenate([new_series, new_series[-sequence_length:][:remaining_length]], axis=0)\n",
    "\n",
    "        bootstrap_series_list.append(new_series)\n",
    "\n",
    "    return bootstrap_series_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzO_WAqMXrHk"
   },
   "source": [
    "## Creation et entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KdXdtod0er4D"
   },
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(nodes_per_layer), activation=activation, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))  # Sortie pour la régression\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model\n",
    "\n",
    "# Fonction pour entraîner le modèle et évaluer la RMSE\n",
    "def train_model(params):\n",
    "    # Création du modèle\n",
    "    model = model_lstm_1layer(input_shape, params['hidden_size'], params['dropout'], activation, round(params['learning_rate'], 5))\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # Désactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "\n",
    "  # minimiser RMSE/s-score\n",
    "\n",
    "    # Retourner la RMSE comme métrique à minimiser\n",
    "    return {'loss': s_score, 'status': STATUS_OK, 's_score':s_score, 'mape':mape, 'rmse':rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPEaXloQYQXC"
   },
   "source": [
    "## Apply HyperOpt TPE and store the combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LmtmfU5JPTmh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de la série bootstrap 1...\n",
      "(51545, 40, 17) (51545, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step          \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 188ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 156ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:19:06<00:00, 474.68s/trial, best loss: 2205.189229499206]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "\n",
      "       s_score      mape        r2  training_time  \n",
      "0  2860.450691  47.09875  0.776731     5107.49225  \n",
      "Traitement de la série bootstrap 2...\n",
      "(51552, 40, 17) (51552, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 185ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 131ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 144ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 154ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 583ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:29:16<00:00, 535.70s/trial, best loss: 2405.0266453320864]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731     5107.49225  \n",
      "1  2864.341255  31.993062  0.767025     6224.00431  \n",
      "Traitement de la série bootstrap 3...\n",
      "(51589, 40, 17) (51589, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 144ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 163ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 140ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 183ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 160ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:12:51<00:00, 437.14s/trial, best loss: 2935.255282680244]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "Traitement de la série bootstrap 4...\n",
      "(51577, 40, 17) (51577, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step          \n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 143ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 143ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:25:13<00:00, 511.34s/trial, best loss: 1927.851904093238]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "Traitement de la série bootstrap 5...\n",
      "(51587, 40, 17) (51587, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 155ms/step\n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 198ms/step          \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 207ms/step          \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 172ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 169ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:42:48<00:00, 616.83s/trial, best loss: 2080.517947224414]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "Traitement de la série bootstrap 6...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 168ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 154ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 146ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 152ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:19:08<00:00, 474.89s/trial, best loss: 1502.5963996016258]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "5                 6         64.0        0.00700      0.3  18.659540   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "5  1548.806263  38.570579  0.823384    5040.677140  \n",
      "Traitement de la série bootstrap 7...\n",
      "(51538, 40, 17) (51538, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 157ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 5s/step             \n",
      "\u001b[1m4/8\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 123ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "100%|██████████| 10/10 [1:39:32<00:00, 597.21s/trial, best loss: 2187.11198174975]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "5                 6         64.0        0.00700      0.3  18.659540   \n",
      "6                 7         96.0        0.00063      0.4  20.179148   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "5  1548.806263  38.570579  0.823384    5040.677140  \n",
      "6  2524.202712  33.915729  0.793446    6474.120813  \n",
      "Traitement de la série bootstrap 8...\n",
      "(51677, 40, 17) (51677, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step       \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 187ms/step        \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 175ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step        \n",
      "\u001b[1m5/8\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step         \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 174ms/step        \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step          \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 173ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\n",
      "100%|██████████| 10/10 [1:34:14<00:00, 565.45s/trial, best loss: 1971.8519873905957]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "5                 6         64.0        0.00700      0.3  18.659540   \n",
      "6                 7         96.0        0.00063      0.4  20.179148   \n",
      "7                 8         64.0        0.00156      0.3  20.899518   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "5  1548.806263  38.570579  0.823384    5040.677140  \n",
      "6  2524.202712  33.915729  0.793446    6474.120813  \n",
      "7  2768.244103  38.582411  0.778435    6043.360340  \n",
      "Traitement de la série bootstrap 9...\n",
      "(51628, 40, 17) (51628, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 165ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step         \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step         \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 126ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 125ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step          \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step         \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 170ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 153ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 153ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:38:35<00:00, 591.55s/trial, best loss: 2201.9570269881506]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "5                 6         64.0        0.00700      0.3  18.659540   \n",
      "6                 7         96.0        0.00063      0.4  20.179148   \n",
      "7                 8         64.0        0.00156      0.3  20.899518   \n",
      "8                 9        224.0        0.00221      0.4  20.337476   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "5  1548.806263  38.570579  0.823384    5040.677140  \n",
      "6  2524.202712  33.915729  0.793446    6474.120813  \n",
      "7  2768.244103  38.582411  0.778435    6043.360340  \n",
      "8  2799.730884  37.319410  0.790192    6720.393760  \n",
      "Traitement de la série bootstrap 10...\n",
      "(51564, 40, 17) (51564, 1) (248, 40, 17)\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step          \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step           \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 162ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 154ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 189ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 171ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 184ms/step           \n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 178ms/step           \n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step            \n",
      "\n",
      "100%|██████████| 10/10 [1:48:08<00:00, 648.81s/trial, best loss: 2519.3569106597333]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "   bootstrap_series  hidden_size  learning_rate  dropout       rmse  \\\n",
      "0                 1         96.0        0.00063      0.3  20.979712   \n",
      "1                 2        224.0        0.00067      0.4  21.430902   \n",
      "2                 3         32.0        0.00768      0.4  21.364736   \n",
      "3                 4         64.0        0.00486      0.1  21.494669   \n",
      "4                 5        128.0        0.00893      0.4  24.364150   \n",
      "5                 6         64.0        0.00700      0.3  18.659540   \n",
      "6                 7         96.0        0.00063      0.4  20.179148   \n",
      "7                 8         64.0        0.00156      0.3  20.899518   \n",
      "8                 9        224.0        0.00221      0.4  20.337476   \n",
      "9                10        160.0        0.00194      0.2  23.618641   \n",
      "\n",
      "       s_score       mape        r2  training_time  \n",
      "0  2860.450691  47.098750  0.776731    5107.492250  \n",
      "1  2864.341255  31.993062  0.767025    6224.004310  \n",
      "2  2609.476349  51.233532  0.768461    4602.941152  \n",
      "3  2825.800179  41.690323  0.765636    5412.700163  \n",
      "4  2756.726472  47.911757  0.698886    6673.513383  \n",
      "5  1548.806263  38.570579  0.823384    5040.677140  \n",
      "6  2524.202712  33.915729  0.793446    6474.120813  \n",
      "7  2768.244103  38.582411  0.778435    6043.360340  \n",
      "8  2799.730884  37.319410  0.790192    6720.393760  \n",
      "9  5143.972751  39.311913  0.717031    7121.980849  \n"
     ]
    }
   ],
   "source": [
    "bootstrap_series_list = create_multivariate_bootstrap_series(train, sequence_length, 10)\n",
    "results_all = pd.DataFrame()\n",
    "for i, series in enumerate(bootstrap_series_list):\n",
    "    print(f\"Traitement de la série bootstrap {i + 1}...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    space = {\n",
    "        'hidden_size': hp.quniform('hidden_size',\n",
    "                              space_val['hidden_size']['min'],\n",
    "                              space_val['hidden_size']['max'],\n",
    "                              space_val['hidden_size']['step']),\n",
    "\n",
    "        'learning_rate': hp.loguniform('learning_rate',\n",
    "                                    space_val['learning_rate']['min'],\n",
    "                                    space_val['learning_rate']['max']),\n",
    "\n",
    "        'dropout': hp.quniform('dropout',\n",
    "                              space_val['dropout']['min'],\n",
    "                              space_val['dropout']['max'],\n",
    "                              space_val['dropout']['step'])\n",
    "    }\n",
    "\n",
    "    series = pd.DataFrame(series, columns=train.columns)\n",
    "    series['RUL'].clip(upper=rul_piecewise, inplace=True)\n",
    "\n",
    "    X_train_interim, X_test_interim = prep_data(series, test, drop_sensors, remaining_sensors, alpha)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = generate_data_wrapper(X_train_interim, sequence_length, remaining_sensors)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit'] == unit_nr], sequence_length, remaining_sensors, -99.))\n",
    "                for unit_nr in X_test_interim['Unit'].unique())\n",
    "\n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test, rul_piecewise)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "\n",
    "    # Optimisation bayésienne avec Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=train_model,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    model = model_lstm_1layer(input_shape, best['hidden_size'], best['dropout'], activation, round(best['learning_rate'], 5))\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    history = model.fit(\n",
    "        train_array, label_array,\n",
    "        validation_data=(test_array, test_rul),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        verbose=0  # Désactiver les logs pour une sortie propre\n",
    "    )\n",
    "\n",
    "    # Prédiction sur l'ensemble de validation\n",
    "    y_pred = model.predict(test_array)\n",
    "\n",
    "    # Calcul de la RMSE, S-Score, Mape\n",
    "    rmse = sqrt(mean_squared_error(test_rul, y_pred))\n",
    "    s_score = compute_s_score(test_rul, y_pred)\n",
    "    mape = compute_MAPE(test_rul, y_pred)\n",
    "    r2 = r2_score(test_rul, y_pred)\n",
    "    #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "\n",
    "    time_training = time.time() - start_time\n",
    "    #Sauvegarder les résultats dans un DataFrame\n",
    "\n",
    "    results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "      'bootstrap_series': i + 1,\n",
    "      'hidden_size': best['hidden_size'],\n",
    "      'learning_rate': round(best['learning_rate'], 5),\n",
    "      'dropout': best['dropout'],\n",
    "      'rmse': rmse,\n",
    "      's_score': s_score,\n",
    "      'mape': mape,\n",
    "      'r2': r2,\n",
    "      'training_time': time_training\n",
    "  }])], ignore_index=True)\n",
    "    print(results_all)\n",
    "\n",
    "  # Sauvegarder les résultats dans un fichier CSV après chaque itération\n",
    "    results_all.to_csv(path_bootstrap, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb-N_tnveCiW"
   },
   "source": [
    "# Intervalle de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "llmldvM9GzOr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def intervalle_confiance(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Supprimer les outliers de la colonne \"s_score\" selon la méthode IQR\n",
    "    q1 = df[\"s_score\"].quantile(0.25)\n",
    "    q3 = df[\"s_score\"].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= lower_bound) & (df[\"s_score\"] <= upper_bound)]\n",
    "\n",
    "    # Calculer la moyenne et l'écart type après avoir retiré les outliers\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    # Garder les valeurs dans l'intervalle de confiance (±1 std autour de la moyenne)\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    # Extraire les hyperparamètres\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    # Supprimer doublons et trier\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\", int(len(dropout_final) * len(learning_final) * len(neurons_final)))\n",
    "    print(type(neurons_final))\n",
    "    return dropout_final, learning_final, neurons_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5otejvX00cDt"
   },
   "source": [
    "# 2e TPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I35N2YFk0fT3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV9djbEb0izo"
   },
   "source": [
    "# intervalle de confiance 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dhFy5xw70nqh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def intervalle_confiance2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Supprimer les outliers de la colonne \"s_score\" selon la méthode IQR\n",
    "    q1 = df[\"s_score\"].quantile(0.25)\n",
    "    q3 = df[\"s_score\"].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    df = df[(df[\"s_score\"] >= lower_bound) & (df[\"s_score\"] <= upper_bound)]\n",
    "\n",
    "    # Calculer la moyenne et l'écart type après avoir retiré les outliers\n",
    "    mean_s_score = df[\"s_score\"].mean()\n",
    "    std_s_score = df[\"s_score\"].std()\n",
    "\n",
    "    # Garder les valeurs dans l'intervalle de confiance (±1 std autour de la moyenne)\n",
    "    filtered_df = df[(df[\"s_score\"] >= mean_s_score - std_s_score) & (df[\"s_score\"] <= mean_s_score + std_s_score)]\n",
    "\n",
    "    # Extraire les hyperparamètres\n",
    "    dropout_rates = filtered_df['dropout'].tolist()\n",
    "    learning_rates = filtered_df['learning_rate'].tolist()\n",
    "    neurons_list = filtered_df['hidden_size'].tolist()\n",
    "\n",
    "    # Supprimer doublons et trier\n",
    "    dropout_final = sorted(set(dropout_rates), reverse=True)\n",
    "    learning_final = sorted(set(learning_rates), reverse=True)\n",
    "    neurons_final = sorted(set(neurons_list), reverse=True)\n",
    "\n",
    "    print(\"search space\", int(len(dropout_final) * len(learning_final) * len(neurons_final)))\n",
    "    print(type(neurons_final))\n",
    "    return dropout_final, learning_final, neurons_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71CHXx5siROg"
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yODLXZzQiPlt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search space 72\n",
      "<class 'list'>\n",
      "Training with LSTM units=224.0, learning_rate=0.0089, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 22.8285\n",
      "Training with LSTM units=224.0, learning_rate=0.0089, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 22.2647\n",
      "Training with LSTM units=224.0, learning_rate=0.0089, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 21.4304\n",
      "Training with LSTM units=224.0, learning_rate=0.0049, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 20.4838\n",
      "Training with LSTM units=224.0, learning_rate=0.0049, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 20.7757\n",
      "Training with LSTM units=224.0, learning_rate=0.0049, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 20.9611\n",
      "Training with LSTM units=224.0, learning_rate=0.0022, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 20.5805\n",
      "Training with LSTM units=224.0, learning_rate=0.0022, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 27.0509\n",
      "Training with LSTM units=224.0, learning_rate=0.0022, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 21.8800\n",
      "Training with LSTM units=224.0, learning_rate=0.0016, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 22.2992\n",
      "Training with LSTM units=224.0, learning_rate=0.0016, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Validation RMSE: 23.2662\n",
      "Training with LSTM units=224.0, learning_rate=0.0016, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 23.0677\n",
      "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Validation RMSE: 21.9975\n",
      "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 22.1677\n",
      "Training with LSTM units=224.0, learning_rate=0.0007, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 20.8889\n",
      "Training with LSTM units=224.0, learning_rate=0.0006, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 21.9997\n",
      "Training with LSTM units=224.0, learning_rate=0.0006, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Validation RMSE: 21.7509\n",
      "Training with LSTM units=224.0, learning_rate=0.0006, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 19.2993\n",
      "Training with LSTM units=128.0, learning_rate=0.0089, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 24.8938\n",
      "Training with LSTM units=128.0, learning_rate=0.0089, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Validation RMSE: 22.0012\n",
      "Training with LSTM units=128.0, learning_rate=0.0089, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 21.1553\n",
      "Training with LSTM units=128.0, learning_rate=0.0049, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 19.9980\n",
      "Training with LSTM units=128.0, learning_rate=0.0049, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Validation RMSE: 24.2979\n",
      "Training with LSTM units=128.0, learning_rate=0.0049, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 21.3775\n",
      "Training with LSTM units=128.0, learning_rate=0.0022, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 24.4078\n",
      "Training with LSTM units=128.0, learning_rate=0.0022, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Validation RMSE: 26.1485\n",
      "Training with LSTM units=128.0, learning_rate=0.0022, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Validation RMSE: 22.4885\n",
      "Training with LSTM units=128.0, learning_rate=0.0016, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Validation RMSE: 21.3873\n",
      "Training with LSTM units=128.0, learning_rate=0.0016, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 23.2154\n",
      "Training with LSTM units=128.0, learning_rate=0.0016, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 19.7284\n",
      "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Validation RMSE: 21.7038\n",
      "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Validation RMSE: 23.8383\n",
      "Training with LSTM units=128.0, learning_rate=0.0007, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 20.2221\n",
      "Training with LSTM units=128.0, learning_rate=0.0006, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 21.8994\n",
      "Training with LSTM units=128.0, learning_rate=0.0006, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 21.3471\n",
      "Training with LSTM units=128.0, learning_rate=0.0006, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 22.6054\n",
      "Training with LSTM units=96.0, learning_rate=0.0089, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Validation RMSE: 23.7962\n",
      "Training with LSTM units=96.0, learning_rate=0.0089, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 21.1405\n",
      "Training with LSTM units=96.0, learning_rate=0.0089, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 22.4322\n",
      "Training with LSTM units=96.0, learning_rate=0.0049, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 21.3523\n",
      "Training with LSTM units=96.0, learning_rate=0.0049, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 23.1180\n",
      "Training with LSTM units=96.0, learning_rate=0.0049, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 21.5108\n",
      "Training with LSTM units=96.0, learning_rate=0.0022, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 20.8765\n",
      "Training with LSTM units=96.0, learning_rate=0.0022, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 23.4601\n",
      "Training with LSTM units=96.0, learning_rate=0.0022, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 20.0421\n",
      "Training with LSTM units=96.0, learning_rate=0.0016, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 20.8596\n",
      "Training with LSTM units=96.0, learning_rate=0.0016, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 22.5823\n",
      "Training with LSTM units=96.0, learning_rate=0.0016, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 22.1494\n",
      "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 22.5690\n",
      "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 21.0819\n",
      "Training with LSTM units=96.0, learning_rate=0.0007, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 20.7968\n",
      "Training with LSTM units=96.0, learning_rate=0.0006, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 21.9754\n",
      "Training with LSTM units=96.0, learning_rate=0.0006, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Validation RMSE: 21.3817\n",
      "Training with LSTM units=96.0, learning_rate=0.0006, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Validation RMSE: 22.6506\n",
      "Training with LSTM units=64.0, learning_rate=0.0089, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Validation RMSE: 27.9831\n",
      "Training with LSTM units=64.0, learning_rate=0.0089, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.9362\n",
      "Training with LSTM units=64.0, learning_rate=0.0089, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.6703\n",
      "Training with LSTM units=64.0, learning_rate=0.0049, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 27.1847\n",
      "Training with LSTM units=64.0, learning_rate=0.0049, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 20.4172\n",
      "Training with LSTM units=64.0, learning_rate=0.0049, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Validation RMSE: 20.4250\n",
      "Training with LSTM units=64.0, learning_rate=0.0022, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 20.3240\n",
      "Training with LSTM units=64.0, learning_rate=0.0022, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.5976\n",
      "Training with LSTM units=64.0, learning_rate=0.0022, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.5014\n",
      "Training with LSTM units=64.0, learning_rate=0.0016, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 21.3650\n",
      "Training with LSTM units=64.0, learning_rate=0.0016, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 22.9443\n",
      "Training with LSTM units=64.0, learning_rate=0.0016, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 20.5353\n",
      "Training with LSTM units=64.0, learning_rate=0.0007, dropout=0.4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.6472\n",
      "Training with LSTM units=64.0, learning_rate=0.0007, dropout=0.3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Validation RMSE: 20.6775\n",
      "Training with LSTM units=64.0, learning_rate=0.0007, dropout=0.1\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Validation RMSE: 23.2750\n",
      "Training with LSTM units=64.0, learning_rate=0.0006, dropout=0.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dropout, learning_rate, hidden_size = intervalle_confiance(path_bootstrap)\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "#Sauvegarder les résultats dans un DataFrame\n",
    "results_all = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for hidden_size in param_grid['hidden_size']:\n",
    "    for learning_rate in param_grid['learning_rate']:\n",
    "        for dropout in param_grid['dropout']:\n",
    "            print(f\"Training with LSTM units={hidden_size}, learning_rate={learning_rate:.4f}, dropout={dropout}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Build the LSTM model\n",
    "            model = model_lstm_1layer(input_shape, hidden_size, dropout, activation, learning_rate)\n",
    "\n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_array, label_array,\n",
    "                validation_data=(test_array, test_rul),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=0\n",
    "            )\n",
    "            # Evaluate the model on the validation set\n",
    "            y_pred = model.predict(test_array)\n",
    "            # Calcul de la RMSE\n",
    "            rmse = root_mean_squared_error(test_rul, y_pred)\n",
    "            s_score = compute_s_score(test_rul, y_pred)\n",
    "            mape = compute_MAPE(test_rul, y_pred)\n",
    "            r2 = r2_score(test_rul, y_pred)\n",
    "            #accuracy = accuracy_score(test_rul, y_pred)\n",
    "\n",
    "            print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "\n",
    "            time_training = time.time() - start_time\n",
    "            i+=1\n",
    "            #Sauvegarder les résultats dans un DataFrame\n",
    "\n",
    "            results_all = pd.concat([results_all, pd.DataFrame([{\n",
    "                'bootstrap_series': i,\n",
    "                'hidden_size': hidden_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'dropout': dropout,\n",
    "                'rmse': rmse,\n",
    "                's_score': s_score,\n",
    "                'mape': mape,\n",
    "                'r2': r2,\n",
    "                'training_time': time_training\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            results_all.to_csv(path_grid, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1qzNWs_zEhJG",
    "w3R-Zqn8b7-s",
    "6XjaNrNBnLtk"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
